{
  "hash": "feb8ac142ada213d810b36ca81a6ddfc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The g`R`ammaticalization of 'perd√≥n' in Spanish varieties\"\nauthor: \"Fatemeh Modir Dehghan\"\naffiliation: \"University of Cologne\"\ndate: \"2025-09-17\"\nexecute:\n  echo: true\n  warning: false\n  message: false\nbibliography: final.bib\n---\n\n\n::: {.cell}\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## About the author of this chapter\n\nDela (Fatemeh) Modir Dehghan is a Master‚Äôs student in linguistics at the University of Cologne in Germany. Originally from Iran, she completed her Bachelor‚Äôs degree in 2023 in English linguistics and translation at Alborz University.She is particularly interested in corpus-based explorations of language and aims to investigate how language changes over time using real-world data. She submitted an earlier version of this chapter as a term paper as part of Dr. Le Foll's M.A. seminar on *Statistics and Data Visualisation in `R`*.\n:::\n\nThis chapter will guide you through the steps to **reproduce** the results of a published corpus linguistics study [@Jansegers2024] using `R`. It will walk you through how to:\n\n-   Download and load the original dataset provided by @Jansegers2024 into `R`\n-   Understand the structure and the linguistic variables of the dataset (Spanish variety, offense type, and apology form)\n-   Wrangle the data to categorize *perd√≥n*, *disculpa*, and *lo siento* by pragmatic function\n-   Analyze the use of *perd√≥n* as a discourse marker in Mexican and Peninsular Spanish\n-   Reproduce the key descriptive statistics and test results reported in @Jansegers2024.\n-   Compare the reproduced values (e.g., frequency counts, significance tests) with those reported in the original study\n-   Visualize trends across varieties and offense types using `{ggplot2}` to support the interpretation of the findings.\n\nWhether you are new to `R` or seeking to sharpen your analytical skills, this chapter provides a guided, reproducible introduction to data-driven linguistic analysis using Spanish apology markers as a case study.\n\n## Introducing the study {#sec-Intro}\n\nIn this chapter, we reproduce the results of a corpus linguistics study [@Jansegers2024], which investigates the grammaticalization of the Spanish apology marker *perd√≥n* in two regional varieties: Mexican and Peninsular Spanish. Grammaticalization refers to the historical process by which lexical items such as verbs or nouns evolve into grammatical or discourse-related elements [@Hopper2003; @Heine2002]. In this case, the verb *perdonar* (‚Äòto pardon‚Äô) has undergone semantic and functional shifts, becoming the discourse marker *perd√≥n*, particularly in the context of low-imposition offenses.\n\nThe original study [@Jansegers2024] analyzes corpus data to explore how apology markers (*perd√≥n*, *lo siento*, *disculpa*) vary according to factors such as offense type, speaker responsibility, and Spanish variety. Their methodology draws on frameworks from grammaticalization theory [@Hopper2003] and politeness theory [@Brown1987].\n\nOur goal is to reproduce the analyses of @Jansegers2024 using the same dataset and statistical procedures, and visualizations in `R`. This will allow us to compare our outputs to those reported in the original study and assess the consistency of results across offense types and regional varieties.\n\nThis reproduction focuses on the following research question:\n\n-   Does *perd√≥n* function differently in Mexican and Peninsular Spanish?\n\n## Retrieving the data {#sec-retrieving}\n\nWe begin by retrieving the original dataset used in the study by @Jansegers2024. The researchers compiled corpus data from two distinct varieties of Spanish:\n\n-   **Mexican Spanish**\n-   **Peninsular Spanish**\n\nThese datasets are made up of real-life language interactions, including transcripts of conversations, online discussions, and formal writing. Each part of the corpus has been carefully annotated to highlight apology phrases like *perd√≥n*, *disculpa*, and *lo siento* showing how they are used in different contexts.\n\nIn their open-access publication in *Languages*, the authors included the following Data Availability Statement [@Jansegers2024: 19]:\n\n> **Data Availability Statement**\\\n> The research data of this study is available in TROLLing. Jansegers, Marlies; Melis, Chantal; Arrington B√°ez, Jennie Elenor, 2023, Replication Data for: Diverging grammaticalization patterns across Spanish varieties: the case of perd√≥n in Mexican and Peninsular Spanish, <https://doi.org/10.18710/IEXVVN> (accessed on 1 December 2023), DataverseNO.\n\nTo obtain the dataset, follow these straightforward steps:\n\n-   **Follow the link to the data repository:\\\n    **<https://doi.org/10.18710/IEXVVN>\n-   **Locate the dataset:**\\\n    Locate the dataset file named `Data_perdon_20231221.csv`.\n-   **Download the dataset:**\\\n    Save the CSV file (`Data_perdon_20231221.csv`) to your local project directory.\n\n## Preprocessing the data {#sec-dataprocessing}\n\nTo get started, you'll want to load (and if necessary, first install) the `R` libraries that we will need for this reproduction project.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(here) # Useful for file path management.\nlibrary(ggmosaic) # Visualizes relationships in data through mosaic plots in {ggplot2}.\nlibrary(kableExtra) # To display nice-looking tables.\nlibrary(skimr) # Provides summaries of dataset variables for quick insights into distributions and missing data.\nlibrary(tidyverse) # A collection of core data science packages, including {ggplot2} and {dplyr} for data visualisation, data wrangling, and data import.\n```\n:::\n\n\nOnce the necessary packages are loaded, we can read in the dataset and check its contents. Note that the dataset is **semi-colon separated**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Import the dataset\ndata <- read.csv(here(\"B_CaseStudies\", \"Dela\", \"Data_perdon_20231221.csv\"), sep = \";\")\n\n# Display the first few rows\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  variety  corpus      form           offense_type face_affected\n1      MX PRESEEA disculpar inappropriate_behavior      positive\n2      MX PRESEEA disculpar     lack_consideration      positive\n3      MX PRESEEA disculpar      censored_language      positive\n4      MX PRESEEA disculpar     temporal_territory      negative\n5      MX PRESEEA disculpar           slips_tongue      positive\n6      MX PRESEEA disculpar           slips_tongue      positive\n  face_orientation\n1          speaker\n2           hearer\n3          speaker\n4           hearer\n5          speaker\n6          speaker\n```\n\n\n:::\n:::\n\n\n-   The dataset is stored as a **CSV file**, so we use `read.csv()`.\n-   `sep = \";\"` ensures the correct **delimiter** is used (European-style CSVs).\n-   `head(data)` helps us **quickly preview** the dataset.\n\nNow that we have imported the data , it's crucial to understand the **structure of the dataset** to ensure all variables are correctly formatted.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check the structure of the dataset\nstr(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t769 obs. of  6 variables:\n $ variety         : chr  \"MX\" \"MX\" \"MX\" \"MX\" ...\n $ corpus          : chr  \"PRESEEA\" \"PRESEEA\" \"PRESEEA\" \"PRESEEA\" ...\n $ form            : chr  \"disculpar\" \"disculpar\" \"disculpar\" \"disculpar\" ...\n $ offense_type    : chr  \"inappropriate_behavior\" \"lack_consideration\" \"censored_language\" \"temporal_territory\" ...\n $ face_affected   : chr  \"positive\" \"positive\" \"positive\" \"negative\" ...\n $ face_orientation: chr  \"speaker\" \"hearer\" \"speaker\" \"hearer\" ...\n```\n\n\n:::\n:::\n\n\nIn this step, we need to check for missing values before we start the analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check for missing values\nsum(is.na(data))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\nTo further understand the dataset, let‚Äôs generate summary descriptive statistics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get an overview of the dataset\nskim(data)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |data |\n|Number of rows           |769  |\n|Number of columns        |6    |\n|_______________________  |     |\n|Column type frequency:   |     |\n|character                |6    |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: character**\n\n|skim_variable    | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:----------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|variety          |         0|             1|   2|   2|     0|        2|          0|\n|corpus           |         0|             1|   3|  10|     0|        9|          0|\n|form             |         0|             1|   6|   9|     0|        4|          0|\n|offense_type     |         0|             1|  10|  22|     0|       14|          0|\n|face_affected    |         0|             1|   8|   8|     0|        2|          0|\n|face_orientation |         0|             1|   6|   7|     0|        2|          0|\n\n\n:::\n:::\n\n\n::: callout-tip\n#### üìù Quiz Time! {.unnumbered}\n\n\\[**Q1**\\] When importing the dataset, why do we specify `sep = \";\"` in `read.csv()`?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_60089\" onsubmit=\"return validate_form_60089()\" method=\"post\">\n<input type=\"radio\" name=\"answer_60089\" id=\"answer_60089_1\" value=\"Because the CSV uses semicolons as the separator character\"/>\n<label>Because the CSV uses semicolons as the separator character</label>\n<br/>\n<input type=\"radio\" name=\"answer_60089\" id=\"answer_60089_2\" value=\"To automatically remove rows with missing values\"/>\n<label>To automatically remove rows with missing values</label>\n<br/>\n<input type=\"radio\" name=\"answer_60089\" id=\"answer_60089_3\" value=\"To indicate that this dataset uses semicolons instead of decimal points\"/>\n<label>To indicate that this dataset uses semicolons instead of decimal points</label>\n<br/>\n<input type=\"radio\" name=\"answer_60089\" id=\"answer_60089_4\" value=\"To convert columns contain texts into factors\"/>\n<label>To convert columns contain texts into factors</label>\n<br/>\n<input type=\"radio\" name=\"answer_60089\" id=\"answer_60089_5\" value=\"To speed up the import of large datasets like this one\"/>\n<label>To speed up the import of large datasets like this one</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_60089\"></div>\n</form>\n<script>function validate_form_60089() {var x, text; var x = document.forms['form_60089']['answer_60089'].value;if (x == 'Because the CSV uses semicolons as the separator character'){text = 'Well done! European-style CSVs often separate fields with semi-colons instead of commas.';} else {text = 'Not quite. <code>sep = ';'</code> ensures fields are properly separated when commas aren‚Äôt used.';} document.getElementById('result_60089').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1;res1 = document.getElementById('result_60089').innerText == 'Well done! European-style CSVs often separate fields with semi-colons instead of commas.';text = res1;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_20302\" onclick=\"return show_hint_20302()\">üê≠ Click for a hint!</div>\n<div id=\"result_20302\" onclick=\"return show_hint_20302()\"></div>\n<script>function show_hint_20302(){var x = document.getElementById('result_20302').innerHTML; if(!x){document.getElementById('result_20302').innerHTML = 'üí° Hint: Different countries use different default separators for CSV files.';} else {document.getElementById('result_20302').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\\[**Q2**\\] What is the purpose of using `skim(data)` after importing the dataset?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_69504\" onsubmit=\"return validate_form_69504()\" method=\"post\">\n<input type=\"radio\" name=\"answer_69504\" id=\"answer_69504_1\" value=\"To quickly summarize variable types, missing values, and distributions\"/>\n<label>To quickly summarize variable types, missing values, and distributions</label>\n<br/>\n<input type=\"radio\" name=\"answer_69504\" id=\"answer_69504_2\" value=\"To delete redundant columns automatically\"/>\n<label>To delete redundant columns automatically</label>\n<br/>\n<input type=\"radio\" name=\"answer_69504\" id=\"answer_69504_3\" value=\"To detect and replace missing values with averages\"/>\n<label>To detect and replace missing values with averages</label>\n<br/>\n<input type=\"radio\" name=\"answer_69504\" id=\"answer_69504_4\" value=\"To visualize the data with {ggplot2}\"/>\n<label>To visualize the data with {ggplot2}</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_69504\"></div>\n</form>\n<script>function validate_form_69504() {var x, text; var x = document.forms['form_69504']['answer_69504'].value;if (x == 'To quickly summarize variable types, missing values, and distributions'){text = 'Exactly! <code>skimr::skim()</code> gives you a compact, detailed overview of your dataset‚Äôs structure and health.';} else {text = 'Not quite. <code>skim()</code> is used for summarizing, not for cleaning or plotting.';} document.getElementById('result_69504').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2;res1 = document.getElementById('result_60089').innerText == 'Well done! European-style CSVs often separate fields with semi-colons instead of commas.'; res2 = document.getElementById('result_69504').innerText == 'Exactly! skimr::skim() gives you a compact, detailed overview of your dataset‚Äôs structure and health.';text = res1 + res2;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_31549\" onclick=\"return show_hint_31549()\">üê≠ Click for a hint!</div>\n<div id=\"result_31549\" onclick=\"return show_hint_31549()\"></div>\n<script>function show_hint_31549(){var x = document.getElementById('result_31549').innerHTML; if(!x){document.getElementById('result_31549').innerHTML = 'üí° Hint: <code>skim()</code> offers summaries for variable types, missingness, and distribution quickly.';} else {document.getElementById('result_31549').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n:::\n\n## Reviewing the variables {#sec-review}\n\nThe dataset consists primarily of **categorical variables**, each of which represents a set of predefined categories. Understanding these variables and the levels that they can take is essential before beginning analysis:\n\n-   **`variety`**: Refers to the regional variety of Spanish in which the apology occurs.\n    -   Levels: `MX` (Mexican) and `SP` (Peninsular).\n-   **`corpus`**: Indicates the specific corpus or sub-corpus from which the example was drawn.\n    -   Levels: `PRESEEA`, `CSCM`, `CHBC`, `CME`, `Ameresco`, `CORMA`, `VALESCO`, `C-ORAL-ROM`, and `CORLEC`.\n-   **`form`**: The type of apology marker used in the utterance.\n    -   Levels: `perd√≥n`, `disculpar`, `perdonar`, and `lo siento`\n-   **`offense_type`**: Categorizes the nature or source of the offense prompting the apology.\n    -   Levels: `inappropriate_behavior`, `criticism_disagreement`, `obligation`, `damage_belongings`,  etc. (14 specific types in total)\n-   **`face_affected`**: Describes whose face (i.e., social identity or image) is being addressed or repaired by the apology.\n    -   Levels: `positive`, `negative`.\n-   **`face_orientation`**: Refers to whether the apology is oriented toward preserving the speaker‚Äôs own face or that of another.\n    -   Levels: `speaker`, `hearer`.\n\nSince many of our variables are categorical (`variety`, `form`, `offense_type`, etc.), we convert them to **factors** to facilitate the analysis in `R`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_filtered <- data |>\n  mutate(across(c(form, variety, offense_type, face_affected, face_orientation), factor))\n```\n:::\n\n\nNow that our dataset is well-structured, we can move forward to descriptive statistics and visualization @sec-DelaPloting.\n\n## Plotting the results {#sec-DelaPloting}\n\nFirst, we take a look at frequency of the the different forms of apology markers across both Spanish varieties.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count frequency of apology markers\napology_counts <- data |>\n  count(variety, form) |>\n  arrange(desc(n))\n\napology_counts |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|variety |form      |   n|\n|:-------|:---------|---:|\n|MX      |perd√≥n    | 299|\n|SP      |perd√≥n    | 201|\n|SP      |perdonar  | 158|\n|MX      |disculpar |  49|\n|SP      |lo siento |  35|\n|SP      |disculpar |  12|\n|MX      |perdonar  |  11|\n|MX      |lo siento |   4|\n\n\n:::\n:::\n\n\nTo better visualize the contrast, we also create a grouped bar chart.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show figure code\"}\nggplot(apology_counts, aes(x = form, \n                           y = n, \n                           fill = variety)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Frequency of Apology Markers by Spanish Variety\",\n    x = \"Apology Marker\",\n    y = \"Count\",\n    fill = \"Variety\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![ Frequency of Apology Markers](GrammaticalizationPerdon_files/figure-html/fig-DelaPlot-1.png){#fig-DelaPlot width=576}\n:::\n:::\n\n\nThis chart confirms the trends reported by @Jansegers2024: *perd√≥n* is the most frequent marker, especially in Mexican Spanish, while Peninsular Spanish shows a broader mix of forms. These findings align with politeness theory [@Brown1987], which explains cultural variation in face strategies, and grammaticalization frameworks [@Hopper2003; @Heine2002], which describe how frequent lexical items become discourse markers.\n\nWhile @fig-DelaPlot earlier provided an overall frequency comparison of apology markers across Spanish varieties, mosaic plots allow for a more detailed visualization. To visualize how apology marker usage differs by Spanish variety, we use `geom_mosaic()` from the {ggmosaic} package. This plot shows the distribution of the different apology forms across Mexican and Peninsular Spanish, with bar widths reflecting the relative frequencies within each variety.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show figure code\"}\nggplot(data_filtered) +\n  geom_mosaic(aes(x = product(variety), \n                  fill = form, \n                  weight = 1)) +\n  labs(\n    title = \"Mosaic Plot: Apology Marker Distribution by Variety\",\n    x = \"Spanish Variety\",\n    y = \"Proportion of Apology Markers\",\n    fill = \"Apology Marker\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Mosaic Plot: Apology Marker Distribution by Variety](GrammaticalizationPerdon_files/figure-html/fig-DelaMosaic-1.png){#fig-DelaMosaic width=576}\n:::\n:::\n\n\n::: callout-tip\n#### üìù Quiz Time! {.unnumbered}\n\n\\[**Q3**\\] What does the height (length) of the bars represent in @fig-DelaMosaic?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_34292\" onsubmit=\"return validate_form_34292()\" method=\"post\">\n<input type=\"radio\" name=\"answer_34292\" id=\"answer_34292_1\" value=\"The number of apology marker types across the two Spanish varieties\"/>\n<label>The number of apology marker types across the two Spanish varieties</label>\n<br/>\n<input type=\"radio\" name=\"answer_34292\" id=\"answer_34292_2\" value=\"The relative frequency of each apology marker within each Spanish variety\"/>\n<label>The relative frequency of each apology marker within each Spanish variety</label>\n<br/>\n<input type=\"radio\" name=\"answer_34292\" id=\"answer_34292_3\" value=\"The number of face-orientation contexts in both Mexican and Peninsular Spanish\"/>\n<label>The number of face-orientation contexts in both Mexican and Peninsular Spanish</label>\n<br/>\n<input type=\"radio\" name=\"answer_34292\" id=\"answer_34292_4\" value=\"The number of corpus observations in each Spanish variety\"/>\n<label>The number of corpus observations in each Spanish variety</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_34292\"></div>\n</form>\n<script>function validate_form_34292() {var x, text; var x = document.forms['form_34292']['answer_34292'].value;if (x == 'The relative frequency of each apology marker within each Spanish variety'){text = 'Well done!';} else {text = 'Not quite. Mosaic plots display group size on the x-axis. On the y-axis, they display within-group proportions.';} document.getElementById('result_34292').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3;res1 = document.getElementById('result_60089').innerText == 'Well done! European-style CSVs often separate fields with semi-colons instead of commas.'; res2 = document.getElementById('result_69504').innerText == 'Exactly! skimr::skim() gives you a compact, detailed overview of your dataset‚Äôs structure and health.'; res3 = document.getElementById('result_34292').innerText == 'Well done!';text = res1 + res2 + res3;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_15094\" onclick=\"return show_hint_15094()\">üê≠ Click for a hint!</div>\n<div id=\"result_15094\" onclick=\"return show_hint_15094()\"></div>\n<script>function show_hint_15094(){var x = document.getElementById('result_15094').innerHTML; if(!x){document.getElementById('result_15094').innerHTML = 'üí° Hint: Mosaic plots visualize both group size and category distribution. Think of x-axis = total group size.';} else {document.getElementById('result_15094').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n:::\n\n## Reproducing the tables\n\nIn this section, we reproduce the main descriptive statistics from @Jansegers2024 regarding the distribution of explicit apology markers across Spanish varieties and face orientations.\n\nWe begin by reconstructing the contingency table comparing Mexican and Peninsular Spanish in @tbl-DelaVariety. We then break down the use of each form in relation to face-orientation contexts for both Mexican (@tbl-DelaMexico) and Peninsular (@tbl-DelaSpain) speakers. Frequencies and row-wise percentages are included to match the original analysis.\n\n### Shared methodology\n\nAll tables were generated using the following functions:\n\n-   **`count()`** to obtain for raw frequencies per combination of characteristics.\n-   **`proportions()` √ó 100** for percentages within each group.\n-   **`paste0()`** to combine counts and percentages.\n-   **`pivot_wider()`** to reshape for display comparable to the original publication.\n    -   `names_from = form` uses the unique apology forms to create new columns.\n    -   `values_from = n_pct` fills those columns with the combined \"count (percent)\" strings.\n\nWe only varied the grouping/filtering depending on the table‚Äôs focus.\n\n### Apology forms by variety {#sec-tab2}\n\nTo begin, we count the number of each apology form in Mexican and Peninsular Spanish, and then calculate row-wise percentages using `group_by()` and `proportions()` to show relative frequency across varieties.\n\n\n::: {#tbl-DelaVariety .cell tbl-cap='Apology Marker Distribution by Variety'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show table code\"}\napology_table <- data |>\n  count(variety, form) |>\n  group_by(variety) |>\n  mutate(percentage = round(proportions(n) * 100, 0)) |>\n  mutate(n_pct = paste0(n, \" (\", percentage, \"%)\")) |>\n  select(variety, form, n_pct) |>\n  pivot_wider(names_from = variety, values_from = n_pct)\n\napology_table |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|form      |MX        |SP        |\n|:---------|:---------|:---------|\n|disculpar |49 (13%)  |12 (3%)   |\n|lo siento |4 (1%)    |35 (9%)   |\n|perdonar  |11 (3%)   |158 (39%) |\n|perd√≥n    |299 (82%) |201 (50%) |\n\n\n:::\n:::\n\n\n@tbl-DelaVariety is a reproduction of Table 2 from @Jansegers2024. The results show a clear preference for *perd√≥n* in Mexico, while *perdonar* is more common in Spain. This contrast reflects broader regional differences in formality and apology strategies.\n\nThe percentages didn‚Äôt exactly match the original article due to **rounding** **difference**. While `49 / 363` equals `13.49%`, R‚Äôs `round()` function rounds it **down to 13%**, whereas the original paper rounds it **up to 14%**.\n\nThis minor discrepancy affects only one cell in the table and does not impact the overall distribution pattern.\n\n### Conducting a Chi-square test {#sec-chi-square-test}\n\nBuilding on the findings summarised in @tbl-DelaVariety, we now test whether the observed differences in apology form usage between Mexican and Peninsular Spanish are statistically significant at an alpha level of 0.05. In line with the original study [@Jansegers2024], we applied a Chi-square test to test this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a contingency table\napology_matrix <- table(data$variety, data$form)\n\n# Run the Chi-square test\nchisq.test(apology_matrix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test\n\ndata:  apology_matrix\nX-squared = 192.35, df = 3, p-value < 2.2e-16\n```\n\n\n:::\n:::\n\n\nThe Chi-Square test that there is a statistically significant association between Spanish variety and apology marker (œá¬≤ = 192.35, df = 3, *p* \\< .001), matching the results in @Jansegers2024.\n\n### Apology forms by face orientation (Mexico) {#sec-tab3}\n\nTo produce Table 3 from @Jansegers2024, we extend the procedure used to generate @tbl-DelaVariety by introducing a new composite variable, `face_group`, which merges `face_orientation` and `face_affected` into three analytically meaningful categories:\n\n-   **Positive face S** (speaker‚Äôs face affected),\n-   **Negative face H** (hearer‚Äôs negative face),\n-   **Positive face H** (hearer‚Äôs positive face).\n\nThese reflects the speaker vs. hearer face-threat distinctions used by @Jansegers2024. \n\n\n::: {#tbl-DelaMexico .cell tbl-cap='Apology Forms by Face Orientation (Mexico), Table 3'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show table code\"}\nmexico_forms <- data |>\n  filter(variety == \"MX\") |>\n  mutate(face_group = case_when(\n    face_orientation == \"speaker\" ~ \"Positive face S\",\n    face_orientation == \"hearer\" & face_affected == \"negative\" ~ \"Negative face H\",\n    face_orientation == \"hearer\" & face_affected == \"positive\" ~ \"Positive face H\"\n  )) |>\n  count(face_group, form) |>\n  group_by(face_group) |>\n  mutate(pct = round(100 * n / sum(n))) |>\n  mutate(n_pct = paste0(n, \" (\", pct, \"%)\")) |>\n  select(face_group, form, n_pct) |>\n  pivot_wider(names_from = form, values_from = n_pct)\n\nmexico_forms |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|face_group      |disculpar |lo siento |perdonar |perd√≥n    |\n|:---------------|:---------|:---------|:--------|:---------|\n|Negative face H |22 (18%)  |1 (1%)    |6 (5%)   |90 (76%)  |\n|Positive face H |12 (40%)  |3 (10%)   |2 (7%)   |13 (43%)  |\n|Positive face S |15 (7%)   |NA        |3 (1%)   |196 (92%) |\n\n\n:::\n:::\n\n\nOur output confirms the study‚Äôs finding that *perd√≥n* is strongly favored when the speaker‚Äôs own face is at stake. All percentages and frequencies match those in the original study exactly, without rounding differences. \n\n### Apology forms by face orientation (Spain) {#sec-tab4}\n\nWe recreate Table 4 from the original study by grouping the Peninsular Spanish data by face orientation and face affected.\n\n\n::: {#tbl-DelaSpain .cell tbl-cap='Apology Forms by Face Orientation (Spain), Table 4'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show table code\"}\nspain_forms <- data |>\n  filter(variety == \"SP\") |>\n  mutate(face_group = case_when(\n    face_orientation == \"speaker\" ~ \"Positive face S\",\n    face_orientation == \"hearer\" & face_affected == \"negative\" ~ \"Negative face H\",\n    face_orientation == \"hearer\" & face_affected == \"positive\" ~ \"Positive face H\"\n  )) |>\n  count(face_group, form) |>\n  group_by(face_group) |>\n  mutate(pct = round(100 * n / sum(n))) |>\n  mutate(n_pct = paste0(n, \" (\", pct, \"%)\")) |>\n  select(face_group, form, n_pct) |>\n  pivot_wider(names_from = form, values_from = n_pct)\n\nspain_forms |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|face_group      |disculpar |lo siento |perdonar |perd√≥n    |\n|:---------------|:---------|:---------|:--------|:---------|\n|Negative face H |7 (4%)    |15 (9%)   |88 (50%) |66 (38%)  |\n|Positive face H |1 (2%)    |14 (22%)  |39 (61%) |10 (16%)  |\n|Positive face S |4 (2%)    |6 (4%)    |31 (19%) |125 (75%) |\n\n\n:::\n:::\n\n\nThe results match those reported in the original study [@Jansegers2024]: the verb *perdonar* is common in hearer-oriented contexts, while *perd√≥n* appears more in speaker-oriented ones. The small discrepancies observed such as 36% instead of 37% for *perd√≥n* under Negative face H, or 17% instead of 16% under Positive face H are limited to 1 percentage point and likely stem from rounding differences in the percentage calculations (see `?round()`). These very minor differences do not affect the interpretation of the results. \n\n::: callout-tip\n#### Quiz Time! {.unnumbered}\n\nüìù Let's check your understanding of the data wrangling steps necessary to generate these tables!\n\n\\[**Q4**\\] What does the `paste0()` function do?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_16543\" onsubmit=\"return validate_form_16543()\" method=\"post\">\n<input type=\"radio\" name=\"answer_16543\" id=\"answer_16543_1\" value=\"It combines count values and percentages into a single vector.\"/>\n<label>It combines count values and percentages into a single vector.</label>\n<br/>\n<input type=\"radio\" name=\"answer_16543\" id=\"answer_16543_2\" value=\"It formats columns for easy export to Word.\"/>\n<label>It formats columns for easy export to Word.</label>\n<br/>\n<input type=\"radio\" name=\"answer_16543\" id=\"answer_16543_3\" value=\"It calculates percentages.\"/>\n<label>It calculates percentages.</label>\n<br/>\n<input type=\"radio\" name=\"answer_16543\" id=\"answer_16543_4\" value=\"It combines two or more vectors into one and separates these vectors with the number 0.\"/>\n<label>It combines two or more vectors into one and separates these vectors with the number 0.</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_16543\"></div>\n</form>\n<script>function validate_form_16543() {var x, text; var x = document.forms['form_16543']['answer_16543'].value;if (x == 'It combines two or more vectors into one with no separating character.'){text = 'Well done!';} else {text = 'Not quite. See what happens if you change the function to paste() rather than paste0().';} document.getElementById('result_16543').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4;res1 = document.getElementById('result_60089').innerText == 'Well done! European-style CSVs often separate fields with semi-colons instead of commas.'; res2 = document.getElementById('result_69504').innerText == 'Exactly! skimr::skim() gives you a compact, detailed overview of your dataset‚Äôs structure and health.'; res3 = document.getElementById('result_34292').innerText == 'Well done!'; res4 = document.getElementById('result_16543').innerText == 'Well done!';text = res1 + res2 + res3 + res4;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_13121\" onclick=\"return show_hint_13121()\">üê≠ Click for a hint!</div>\n<div id=\"result_13121\" onclick=\"return show_hint_13121()\"></div>\n<script>function show_hint_13121(){var x = document.getElementById('result_13121').innerHTML; if(!x){document.getElementById('result_13121').innerHTML = 'üí° Hint: Check the help file of the <code>paste0()</code> function.';} else {document.getElementById('result_13121').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n\n\\[**Q5**\\] Why did we use `pivot_wider()` in our table generation steps?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<form name=\"form_55385\" onsubmit=\"return validate_form_55385()\" method=\"post\">\n<input type=\"radio\" name=\"answer_55385\" id=\"answer_55385_1\" value=\"To convert the long-format counts into a wide-format table with forms as columns.\"/>\n<label>To convert the long-format counts into a wide-format table with forms as columns.</label>\n<br/>\n<input type=\"radio\" name=\"answer_55385\" id=\"answer_55385_2\" value=\"To make the plot display the x-axis in alphabetical order.\"/>\n<label>To make the plot display the x-axis in alphabetical order.</label>\n<br/>\n<input type=\"radio\" name=\"answer_55385\" id=\"answer_55385_3\" value=\"To automatically rename the apology marker variables.\"/>\n<label>To automatically rename the apology marker variables.</label>\n<br/>\n<input type=\"radio\" name=\"answer_55385\" id=\"answer_55385_4\" value=\"To filter out rows with zero frequency.\"/>\n<label>To filter out rows with zero frequency.</label>\n<br/>\n<input type=\"submit\" value=\"Check answer\"/>\n<div id=\"result_55385\"></div>\n</form>\n<script>function validate_form_55385() {var x, text; var x = document.forms['form_55385']['answer_55385'].value;if (x == 'To convert the long-format counts into a wide-format table with forms as columns.'){text = 'Exactly!';} else {text = 'Not quite! Think about how the data was displayed before and after reshaping.';} document.getElementById('result_55385').innerHTML = text; evaluate_final_score(); return false;}function evaluate_final_score(){\n         element = document.getElementById('checkdown_final_score');\n         if(element === null){return false;} else {var element, text, res1, res2, res3, res4, res5;res1 = document.getElementById('result_60089').innerText == 'Well done! European-style CSVs often separate fields with semi-colons instead of commas.'; res2 = document.getElementById('result_69504').innerText == 'Exactly! skimr::skim() gives you a compact, detailed overview of your dataset‚Äôs structure and health.'; res3 = document.getElementById('result_34292').innerText == 'Well done!'; res4 = document.getElementById('result_16543').innerText == 'Well done!'; res5 = document.getElementById('result_55385').innerText == 'Exactly!';text = res1 + res2 + res3 + res4 + res5;element.innerHTML = text;\n         return false;\n         }}</script>\n```\n\n:::\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hint_60823\" onclick=\"return show_hint_60823()\">üê≠ Click for a hint!</div>\n<div id=\"result_60823\" onclick=\"return show_hint_60823()\"></div>\n<script>function show_hint_60823(){var x = document.getElementById('result_60823').innerHTML; if(!x){document.getElementById('result_60823').innerHTML = 'üí° Hint: We used it after counting form/face combinations ‚Äî the result looked like a grid of labels and values.';} else {document.getElementById('result_60823').innerHTML = '';}}</script>\n```\n\n:::\n:::\n\n:::\n\n## Conclusion\n\nThis project set out to reproduce the main findings of @Jansegers2024, which explored the grammaticalization of *perd√≥n* in Mexican and Peninsular Spanish. We were able to reproduce the findings of the original authors: in this corpus data, *perd√≥n* is far more frequent in Mexican Spanish, while Peninsular Spanish speakers make use of a broader range of apology forms, including *perdonar* and *lo siento*. The frequency tables and percentage distributions that we reproduced from the author's original data closely mirror those published in the original study.\n\nBeyond reproducing the numerical results, we also matched the study‚Äôs visualizations using bar plots (@fig-DelaPlot) and mosaic plots (@fig-DelaMosaic), which clearly show how apology strategies vary by variety and face orientation. These visuals help to illustrate the claim that *perd√≥n* has undergone grammaticalization‚Äîespecially in Mexican Spanish into a high-frequency discourse marker used to manage politeness.\n\nOverall, the reproduction validates both the descriptive and statistical results of the original study, demonstrating how *perd√≥n*‚Äôs usage reflects broader sociopragmatic and grammatical trends across Spanish varieties. Minor formatting or rounding differences aside, our results strongly align with the published findings and reinforce the value of data sharing in corpus-based linguistic research.\n\n### Suggestions for future research\n\nWhile this project successfully reproduces and extends the findings of @Jansegers2024, further studies could enrich the analysis by incorporating additional Spanish varieties beyond Mexico and Spain, or by examining sociolinguistic variables such as speaker age, gender, and social status [see, e.g., @Hernandez2012]. Longitudinal research could also explore whether the grammaticalization of *perd√≥n* continues to evolve over time.\n\n::: {.callout-note collapse=\"true\" title=\"üìå Implementing Citation Management with .bib in Quarto\"}\nTo ensure standardized citation formatting, this project employs a **BibTeX (.bib)** file, referenced within the YAML metadata. The `.bib` file (e.g., `final.bib`) is specified under the `bibliography` field, allowing Quarto to format **in-text citations** and automatically generate a **reference list**.\n\nAdditionally, a **Citation Style Language (CSL)** file (`apa.csl`) is included to enforce **APA-style referencing**. This setup enables seamless integration of bibliographic data while maintaining consistency across the document.\n\nIn-text citations are implemented using the `@key` notation, which Quarto automatically resolves into properly formatted references during rendering.\n\nFor more information on how to insert bibliographic references in Quarto documents, see @sec-References.\n:::\n\n## Packages used in this chapter {.unnumbered}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] H. Jeppson, H. Hofmann, and D. Cook. _ggmosaic: Mosaic Plots in the\nggplot2 Framework_. R package version 0.3.3. 2021.\n<https://github.com/haleyjeppson/ggmosaic>.\n\n[2] K. M√ºller and H. Wickham. _tibble: Simple Data Frames_. R package\nversion 3.2.1. 2023. <https://tibble.tidyverse.org>.\n\n[3] B. Ripley. _nnet: Feed-Forward Neural Networks and Multinomial\nLog-Linear Models_. R package version 7.3-20. 2025.\n<http://www.stats.ox.ac.uk/pub/MASS4/>.\n\n[4] V. Spinu, G. Grolemund, and H. Wickham. _lubridate: Make Dealing\nwith Dates a Little Easier_. R package version 1.9.3. 2023.\n<https://lubridate.tidyverse.org>.\n\n[5] E. Waring, M. Quinn, A. McNamara, et al. _skimr: Compact and\nFlexible Summaries of Data_. R package version 2.1.5. 2022.\n<https://docs.ropensci.org/skimr/>.\n\n[6] H. Wickham. _forcats: Tools for Working with Categorical Variables\n(Factors)_. R package version 1.0.0,\n<https://github.com/tidyverse/forcats>. 2023.\n<https://forcats.tidyverse.org>.\n\n[7] H. Wickham. _tidyverse: Easily Install and Load the Tidyverse_. R\npackage version 2.0.0, <https://github.com/tidyverse/tidyverse>. 2023.\n<https://tidyverse.tidyverse.org>.\n\n[8] H. Wickham, W. Chang, L. Henry, et al. _ggplot2: Create Elegant\nData Visualisations Using the Grammar of Graphics_. R package version\n3.5.1, <https://github.com/tidyverse/ggplot2>. 2024.\n<https://ggplot2.tidyverse.org>.\n\n[9] H. Wickham, R. Fran√ßois, L. Henry, et al. _dplyr: A Grammar of Data\nManipulation_. R package version 1.1.4. 2023.\n<https://dplyr.tidyverse.org>.\n\n[10] H. Wickham and L. Henry. _purrr: Functional Programming Tools_. R\npackage version 1.0.2. 2023. <https://purrr.tidyverse.org>.\n\n[11] H. Wickham, J. Hester, and J. Bryan. _readr: Read Rectangular Text\nData_. R package version 2.1.5. 2024. <https://readr.tidyverse.org>.\n\n[12] H. Wickham, D. Vaughan, and M. Girlich. _tidyr: Tidy Messy Data_.\nR package version 1.3.1. 2024. <https://tidyr.tidyverse.org>.\n```\n\n\n:::\n:::\n\n\n## References {.unnumbered}\n\n[1] P. Brown and S. C. Levinson. _Politeness: Some Universals in\nLanguage Usage_. Cambridge University Press, 1987.\n<https://www.cambridge.org/core/books/politeness-some-universals-in-language-usage/>.\n\n[2] B. Heine and T. Kuteva. _World Lexicon of Grammaticalization_.\nCambridge University Press, 2002.\n<https://doi.org/10.1017/CBO9780511613463>.\n\n[3] J. M. Hern√°ndez-Campoy and J. C. Conde-Silvestre. _The Handbook of\nHistorical Sociolinguistics_. Wiley-Blackwell, 2012.\n<https://doi.org/10.1017/S0047404515000688>.\n\n[4] P. Hopper and E. C. Traugott. _Grammaticalization_. Cambridge\nUniversity Press, 2003. <https://doi.org/10.1017/CBO9781139165525>.\n\n[5] M. Jansegers, E. Melis, and G. Arrington. \"The Grammaticalization\nof Perd√≥n in Spanish Varieties\". In: _Journal of Pragmatics_ 192\n(2024), pp. 15-32. <https://doi.org/10.3390/languages9010013>.\n\n[6] E. C. Traugott and R. B. Dasher. _Regularity in Semantic Change_.\nCambridge University Press, 2001.\n<https://doi.org/10.1017/CBO9780511486500>.\n\n[7] H. Wickham. _ggplot2: Elegant Graphics for Data Analysis_.\nSpringer, 2016. <https://ggplot2-book.org/>.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}