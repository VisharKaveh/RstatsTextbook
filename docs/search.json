[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Analysis for the Language Sciences",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#what-is-this-book-about",
    "href": "index.html#what-is-this-book-about",
    "title": "Data Analysis for the Language Sciences",
    "section": "What is this book about?",
    "text": "What is this book about?\nThis textbook is intended as a hands-on introduction to data management, statistics, and data visualisation for students and researchers in the language sciences. It relies exclusively on freely accessible, open-source tools, focusing primarily on the programming language and environment R.\nIt is often claimed that learning R is ‚Äúnot for everyone‚Äù, or that it has ‚Äúa steep learning curve‚Äù. This textbook aims to prove that the opposite is true. There are many reasons why it is worth investing the time and effort to learn how to do research in R, and it is no more difficult than learning any other new skill. In fact, the results of a recent study suggests that language aptitude is a much stronger predictor of programming aptitude than numeracy (i.e., ‚Äúbeing good at numbers‚Äù) (Prat et al. 2020). So if you have successfully learnt a foreign language in the past, there is no reason why you shouldn‚Äôt succeed in learning a programming language!\n\nLearning R is like learning a foreign language. If you enjoy learning languages, then ‚ÄòR‚Äô is just another one. [‚Ä¶] You have to learn vocabulary, grammar and syntax. Similar to learning a new language, programming languages also have steep learning curves and require quite some commitment. (Dauber 2024)\n\nThe rationale for this textbook is based on my personal observations, in both teaching and consulting, that many ‚Äòintroductory‚Äô textbooks to statistics and/or R are not suitable for many humanities scholars, who typically have little to no prior programming experience and for whom the word ‚Äústatistics‚Äù often evokes little more than unpleasant memories of school mathematics. It is worth stressing that is not a matter of generation (I have observed this phenomenon across all age groups), intelligence (I have taught people far more intelligent than me), or an innate inability to deal with numbers and/or computers (although these are beliefs that, sadly, some have deeply internalised). Instead, I am convinced that, for many people, it is simply a matter of finding a sturdy, first stepping stone and gathering up the courage to step on it to begin this learning journey.\nThe aim of this textbook is by no means to replace any of the brilliant, existing textbooks aimed at imparting statistical literacy for linguistics research, but rather to provide a stepping stone to be able to access these wonderful resources.1",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#who-is-this-book-for",
    "href": "index.html#who-is-this-book-for",
    "title": "Data Analysis for the Language Sciences",
    "section": "Who is this book for?",
    "text": "Who is this book for?\nThe target audience for this book are students and researchers in the language sciences, including (applied) linguistics, (first and second) language teaching, and language education research. All examples are taken from these research areas. Ultimately, however, this textbook may be of use to anyone who feels they could benefit from a maximally accessible stepping stone, whichever discipline they are coming from.\nThis textbook is intended to be read linearly, chapter by chapter. Apart from the first introductory chapter, all other chapters will require several hours of commitment. They include quiz questions and short practical tasks. Completing these tasks is essential to genuinely assimilate the textbook‚Äôs contents. That‚Äôs because the best way to learn new skills is to try things out so, with this in mind, let‚Äôs get cracking!\n\n\n\n\n\n\nFigure¬†1: Artwork encouraging beginner R learners by @allison_horst.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#about-the-author",
    "href": "index.html#about-the-author",
    "title": "Data Analysis for the Language Sciences",
    "section": "About the author",
    "text": "About the author\nI started learning about statistics and R in 2017 when I realised that it would be important for me to conduct the kind of quantitative analyses that I wanted to do as part of my PhD in applied linguistics/English language teaching (Le Foll 2022). I had no previous experience in either and there were no such courses at my university. Even though I mostly learnt by myself, it would be incorrect to say that I am self-taught: I learnt from some of the resources listed in Appendix A, attended bootcamps and summer schools, read countless posts on StackOverflow and various blogs, and exchanged with like-minded people on social media (#Rstats, #dataviz, #TidyTuesday). This why it is fairer to say that I am community-taught.\nI now like to describe myself as an ‚Äúadvanced beginner‚Äù in R and statistics. I am not a programmer, nor a statistician, but rather an applied linguist and committed educator. I enjoy teaching data literacy, statistics, and data visualisation to current and future generations of linguists, language education scholars, and teachers. I teach regular methods courses at the University of Cologne that are attended not just by M.A.¬†and M.Ed. students, but also by some doctoral and post-doctoral researcher colleagues. I also teach workshops for both doctoral and post-doctoral researchers at other institutions on a freelance basis.\nThis textbook was partly designed on the basis of materials that I have developed for these courses and workshops. Publishing these materials is my way to contribute to the wonderful community of people who have helped me on my leaRning journey. ü§ó\n\n\n\nMe back in 2017, proudly presenting at my first international conference.2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Data Analysis for the Language Sciences",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis textbook has benefited greatly from the generous, critical feedback I have received from both novice and expert users of R throughout this project. Many thanks to my colleagues from the Digital Research Academy, Nick Bearman, Ben Golub, and Fritjof Lammers for their critical peer review and to my (former) students at the University of Cologne, Jan Hollmann, Rose H√∂rsting, Vijaya Lakshmi, Paula Raabe, Poppy Siahaan, Veronika Strobl, Clara Stumm, Katja Wiesner, and Isabel Zimmer, for their critical learner feedback.\nSpecial thanks also go out to the researchers whose works are used as case studies in this textbook, Sarah Schimke and Ewa DƒÖbrowska, and to Allison Horst whose beautiful and witty artworks illustrate many of the chapters of this textbook (e.g., Figure¬†1).\nIn addition, I would like to thank everyone who has contributed and continues to contribute to my own data analysis learning journey. At the risk of forgetting someone, I would like to extend special thanks to Vaclav Brezina, Guillaume Desagulier, Stephanie Evert, Stefan Gries, Dani√´l Lakens, Natalia Levshina, Luke Tudge, the RLadies Stack group, the R package developers and maintainers of all the packages I use, as well as the many generous contributors to Stack Overflow and to #Rstats on social media.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#get-in-touch",
    "href": "index.html#get-in-touch",
    "title": "Data Analysis for the Language Sciences",
    "section": "Get in touch! üì©",
    "text": "Get in touch! üì©\nIf (parts of) this textbook helped you on your leaRning journey or for your teaching, do drop me a line to let me know!\nIf you have any suggestions for improvements, I would also love to hear from you. ‚úâÔ∏è\n\n\n\n\n\nDauber, Daniel. 2024. R for non-programmers: A guide for social scientists. Open Education Resource. https://bookdown.org/daniel_dauber_io/r4np_book/.\n\n\nLe Foll, Elen. 2022. Textbook English: A corpus-based analysis of the language of EFL textbooks used in secondary schools in France, Germany and Spain. Osnabr√ºck University PhD thesis. https://doi.org/10.48693/278.\n\n\nPrat, Chantel S., Tara M. Madhyastha, Malayka J. Mottarella & Chu-Hsuan Kuo. 2020. Relating natural language aptitude to individual differences in learning programming languages. Scientific Reports. Nature 10(1). 3817. https://doi.org/10.1038/s41598-020-60661-8.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Data Analysis for the Language Sciences",
    "section": "",
    "text": "A (work-in-progress) list of next-step resources can be found in Appendix A.‚Ü©Ô∏é\nI chose this picture because I vividly remember two professors pointing out that I had written ‚Äúp¬†=¬†0.00‚Äù on my poster (which I had copied-and-pasted from the output of the statistics tool that I had used) and laughing among themselves (but well within earshot) at how stupid that was. Learning these skills certainly requires a lot of effort on the part of the learner, but it also requires an academic culture that strives to include rather than exclude. This textbook explicitly aims for an inclusive approach to teaching the basics of data literacy and I have included this photo as a reminder to always persevere, whether in the face of seemingly insurmountable error message or snarky remarks!‚Ü©Ô∏é",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "1_OpenScholarship.html",
    "href": "1_OpenScholarship.html",
    "title": "1¬† Open ScholaRship",
    "section": "",
    "text": "Chapter overview\nIn this chapter, you will learn about the relevance of Open Scholarship in learning how to manage, manipulate, analyse, and visualise research data. In doing so, the following aspects of Open Scholarship will be introduced:",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Open Schola`R`ship</span>"
    ]
  },
  {
    "objectID": "1_OpenScholarship.html#sec-OpenScience",
    "href": "1_OpenScholarship.html#sec-OpenScience",
    "title": "1¬† Open ScholaRship",
    "section": "1.1 Open Science",
    "text": "1.1 Open Science\nOpen Science is a major component of Open Scholarship and the two terms are frequently used synonymously. Open Scholarship, however, is broader in that it includes all kinds of knowledge, whereas Open Science focuses on what is conventionally considered ‚Äúscientific knowledge‚Äù. Open Science covers many different aspects including:\n\n\n\n\n\n\n\n\nOpen materials\nGiving free, unrestricted, public access to research materials in a way that allows others to replicate the results of published studies and to conduct new studies based on these existing materials.\nMaterials may include questionnaire items, all kinds of experimental stimuli, annotation schemes, inclusion and exclusion criteria, etc. (see Task 2 in Section 2.4).\n\n\n\nOpen data\nGiving free, unrestricted, public access to scientific data, whenever ethically and legally possible (see Berez-Kroeker et al. 2022).\nIn Section 2.1, we will see that studies in the language sciences can involve many different types of data including texts, tables, images, and videos.\n\n\n\nOpen code\nMaking computer code freely and publicly available with appropriate documentation to make research methods and data analyses transparent.\nOpen code can include source code for custom software and packages, code for stimuli generation, data collection and processing, statistical analysis, and data visualisation. Sharing code allows for collaborations, while sharing both code and data allows others to reproduce published results.\n\n\n\nOpen access\nGiving free, unrestricted, public access to scientific outputs, foremost publications. Contrary to a frequent misunderstanding, authors or their institutions do not necessarily have to pay article processing fees (APC) to publish their work in open access. Publishing open access can instead involve uploading a pre-copyedit version of a publication on a public repository (see Section 2.4) or publishing in a not-for-profit open access publication outlet (see section on Open Access in The Turing Way Community 2022).\n\n\n\n\nSharing research data allows us to reproduce the analyses reported in research publications based on the authors‚Äô original data and to test whether different analysis methods would have led to different conclusions. Sharing research materials and code means that we can replicate studies to check the robustness of published results and/or their generalisability across different populations. For example, if a journal article reports on the effectiveness of a new language teaching method based on a study conducted at a British university, we can test whether the same effect can be observed when replicating the study at a Nigerian university or an Indonesian secondary school.\nOpen Science advocates argue that scientific knowledge ‚Äú[should], where appropriate, be openly accessible, transparent, rigorous, reproducible, replicable, accumulative, and inclusive, all which are considered fundamental features of the scientific endeavour‚Äù (Parsons et al. 2022). This corresponds to an ideal that, although probably impossible to fully achieve, is nonetheless worth striving for at all times.\n\nOpen science consists of principles and behaviors that promote transparent, credible, reproducible, and accessible science. (Parsons et al. 2022)\n\nTo conduct open science, a sound understanding of data management and of effective data analysis workflows is crucial. This textbook aims to provide a gentle, practical introduction to these foundational skills using examples from the language sciences. Published as an Open Educational Resource (see Section 1.3), it showcases linguistics and Second Language Acquisition (SLA) publications that include open data, open code and/or materials and teaches data analysis using exclusively open-source software and programming languages (see Section 1.2).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Open Schola`R`ship</span>"
    ]
  },
  {
    "objectID": "1_OpenScholarship.html#sec-OpenSource",
    "href": "1_OpenScholarship.html#sec-OpenSource",
    "title": "1¬† Open ScholaRship",
    "section": "1.2 Open Source",
    "text": "1.2 Open Source\nIn line with its aim to provide an accessible introduction to statistics and data visualisation, this textbook relies exclusively on open-source software and programming languages, foremost LibreOffice Calc, R and RStudio. Open source refers to software whose source code is available under a license that grants anyone the rights to study, modify, and distribute the software to anyone and for any purpose. If we think of a software application as a cake, the source code is like its recipe. It contains the list of ingredients and the steps to bake the cake. Open source means that the recipe is publicly available. You can access it, read it, and use it to bake the cake. You can also modify it to add your own twist, such as adding a new ingredient or making it vegan, and share it with others. In the context of software, this allows many people to collaborate, make improvements, and share their versions, resulting in better and more diverse software.\nUsing open-source software in this introductory textbook means that anyone2 can download, install and use the required software at no cost. However, it is very important to note that not all free software (‚Äòfreeware‚Äô) is open source.\n\n\n\n\n\n\nQuiz time!\n\n\n\nThis quiz encourages you to do some quick internet searches to find out more about open-source software.\n1) Which of these is an open-source alternative to Microsoft Word?\n\n\n\n\nGoogle Docs\n\n\nPages\n\n\nLibreOffice Writer\n\n\n\n\n\n\n\n¬†\n2) Which of these is an open-source alternative to Microsoft Powerpoint?\n\n\n\n\nLibreOffice Impress\n\n\nGoogle Slides\n\n\nKeynote\n\n\n\n\n\n\n\n¬†\n3) Not only can software be open source, programming languages can, too. In fact, most modern programming languages are open source. In this book, we will focus on the open-source programming language R. Which of these is not an open-source programming language?\n\n\n\n\nMATLAB\n\n\nPython\n\n\nJavaScript\n\n\n\n\n\n\n\n¬†\n4) There are also many open-source operating systems. Which of these is an open-source alternative to the operating system Windows?\n\n\n\n\nMacOS\n\n\nUbuntu\n\n\niOS\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\nTask 1\n\n\n\nYour first practical task is to download and install the open-source software suite LibreOffice. This is important as we will use its spreadsheet editor, LibreOffice Calc, in the following two chapters.\n\n\nLibreOffice is available for Windows, Mac and Linux. You can download it from here: https://www.libreoffice.org/download/download-libreoffice/.\nDetailed installation instructions can be found here: https://www.libreoffice.org/get-help/install-howto/.\nOn the official LibreOffice website you can choose either:\n\nthe latest version for ‚Äútechnology enthusiast, early adopter or power user‚Äù\nor the ‚Äúslightly older‚Äù but more tested version.\n\nIn drafting this textbook, I used the latest version which, at the time, was version 24.2.2. The one that you download will be higher than that as the developers regularly publish updates. If you already have LibreOffice installed on your computer, now is a good time to check that your version is up-to-date.\nDetailed documentation is available in many different languages: https://documentation.libreoffice.org/en/english-documentation/\n\n\n\n\n\n\n\n\n\nGoing further\n\n\n\n\n\nIn this introductory textbook, we have simplified things considerably. To be considered open source, software distributions actually have to comply with ten criteria. You can read up on them here:\n\nhttps://opensource.org/osd\n\nTo find out more about the benefits of open-source software in the context of research, I recommend reading:\n\nhttps://book.the-turing-way.org/reproducible-research/open/open-source",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Open Schola`R`ship</span>"
    ]
  },
  {
    "objectID": "1_OpenScholarship.html#sec-OpenEducation",
    "href": "1_OpenScholarship.html#sec-OpenEducation",
    "title": "1¬† Open ScholaRship",
    "section": "1.3 Open Education",
    "text": "1.3 Open Education\nOpen Education is a key component of Open Scholarship (see Chapter 1). Open Education aims to stimulate collaborative teaching and learning and to provide high-quality Open Educational Resources (OERs) that are accessible for all.\nAs illustrated in Figure¬†1.1, OERs are licensed in such a way that everyone has the right to engage in ‚Äú5 Rs‚Äù when using OERs. The 5 Rs of OERs are:\n\nRetain - the right to make, own, and control copies of the content (e.g., download, duplicate, and store copies of an OER).\nReuse - the right to use the content in a range of ways (e.g., as teaching materials on a course, as part of a website, or in a video).\nRevise ‚Äì the right to adapt, adjust, modify, or alter the content itself (e.g., translate the content into another language, create a version for a different programming language).\nRemix ‚Äì the right to combine the original or revised content with other open materials to create something new.\nRedistribute ‚Äì the right to share copies of the original content, any revisions, and remixes with others (e.g., give a copy of the content to a friend).\n\n\n\n\n\n\n\nFigure¬†1.1: OER sketch note by Yvonne Stry\n\n\n\nOERs may be published under different licenses and, in engaging in the 5 Rs, the exact terms of an OER‚Äôs license must be respected. For example, the web-based version of this textbook is published as an OER under the Creative Commons license CC BY-NC-SA. This means that anyone can engage in the 5 Rs with it (i.e., users are free to read and use, edit, remix, and expand upon the textbook) as long as:\n\nthe original author and source is mentioned (hence you should specify who this resource is BY),\nany derived version is not made into a commercial product (NC stands for non-commercial), and that\nany derived versions of this textbook (e.g., a translated version or a version adapted for history scholars) are also shared with this same license (SA stands for share alike).\n\nIn line with the principles of Open Education, all of the datasets used as case studies in this textbook have been published in open access. We will analyse real data from published research studies in the fields of applied linguistics and language education to learn about data management, statistics, and data visualisation.\n\n\n\n\n\n\nQuiz time!\n\n\n\n5) Is it possible to reuse Figure¬†1.1 on a company website?\n\n\n\n\nYes, but you must mention the name of the artist.\n\n\nYes, but you must mention the image's sell-by date.\n\n\nYes, but only if it is the website of a non-profit company.\n\n\nYes, but only after having obtained written consent from the artist.\n\n\n\n\n\n\n\n¬†\n6) Which of these resources can be published as OERs?\n\n\n\n\nLesson plans\n\n\nCourse assessments\n\n\nTextbooks\n\n\nMassive Open Online Courses\n\n\nCourse syllabi\n\n\nHomework tasks\n\n\nSerious games\n\n\nLecture slides\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\nGoing further\n\n\n\n\n\nThere are thousands of high-quality Open Educational Resources (OERs) out there, yet few people are aware of them. OER databases are good starting points to start exploring OERs, e.g.:\n\nhttps://oercommons.org/\nhttps://www.twillo.de/oer/web/\n\nAppendix A also includes a list of recommended next-step OERs on data management, data analysis in R, statistics, data visualisation, Open Science, and reproducibility.\n\n\n\n\n\n\n\nBerez-Kroeker, Andrea L., Bradley McDonnell, Eve Koller & Lauren B. Collister. 2022. The open handbook of linguistic data management. MIT Press. https://doi.org/10.7551/mitpress/12200.001.0001.\n\n\nParsons, Sam, Fl√°vio Azevedo, Mahmoud M. Elsherif, Samuel Guay, Owen N. Shahim, Gisela H. Govaart, Emma Norris, et al. 2022. A community-sourced glossary of open scholarship terms. Nature Human Behaviour. Nature 6(3). 312‚Äì318. https://doi.org/10.1038/s41562-021-01269-4.\n\n\nThe Turing Way Community. 2022. The turing way: A handbook for reproducible, ethical and collaborative research (1.0.2). Zenodo. https://doi.org/10.5281/zenodo.3233853.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Open Schola`R`ship</span>"
    ]
  },
  {
    "objectID": "1_OpenScholarship.html#footnotes",
    "href": "1_OpenScholarship.html#footnotes",
    "title": "1¬† Open ScholaRship",
    "section": "",
    "text": "Empirical data is based on what is experienced or observed rather than on theory alone.‚Ü©Ô∏é\nProvided that they have access to the internet and a functioning personal computer.‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Open Schola`R`ship</span>"
    ]
  },
  {
    "objectID": "2_Data.html",
    "href": "2_Data.html",
    "title": "2¬† Data files and formats",
    "section": "",
    "text": "Chapter overview\nThis chapter first considers what data means in the context of language research, before turning to how these data are formatted and stored. You will learn about:\nAlong the way, you will get insights into an eye-tracking study involving cute Playmobil figures and a meta-science investigation that highlights the utmost importance of data literacy for research.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data files and formats</span>"
    ]
  },
  {
    "objectID": "2_Data.html#sec-DataLanguageSciences",
    "href": "2_Data.html#sec-DataLanguageSciences",
    "title": "2¬† Data files and formats",
    "section": "2.1 Data in the language sciences",
    "text": "2.1 Data in the language sciences\nIn this book, we are concerned with empirical research in the language sciences, in other words, with research that is based on the analysis of data. But what is data exactly? Data can be collected via surveys, measurements, or observations. To begin with, however, these collected datasets are ‚Äúraw‚Äù. Data only becomes information once we have analysed and interpreted the data in a meaningful way. Hence, just like uncooked pasta does not make a flavourful meal, we must learn to ‚Äúcook‚Äù the raw data to obtain meaningful information.\nWhat kind of data are analysed in the language sciences? To get a rough idea of the range of data types analysed in the language sciences, let us take a look at the IRIS database.\n\nIRIS is a collection of instruments, materials, stimuli, data, and data coding and analysis tools used for research into languages, including first, second, and beyond, and signed language learning, multilingualism, language education, language use, and language processing. Materials are freely accessible and searchable, easy to upload (for contributions) and download (for use). (2011)\n\nAs such, IRIS supports Open Science and Open Scholarship (see Chapter 1).\n\n\n\n\n\n\nTask 1\n\n\n\nIn this task and many future tasks, we will make use of the IRIS database.\n\nConnect to the IRIS website and navigate to its Search and Download page.\nScroll down to the filter option ‚ÄòData Type‚Äô.\nClick on ‚ÄòData Type‚Äô and browse through the different data types that are most commonly used in language-related research.\n\n\n\n\n\n\n\nFigure¬†2.1: Screenshot from the IRIS database search page (accessed on 17 April 2024)\n\n\n\na) For which kinds of studies could these different types of data have been collected? Think about both experimental and observational studies.\nb) Which of these data types is most likely to be measured in milliseconds (ms)?",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data files and formats</span>"
    ]
  },
  {
    "objectID": "2_Data.html#sec-ResearchData",
    "href": "2_Data.html#sec-ResearchData",
    "title": "2¬† Data files and formats",
    "section": "2.2 Types of research data",
    "text": "2.2 Types of research data\nGiven the wide range of methods used in language research, it is no surprise that they are so many different types of research data. Although the data types listed on the IRIS search page (see Figure¬†2.1 for extract) are very broad and the categories not clearly defined, the list illustrates the breadth of research data types typically analysed in language studies.\nThe first data type category, ‚ÄúOral production‚Äù, for instance, can equally refer to text transcriptions of language users‚Äô oral production, audio, or video files. It can also refer to either raw data or to (more or less) processed data. For example, a transcript of a conversation could have been automatically annotated for part-of-speech, meaning that every word would be marked for their word class (e.g., This_DT is_VBZ not_RB raw_JJ text_NN data_NN ._PUNC), or it could have been manually anonymised by adding placeholders (e.g., Is &lt;NAME&gt; going out with &lt;NAME&gt;?) indicating that certain words have been retracted for data protection reasons.\nThe second most frequent data type category, ‚ÄúClosed response format‚Äù, includes different kinds of questionnaires and tests. Questionnaires may ask study participants to disclose personal information relevant to the research questions using single or multiple-choice questions, such as what language(s) they use at home, how long they have studied a language for, or how old they are. Tests may be designed to assess participants‚Äô language competences (e.g., in the form of a vocabulary or grammar test), as well as other aspects relevant to the research questions being investigated (e.g., short-term memory or baseline reaction times).\nIn this book we will focus on the research processes that take place after the data have been collected. However, it is vital that we are aware of the conditions and context in which the data we are analysing were collected and pre-processed. It is no exaggeration to say that these steps in the research process can entirely change the results of the data analysis. Suppose we decide to compare the abilities of two groups of French L2 learners. To do this, we administered a language production test to two whole classes of secondary school students learning French as a second language using two different teaching methods. If one group had 15 minutes to complete the test and the other had up to 60 minutes, the results would not be comparable.\n\n\n\n\n\n\nQuiz time!\n\n\n\n1) Which other reasons could potentially jeopardise the comparison of test results data from two different groups of pupils?\n\n\n\n\nOne group having French lessons on Tuesday mornings, the other on Friday afternoons.\n\n\nThe two groups having different teachers.\n\n\nOne group having a classroom decorated with French flags and posters about France.\n\n\nOne group having a single native speaker of French, whilst the other has none.\n\n\nOne group having a higher proportion of pupils from migrant families.\n\n\nOne group having a higher proportion of pupils with reading difficulties.\n\n\n\n\n\n\n\n\n\nWhilst there are many ways to ensure that as many factors as possible are controlled for, not all can be controlled for. What is crucial is that all aspects of the data collection process are well documented so that all factors, whether controlled or not, can be taken into account when analysing the data.\nIn research, we usually distinguish between primary data, which is the data that you collected yourself, and secondary data, which is data that was collected by others. Hence if you were to carry out a new study based on data that you found on IRIS, you would be conducting a secondary data analysis. Especially when conducting secondary data analyses, it is crucial that we have enough information about the data itself, i.e.¬†metadata. Metadata is crucial for finding, sharing, evaluating, and reusing datasets. Metadata can be generated automatically and stored within the data file. For example, unless this metadata was explicitly deleted or amended, Microsoft Word files typically contain metadata describing who created the file, when it was first created, and when the file was last modified. For some data and projects, it also makes sense to create separate metadata files that contain additional or more detailed information about the collected data.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data files and formats</span>"
    ]
  },
  {
    "objectID": "2_Data.html#sec-FileExtensions",
    "href": "2_Data.html#sec-FileExtensions",
    "title": "2¬† Data files and formats",
    "section": "2.3 Data formats and file extensions",
    "text": "2.3 Data formats and file extensions\nDifferent data types come in different data formats. For audio files, you may be familiar with the MP3 format, but this is by no means the only format in which audio files can be saved. Many other audio file formats exist, such as Waveform Audio File Format (WAVE) and Free Lossless Audio Codec (FLAC).\nWe can usually tell in what format a file is in by looking at its file extension. The file extension is the suffix of the file name. It comes at the end of the file name and is preceded by a dot. The file extension of a WAVE file is .wav, whereas that of an MP3 file is .mp3; hence the file recording.wav is a WAVE file, whereas recording.mp3 is an MP3 file.\n\n\n\n\n\n\nQuiz time!\n\n\n\n2) In which format are Microsoft Word files typically saved?\n\n\n\n\n.msword\n\n\n.docs\n\n\n.odt\n\n\n.docx\n\n\n\n\n\n\n\n¬†\n3) Which of these files are audio files?\n\n\n\n\ndialogue001.mp3\n\n\ndialog_01.csv\n\n\n001_dialog.flac\n\n\ndialogue001.wav\n\n\nDIALOGUE.audio\n\n\n\n\n\n\n\nüòá Hover for a hint\n\n\n\n\n\n\nUnfortunately, many modern operating systems have a tendency to hide file extensions by default. This results in the files recording.wav and recording.mp3 both being displayed as recording in File Finder/Explorer windows (compare Figure¬†2.2 (a) and Figure¬†2.2 (b)). This is misleading and can lead to all kinds of problems.\n\n\n\n\n\n\n\n\n\n\n\n(a) Displaying file names without file extensions\n\n\n\n\n\n\n\n\n\n\n\n(b) Displaying file names with their extensions\n\n\n\n\n\n\n\nFigure¬†2.2: Demonstrating the importance of seeing file extensions.\n\n\n\nTo ensure that you can always see the extensions of the files on your computer in the File Explorer (on Windows) or the File Finder (on macOS), follow these instructions:\n\nOn Windows: https://www.howtogeek.com/205086/beginner-how-to-make-windows-show-file-extensions/.\nOn macOS: https://support.apple.com/en-gb/guide/mac-help/mchlp2304/mac (select the version of your operating system at the top of the page).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data files and formats</span>"
    ]
  },
  {
    "objectID": "2_Data.html#sec-Sharing",
    "href": "2_Data.html#sec-Sharing",
    "title": "2¬† Data files and formats",
    "section": "2.4 Sharing research data and materials",
    "text": "2.4 Sharing research data and materials\nIn line with the principles of Open Science (see Chapter 1), it is important to ensure that both the materials that were used to collect research data (e.g., questionnaire items, audio, image or video stimuli, language aptitude tests, etc.) and the data themselves are made openly available to the research community, whenever legally possible and ethically responsible. Sharing materials ensures that studies can be replicated, for example with new participants or in a different language. Sharing research data also allows independent researchers to reproduce the results of studies, allowing them to verify the reported results and to conduct additional analyses that may confirm, contradict, or extend the conclusions of the original studies.\nYou may be wondering how linguists and language education researchers can make their research data and materials publicly available. Table¬†2.1 provides a non-exhaustive list of public repositories where researchers can upload research data and materials (with figures collected in early June 20241). Some are specific to the language sciences, while others cater to all research disciplines. If you completed the first task in Section 2.1, you should already be familiar with at least one of these! üòâ All of the examples, tasks, and exercises in this book are based on research data and materials that researchers have made available in open access on one or more of these repositories.\n\n\n\n\nTable¬†2.1: Non-exhaustive list of public repositories of research data and materials.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepository\nDiscipline\nNb. of entries\nProvides DOI\nOnline since\n\n\n\n\nDryad\nAll\n60000\nYes\n2008\n\n\nFigshare\nAll\n8000000\nYes\n2012\n\n\nHAL\nAll\n5000000\nNo\n2001\n\n\nHarvard Dataverse\nAll\n160000\nYes\n2006\n\n\nIRIS\nLinguistics\n3500\nNo\n2011\n\n\nOpen Science Repository, OSF\nAll\n153663\nYes\n2012\n\n\nTroms√∏ Repository of Language and Linguistics, TROLLing\nLinguistics\n4500\nYes\n2014\n\n\nVivil\nClinical research\n7000\nYes\n2013\n\n\nZenodo\nAll\n3750000\nYes\n2013\n\n\n\n\n\n\n\n\n\nIn the following tasks, we will look at a study by Schimke et al. (2018) (see Figure¬†2.3 (a)), which is an example of a publication which was awarded the Open Data and the Open Materials badges (see Figure¬†2.3 (b)). This means that the research materials and data associated with this study can be found in an open, online repository:\n\n‚ÄúThis article has been awarded Open Materials and Open Data badges. All materials and data are publicly accessible via the IRIS Repository at https://www.iris-database.org/iris/app/home/detail?id=york:934337. Learn more about the Open Practices badges from the Center for Open Science: https://osf.io/tvyxz/wiki‚Äù Schimke et al. (2018).\n\nThe authors could have chosen to upload their materials and data to any of the online repositories listed in Table¬†2.1 but, in this case, they chose IRIS.\n\n\n\n\n\n\n\n\n\n\n\n(a) Title page of the Schimke et al. (2018)\n\n\n\n\n\n\n\n\n\n\n\n(b) The Open Data and Open Materials badges\n\n\n\n\n\n\n\nFigure¬†2.3: An example of a publication for which both research materials and data have been published.\n\n\n\nAmong other results, Schimke et al. (2018) report on two eye-tracking experiments. One of these experiments involved Spanish-speaking participants listening to ambiguous sentences in Spanish whilst looking at images of Playmobil figures (see Figure¬†2.4 for an example).\n\n\n\n\n\n\nFigure¬†2.4: Image from Experiment 1 in Schimke et al. (2018)\n\n\n\n\n\n\n\n\n\nNote¬†2.1: How did the experiment work?\n\n\n\nIn this eye-tracking experiment, participants were instructed to decide whether the sentences they heard matched the Playmobil images or not. Consider the following two sentences from the experiment:\n\n\nEl barrendero se encontr√≥ con el cartero antes de que recogiera las cartas.\n[The street sweeper met the postman before he fetched the letters.]\nEl barrendero se encontr√≥ con el cartero antes de que recogiera la escoba.\n[The street sweeper met the postman before he fetched the broom.]\n\n\nUp until the point at which either las cartas [the letters] or la escoba [the broom] are heard, it is unclear who is doing the fetching. From a grammatical point of view, it could be either the street sweeper or the postman.\nParticipants were presented with Figure¬†2.4 as they were listening to either Sentence 1 or Sentence 2. At the same time, the researchers measured how long it took for the participants to look at the subject governing the verb recogiera. In other words, for Sentence 1, they were interested in how long it took participants to focus on the postman Playmobil figure and, in Sentence 2, on the street sweeper. Such fine measurements are made in milliseconds, i.e.¬†in thousandths of seconds, using a special eye-tracking device.\n\n\n\n\n\n\n\n\nTask 2\n\n\n\nImagine that you want to run an experiment similar to the one carried out in Schimke et al. (2018). You can reuse the Playmobil image files created by the researchers as they helpfully uploaded them to the IRIS database.\nIn which file format do you think the images are archived? To find out, click here to go directly to the list of data and materials associated with the study. There are four entries in the IRIS database that are associated with this study. Select the ‚ÄúPictorial‚Äù entry which contains the images. It allows you to download a ZIP file called Images_online.zip. ZIP is an archive file format that can contain one or more compressed files. Download this ZIP file.\nOnce the download was successful, navigate to the folder where the file was saved on your computer and unzip the file, i.e., decompress it and extract its contents:\n\nTo unzip on Windows, double-click the .zip file\n\nselect ‚ÄòExtract All‚Äô,\nselect a folder,\nand then click ‚ÄòExtract‚Äô.\n\nOn a Mac, simply double-click the .zip file to unzip it.\nIf you are using the Linux command line, use the command unzip followed by the name of the file to unzip it.\n\nYou should find that the ZIP file contains a folder entitled ‚ÄòImages‚Äô, which contains 58 pictures of different combinations of Playmobil figures that correspond to the experiment‚Äôs stimulus sentences.\n1a) In which file format are these Playmobil image files?\n\n\n\n\nBMP\n\n\nGIMP\n\n\nJPEG\n\n\nPNG\n\n\nGIF\n\n\n\n\n\n\n\n¬†\nImage files typically contain metadata that is embedded in the image files themselves. This metadata may include the dimensions of the image and its colour profile. To view this metadata, right-click on one of the image files that you have extracted from the ZIP file and select the option to get more information about the file, e.g., ‚ÄúGet Info‚Äù or ‚ÄúProperties‚Äù.\n1b) How wide are these Playmobil images in pixel?",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data files and formats</span>"
    ]
  },
  {
    "objectID": "2_Data.html#working-with-tabular-data",
    "href": "2_Data.html#working-with-tabular-data",
    "title": "2¬† Data files and formats",
    "section": "2.5 Working with tabular data",
    "text": "2.5 Working with tabular data\nThe measurements made by the eye-tracking device in Schimke et al. (2018)‚Äôs eye-tracking experiments were stored in the form of tables. Table¬†2.2 is an extract of a table that contains processed eye-tracking data from Schimke et al. (2018). It forms part of the study‚Äôs supplementary materials and can also be downloaded from the IRIS database.\nIn this table, each row corresponds to the data associated with one participant‚Äôs eye movements while listening to a single stimulus sentence and looking at the corresponding Playmobil image (e.g., Figure¬†2.4). The extract displayed as Table¬†2.2 only shows the data associated with the first six stimulus sentences (items) that participant ‚Äús1‚Äù, a Spanish L2 learner, listened to. The columns crit1, crit2 and crit3 contain values derived from the measurements made using the eye-tracking device.2 From Table¬†2.2, we can also see that participant ‚Äús1‚Äù was 19 years old when they started formally learning Spanish (AoO stands for ‚Äúage of onset of formal instruction‚Äù) and that they were 20 when the experiment was conducted.\n\n\n\n\nTable¬†2.2: Extract of table containing eye-tracking data from Schimke et al.¬†(2018)'s appendix\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlanguage\nsubject\ndisambiguation\nitem\ncrit1\ncrit2\ncrit3\nAoO\nage\n\n\n\n\nS\ns1\n1\n1\n0.3451355\n-0.5618789\n0.7036070\n19\n20\n\n\nS\ns1\n2\n2\n-0.2679332\n-1.5849625\n0.1852149\n19\n20\n\n\nS\ns1\n1\n3\n-1.1563420\n0.9898042\n-1.5849625\n19\n20\n\n\nS\ns1\n2\n4\n-1.5849625\n-0.0874628\n-1.5849625\n19\n20\n\n\nS\ns1\n1\n5\n1.5849625\n0.1831223\n1.5849625\n19\n20\n\n\nS\ns1\n2\n6\n-0.7824086\n-0.8548021\n-1.1758498\n19\n20\n\n\n\n\n\n\n\n\n\nWhen working with data, tables are ubiquitous. Data stored in tables are called tabular data. Hence, learning to work with tabular data is a crucial data literacy skill.\nIn the language sciences, the results of most studies (whether experimental or corpus studies) are stored in tables. For example, when researchers conduct an online survey, the data collected by the online survey platform (e.g., Qualtrics, SoSci, SurveyMonkey) is automatically stored in the form of one or more table(s). These can then be exported from the survey platform in various tabular file formats (e.g., .csv, .json, .xlsx).\nIn some cases, data may be collected by analogue means, e.g., by getting participants to answer a paper questionnaire or collecting school children‚Äôs work on paper. However, for quantitative analysis, analogue research data are first digitalised. Then, the data are typically stored as text files in file formats such as .txt or .csv.\n\n2.5.1 Delimiter-separated values (DSV) files\nTables can be stored in many data formats but the simplest and most widely used in linguistic research are text files with delimiter-separated values (DSV). For sharing and archiving research data, DSV files are favoured over formats specific to propriety software such as .xslx (Microsoft Excel files) or .numbers (Apple Numbers files). This is because DSV files can be ‚Äúunderstood‚Äù by many different programs and on all operating systems. The fact that they are simple text files means that we will also be able to reliably read them in the future, even if programs such as Excel or Numbers have evolved or have been discontinued. Reliability and compatibility are fundamental to maintaining the integrity of research data and ensuring that data can be reused, even in the distant future.\nIn DSV files, each value (e.g., measurement or response) is separated by a specific separator character. In principle, any character can be used to separate values, but the most common separators are the comma (,), tab (\\t), and colon (:). Below is the .csv file corresponding to Table¬†2.1.\nRepository,Discipline,Nb. of entries,Provides DOI,Online since\nDryad,All,60000,Yes,2008\nFigshare,All,8000000,Yes,2012\nHAL,All,5000000,No,2001\nHarvard Dataverse,All,160000,Yes,2006\nIRIS,Linguistics,3500,No,2011\n\"Open Science Repository, OSF\",All,153663,Yes,2012\n\"Troms√∏ Repository of Language and Linguistics,TROLLing\",Linguistics,4500,Yes,2014\nVivil,Clinical research,7000,Yes,2013\nZenodo,All,3750000,Yes,2013\nAs you can see, the values are separated by commas.3 Additionally, some of the values are enclosed in, or delimited by, double quotation marks (\"). This prevents any commas that may occur within an actual field value, e.g., the comma in the field Open Science Repository, OSF, from being interpreted as a separator character.\nGiven that DSV files are text files, it is possible to open them in a free plain-text editor (e.g., Notepad++ or BBEdit) or a text-processing program (e.g., Microsoft Word or LibreOffice Writer). However, these programmes will typically display DSV files as in Figure¬†2.5.\n\n\n\n\n\n\nFigure¬†2.5: The .csv file corresponding to Table¬†2.1 opened in Word\n\n\n\nWe can probably agree that what we are seeing in Figure¬†2.5 is not a very reader-friendly way to display tabular data! This is why DSV files are more often opened in spreadsheet programs (e.g., LibreOffice Calc, Google Sheets, Microsoft Excel, Numbers) than in text-editing programs. Let‚Äôs find out how in the next section.\n\n\n2.5.2 Opening DSV files in LibreOffice Calc\nThere are several ways to open a DSV file in LibreOffice Calc but the safest is to launch LibreOffice (see Task 1 in Section 1.2 if you have not yet installed LibreOffice) and, from the list of options under ‚ÄòCreate‚Äô, click on ‚ÄòCalc Spreadsheet‚Äô to open up a blank spreadsheet. Then, from the ‚ÄòFile‚Äô drop-down menu, select ‚ÄòOpen‚Ä¶‚Äô or use the keyboard shortcut Ctrl/Cmd + O and locate the DSV file that you wish to open.\nOn opening a DSV file in LibreOffice Calc, we get a dialogue box with various options (see Figure¬†2.6).\n\n\n\n\n\n\nFigure¬†2.6: Text import dialogue in LibreOfficeCalc\n\n\n\nTo correctly import this particular DSV file, it is necessary to specify that the separator character is the comma (,) and that the delimiter character is the double quotation mark (\") (see selected options in Figure¬†2.6). With these settings in LibreOffice Calc, the table is rendered as in Figure¬†2.7.\n\n\n\n\n\n\nFigure¬†2.7: CSV file opened in LibreOffice Calc\n\n\n\nNote that if you open a DSV file in Excel or Google Sheets, you will not be shown such a dialogue box. Instead, these programs assume that they can guess which separator and delimiter characters your file uses. Whilst this may, at first, sound convenient, this is not good news: you should be the one in control of how your data files are interpreted, not the program! In the next section, you will learn why opening DSV files such as .csv and .tsv files in Microsoft Excel, Google Sheets, or Numbers can be very dangerous. In some cases, these programs will ‚Äòcorrupt‚Äô, i.e.¬†permanently damage, your DSV files, which can lead to irreversible data loss!\nThe bad news is that, if you are using Windows or MacOS, it is very likely that either Excel or Numbers is your default app to open DSV files. This means that if you double click on a .csv and .tsv file in your Finder/Explorer window, the file will likely automatically open up in either Excel or Numbers. This is why it is important you do not double-click on such files to open them: Opening a file just once with these programs can lead to data loss! If this happens to you with a file that you have downloaded from a repository, your best bet is to delete your local version of the file and download a fresh version so that you can start again from scratch.\n\n\n\n\n\n\nTask 3\n\n\n\nIn this task, we will practice opening a DSV file in LibreOffice Calc. Our example file is a real dataset from Schimke et al. (2018). We will begin by downloading it from the public repository IRIS.\nIn addition to the eye-tracking experiments, Schimke et al. (2018) conducted two further experiments in which participants completed a gap-filling task via an online survey platform. In the first of these experiments, the participants were native (L1) speakers of French, German, and Spanish. In the second, they were French- and Spanish-speaking learners (L2) of German.\nIn both experiments, the L1 and L2 participants were shown ambiguous sentences similar to the ones used in the eye-tracking experiment with the Playmobil images (see Note¬†2.1). After having read each stimulus, the participants were asked to complete a gap-fill task according to their understanding of the preceding ambiguous sentence. Participants were told ‚Äúthat there were no incorrect responses and that they should answer spontaneously‚Äù (Schimke et al. 2018: 755). Below is an example questionnaire item in the three languages examined:\n\n\n1. Der Brieftr√§ger ist dem Stra√üenfeger begegnet, bevor er schnell ein Sandwich geholt hat. ___________________ hat ein Sandwich geholt.\n2. Le facteur a rencontr√© le balayeur avant qu‚Äôil prenne rapidement un sandwich. ___________________ a pris un sandwich.\n3a. El cartero se reuni√≥ con el barrendero antes de que √©l recogiera velozmente un emparedado. ___________________ recogi√≥ un emparedado.\n3b. El cartero se reuni√≥ con el barrendero antes de que recogiera velozmente un emparedado. ___________________ recogi√≥ un emparedado.\n\n\nNote that, for Spanish, there were two types of stimuli: one with an overt pronoun (as in 3a. with √©l) and one without (as in 3b. with a null pronoun), as both variants are possible in Spanish. All three examples translate as:\n\n\nThe postman encountered the street sweeper before he quickly fetched a sandwich. ___________________ fetched a sandwich.\n\n\nTo complete the gap, participants could either select ‚ÄòThe postman‚Äô or ‚ÄòThe street sweeper‚Äô.\n\nGo back to the study‚Äôs page on IRIS and select the second entry entitled ‚ÄòOther questionnaire‚Äô which, among other things, contains ‚ÄòWritten production data‚Äô.\n\nNote that this database entry includes both research data and research materials: the file sentences_offline_task.xlsx contains the full list of questionnaire items, including both experimental and filler items, with which we could reconstruct the experiment to replicate it with a new set of participants. For now, however, we are not interested in obtaining materials to replicate the study, but rather in examining the study‚Äôs original data.\nThis IRIS entry also contains three data files. The last file (logoddslearnersfinal.txt) is the DSV file that was used to create Table¬†2.2 above.\nIn this task, we are going to look at the questionnaire data corresponding to the gap-filling task experiment conducted with German L2 learners, which is contained in the data file offlinedataLearners.txt:\n\nDownload the offlinedataLearners.txt file (which is the second listed) and save it on your computer (see Section 3.3).\nLaunch LibreOffice (see Section 1.2 if you have not yet installed LibreOffice) and, from the list of options under ‚ÄòCreate‚Äô, click on ‚ÄòCalc Spreadsheet‚Äô to open up a blank spreadsheet.\nFrom the ‚ÄòFile‚Äô drop-down menu, select ‚ÄòOpen‚Ä¶‚Äô or use the keyboard shortcut ‚ÄòCtrl/Cmd + O‚Äô. Find offlinedataLearners.txt in the folder where you saved it and click on ‚ÄòOpen‚Äô.\nA ‚ÄòText Import‚Äô dialogue box will pop up. This a DSV file, not a fixed-width file, so ensure that the option ‚ÄòSeparated by‚Äô is selected. If not already set by default, it is also a good idea to select ‚ÄòUnicode (UTF-8)‚Äô for the ‚ÄòCharacter set‚Äô.\nExperiment with the different ‚ÄòSeparator Options‚Äô until the preview at the bottom of the dialogue box looks like a table.\nEnsure that, apart from the ‚ÄòSeparator Options‚Äô, all other options in the dialogue box are unselected and then click on ‚ÄòOK‚Äô.\n\n\nQuiz time!\na) What is the separator character in the file offlinedataLearners.txt?\n\n\n\n\nTab\n\n\nComma\n\n\nSemicolon\n\n\nSpace\n\n\nAll of them\n\n\n\n\n\n\n\n¬†\nb) What is the delimiter character in the file offlinedataLearners.txt?\n\n\n\n\nBoth \" and '\n\n\n'\n\n\n\"\n\n\nThere is none.\n\n\n\n\n\n\n\n¬†\nc) How many observations does the file offlinedataLearners.txt contain?\n\n\n\n\n700\n\n\n3500\n\n\n5\n\n\n3505\n\n\n701\n\n\n\n\n\n\n\n¬†\nd) In this table, what does each observation correspond to?\n\n\n\n\nA single participant's response to a single sentence gap.\n\n\nAll the responses in a single language.\n\n\nAll the responses to a single sentence in a single language.\n\n\nAll the responses from a single participant.\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\nWhat if I absolutely have to open a DSV file in Excel? üòß\n\n\n\n\n\nIf you absolutely must open a DSV file (e.g., a .csv or .tsv file) in Excel (for example because you do not have sufficient permissions to install LibreOffice on the computer that you are using), do not open the file by double clicking on the file as this will automatically trigger Excel‚Äôs problematic auto-formatting behaviour (see Section 2.6)! Instead, first launch Excel and create a new blank workbook. Then navigate to the ‚ÄòData‚Äô tab, select the ‚ÄòGet Data‚Äô option, and then ‚ÄòFrom Text/CSV‚Äô (see Figure¬†2.8). In the following dialogue, you can specify how the data should be imported. The options are very similar to the ones offered in LibreOffice (see above).\nNote that with this method it may be possible to prevent Excel from automatically (and irreversibly!) applying transformations to your data. However, sadly, this may not suffice. Read on to find out more‚Ä¶\n\n\n\n\n\n\nFigure¬†2.8: Import data into excel",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data files and formats</span>"
    ]
  },
  {
    "objectID": "2_Data.html#sec-ExcelWarning",
    "href": "2_Data.html#sec-ExcelWarning",
    "title": "2¬† Data files and formats",
    "section": "2.6 A word of warning about spreadsheet programs ‚ö†Ô∏è",
    "text": "2.6 A word of warning about spreadsheet programs ‚ö†Ô∏è\nYou should be aware that opening DSV files in spreadsheet programs can corrupt the files! Once a file is corrupted, it is often not possible to retrieve the original data so this is very bad news, indeed. Such problems are particularly frequent when opening DSV files with Microsoft Excel and Google Sheets. This is because the default settings in these programs surreptitiously modify files upon opening.\nThese ‚Äòauto-format‚Äô modifications include replacing certain values by dates (e.g., changing 3-4 to March, 4th) or numbers (e.g., changing 1.23E5 to 123000)4, removing leading zeros (e.g., changing 001 to 1), or misinterpreting certain characters (e.g., the value -ism will generate an error because the hyphen is interpreted as minus sign).\nNot only can these auto-format modifications lead to inaccurate data analysis but, in the worst of cases, they can even cause data loss. The crux of the problem is that often users do not realise what the program has done in the background. How bad can this be? Find out by completing the task below.\n\n\n\n\n\n\nTask 4\n\n\n\nIn this task, you will find out how genetics researchers who use spreadsheets for their analyses regularly have their data so badly damaged that it affects the results of their publication. Though we have no statistics on how spreadsheet errors affect the work of linguists, it is (unfortunately) very likely to be just as bad as in genetics.\nZiemann, Eren & El-Osta (2016) reported that a fifth of genetics publications with supplementary .xls or .xlsx files with gene lists contained errors caused by Excel‚Äôs auto-formatting behaviour. The results of this study shocked the research community and a report about it went viral. Click on the link below to read the open-access article ‚ÄúGene name errors: Lessons not learnt‚Äù by Abeysooriya et al. (2021) to find out whether the situation has improved since 2016 and answer the questions below.\n\nAbeysooriya, Mandhri, Megan Soria, Mary Sravya Kasu & Mark Ziemann. 2021. Gene name errors: Lessons not learned. PLOS Computational Biology. Public Library of Science 17(7). e1008984. https://doi.org/10.1371/journal.pcbi.1008984.\n\na) Has the proportion of genetics publications with Excel gene lists affected by auto-formatting errors decreased since 2016?\n\n\n\n\nNo, it increased between 2016 and 2020.\n\n\nNo, it has remained stable.\n\n\nYes, it decreased between 2016 and 2020.\n\n\n\n\n\n\n\n¬†\nb) Does using LibreOffice Calc (see Section 1.2) also cause these same issues?\n\n\n\n\nNo, if you cannot afford Excel, then LibreOffice Calc is an excellent open-source alternative.\n\n\nYes, LibreOffice is just as likely to cause such errors.\n\n\nNo, but whilst LibreOffice is better than Excel or Google Sheets, it is still less than ideal for data analysis.\n\n\n\n\n\n\n\n¬†\nc) Did highly reputable journals publish fewer articles with erroneous Excel gene lists?\n\n\n\n\nNo, publications with problematic Excel files were found in more or less equal proportions in all journals.\n\n\nYes, they published fewer.\n\n\nNo, they published more.\n\n\n\n\n\n\n\n¬†\n\n\nIt is worth noting that, for some Windows users, these auto-formatting issues can corrupt files that they have never actively opened in Excel! ü§Ø This happens when Windows applies Excel‚Äôs default settings to all CSV files, regardless of what program they are actually opened with. To ensure that this does not happen to you, check that Excel is definitely not your default app to open .csv and .tsv files (see below for instructions).\n\n\n\n\n\n\nOpening a .csv or .tsv file in LibreOffice from a File Finder/Explorer window\n\n\n\n\n\nRemember that to open a .csv or .tsv file on your computer, should never ever double-click on it and let the default program open it! As we saw in Section 2.6, this can break or ‚Äòcorrupt‚Äô the file. To avoid accidentally double-clicking on a .csv or .tsv file and having the file corrupted, I recommend making either LibreOffice or a plain-text editor (e.g., Notepad++ or BBEdit) your default application to open up such files.\nOn MacOS, you can change the default application used to open files of any file extensions by right-clicking a file name with this particular extension and than selecting ‚ÄòGet Info‚Äô (Figure¬†2.9 (a)). In the example below, Numbers is the default application for all .csv files (see Figure¬†2.9 (b)). In the dropdown menu ‚ÄòOpen with:‚Äô, you can then select LibreOffice (provided you have installed it beforehand!) and finally click on ‚ÄòChange All‚Ä¶‚Äô (Figure¬†2.9 (c)). You will be asked to confirm your choice.\n\n\n\n\n\n\n\n\n\n\n\n(a) ¬†\n\n\n\n\n\n\n\n\n\n\n\n(b) ¬†\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) ¬†\n\n\n\n\n\n\n\nFigure¬†2.9: Changing the default application for a file extension on MacOS\n\n\n\nIf your operating system is Windows, you should look in your Windows‚Äô settings for the option ‚ÄòDefault Apps‚Äô (see Figure¬†2.10).\n\n\n\n\n\n\nFigure¬†2.10: Default apps in Windows settings\n\n\n\nIn the next step, select ‚ÄòChoose default apps by file type‚Äô. Here, you can search for .csv as a file type, and choose which program you want to set as the default program for opening .csv files. If Excel is currently your default (as in Figure¬†2.11 (a)), you can click on Excel and choose a different program. LibreOffice is a sensible, open-source alternative (see Figure¬†2.11 (b)). A plain-text editor such as Notepad would also be fine (also listed on Figure¬†2.11 (b)).\n\n\n\n\n\n\n\n\n\n\n\n(a) Excel as the default programme for .csv files\n\n\n\n\n\n\n\n\n\n\n\n(b) Changing the default programme for .csv files\n\n\n\n\n\n\n\nFigure¬†2.11: Changing the default app for opening .csv files in Windows\n\n\n\nIf it is not possible to adjust the default app settings, either due to insufficient permissions or because you only have temporary access to this PC, do not to open .csv or .tsv files with the default program. Instead, right-click on the file name and, using the ‚ÄòOpen with‚Äô option, select the option to open the file with LibreOffice, if available, or else with a plain-text editor.\n\n\n\n\n\n\n\n2011. IRIS. https://iris-database.org/.\n\n\nAbeysooriya, Mandhri, Megan Soria, Mary Sravya Kasu & Mark Ziemann. 2021. Gene name errors: Lessons not learned. PLOS Computational Biology. Public 17(7). e1008984. https://doi.org/10.1371/journal.pcbi.1008984.\n\n\nSchimke, Sarah, Israel de la Fuente, Barbara Hemforth & Saveria Colonna. 2018. First language influence on second language offline and online ambiguous pronoun resolution. Language Learning 68(3). 744‚Äì779. https://doi.org/10.1111/lang.12293.\n\n\nZiemann, Mark, Yotam Eren & Assam El-Osta. 2016. Gene name errors are widespread in the scientific literature. Genome Biology 17(1). 177. https://doi.org/10.1186/s13059-016-1044-7.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data files and formats</span>"
    ]
  },
  {
    "objectID": "2_Data.html#footnotes",
    "href": "2_Data.html#footnotes",
    "title": "2¬† Data files and formats",
    "section": "",
    "text": "Note that, for some repositories, the number of entries includes other types of research outputs, e.g., preprints and figures.‚Ü©Ô∏é\nDetails of what these values mean are not relevant here but, for those of you who are curious, they correspond to the ‚Äúlog odds of looks‚Äù that participant made towards one or the other Playmobil figure whilst listening to the experimental stimulus sentences at three time points, called ‚Äúcritical regions‚Äù. These critical regions include the time window between the onset of the pronoun and 480 milliseconds after the onset of the disambiguating information. Schimke et al. (2018: 768‚Äì769) explain that ‚Äú[a] positive value of the log odds indicates more looks to the subject than to the object antecedent, while a negative value indicates the reverse pattern.‚Äù‚Ü©Ô∏é\nNote that the file extension .csv stands for ‚Äúcomma-separated values‚Äù. Confusingly, however, DSV files are often given a .csv extension even when the separator character is not the comma. As a result, even though the .tsv extension stands for ‚Äútab-separated values‚Äù, .csv files are frequently separated by a tab (\\t) rather than comma. Isn‚Äôt that fun? üôÉ‚Ü©Ô∏é\nIn scientific notation, ‚ÄúE‚Äù stands for ‚Äúexponent‚Äù, which refers to the number of times a number needs to be multiplied by 10. This notation is used as a shorthand way of writing very large or very small numbers. This is why ‚Äú1.23E5‚Äù is interpreted by Excel as 1.23 multiplied by 10 to the power of 5, which is to say: 1.23 multiplied by 100,000. This operation shifts the decimal point five places to the right, resulting in the number 123000.‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data files and formats</span>"
    ]
  },
  {
    "objectID": "3_DataManagement.html",
    "href": "3_DataManagement.html",
    "title": "3¬† Data management",
    "section": "",
    "text": "Chapter overview\nEven if you are confident that you have no trouble managing your computer files, it is still worth taking a few minutes to read up on the basics of data management. This is especially true if you consider yourself a ‚Äúdigital native‚Äù as modern operating systems have made the way that computers deal with files very opaque.\nIn this chapter, you will learn about:",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "3_DataManagement.html#recipes-for-successful-data-management-masterchef-meets-masters-thesis",
    "href": "3_DataManagement.html#recipes-for-successful-data-management-masterchef-meets-masters-thesis",
    "title": "3¬† Data management",
    "section": "3.1 Recipes for successful data management: MasterChef meets Master‚Äôs Thesis",
    "text": "3.1 Recipes for successful data management: MasterChef meets Master‚Äôs Thesis\nData management is hardly a ‚Äúhot‚Äù topic that people like to dwell on. That‚Äôs a shame because good file management is absolutely central to be able to conduct research and poor file management has the potential to seriously ‚Äòspice things up‚Äô‚Ä¶ but not in a good way! üå∂Ô∏è Whether you are working on a short course assignment, your Master‚Äôs or PhD thesis, or as part of a large research project team: research-related files must be named appropriately and safely stored in meaningful places.\nImagine trying to make a curry in an utterly disorganised kitchen that contains dozens of different spices, scattered across different cabinets and drawers, with vague or misleading labels. For example, you might have three jars labelled ‚ÄúChilli‚Äù and no way of knowing which is mild ‚ÄúKashmiri Chilli‚Äù as opposed to the extra hot ‚ÄúThai Bird‚Äôs Eye Chilli‚Äù. The third might not be chilli at all, but actually a jar of paprika that has been entirely mislabelled. Some of these spices have been gathering dust for decades but the labels have no best-before dates so there is no way of knowing which are still fragrant. Cooking in such a kitchen would turn even the simplest cooking task into a tedious, time-consuming, and error-prone chore: If you‚Äôre not extremely careful, you could easily end up serving something that is bland or, in the worst of cases, entirely inedible! Similarly, in research, if your files are poorly named or stored haphazardly, it will make your work far less efficient, considerably more error-prone, and ultimately utterly frustrating.\nBut the good news is: just as a tidy, well-organized kitchen can greatly enhance your cooking experience, good file management can streamline your research process, help you avoid making mistakes, and reduce stress. In the following sections, we will cook up some good practices for file naming, data management, and project organisation. We will start with basic recipes for naming and managing your files. See the ‚ÄòGoing further‚Äô boxes for tips on learning the ‚Äògourmet skills‚Äô needed to handle more complex projects. So, let‚Äôs don the chef‚Äôs hat and learn how to create a user-friendly computer workspace. And remember, as with cooking, practice makes perfect! üßëüèΩ‚Äçüç≥",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "3_DataManagement.html#sec-FileNaming",
    "href": "3_DataManagement.html#sec-FileNaming",
    "title": "3¬† Data management",
    "section": "3.2 Naming conventions",
    "text": "3.2 Naming conventions\nFile names are labels. They tell us what is inside a file and helps us identify the correct file quickly and reliably. If you had to run to the printing shop to get your thesis printed in time for a tight deadline, which of these sets of files would you rather have to choose from? Which is more likely to lead you to getting the wrong version printed?\n\n\n\n\n\n\n\n\n\n\n\n(a) ¬†\n\n\n\n\n\n\n\n\n\n\n\n(b) ¬†\n\n\n\n\n\n\n\nFigure¬†3.1: Two sets of file names, one clearly better than the other.\n\n\n\nLike the labels on your neatly organised spice jars, file and folder names should be clear, concise, and easily readable. Good file and folder names should be both human-friendly and computer-friendly.\nBy human-friendly we mean that you and any other human being should easily be able to understand what a folder or file contains. Just like you wouldn‚Äôt want a label on a spice jar to be a random string of numbers (e.g., 0171) or only include the best-before date but nothing else (e.g., 31 Jan 2028), you also wouldn‚Äôt want to guess what a file contains based on an ambiguous or unclear name like Chili. Labels should be informative but succinct (e.g., Thai Bird's Eye Chilli 31 Jan 2028 not Thai Bird's Eye Chilli bought on December 19, 2023 whilst Christmas shopping with mum, note that the best before date is 31 January 2028)! Unless you and all your colleagues read Thai, do not be tempted to write the part of the file name in Thai as this could also lead to misunderstandings.\nAnother reason for not including Thai characters in your file name is that it would not be computer-friendly. In general, computers are not good at dealing with names that contain anything else but Latin alphanumeric characters, e.g., the letters A to Z and a to z with no accents and the numbers 0 to 9. Hyphens (-) and underscores (_) can also be used, but not spaces. The dot (.) is reserved for the file extension and should ideally not be used elsewhere in the file name.\nHence, whilst Thai Bird's Eye Chilli 31 Jan 2028 is human-friendly, it is not computer-friendly. To make it a computer-friendly label, we need to remove the apostrophe. Whilst spaces are not strictly forbidden, they can cause all kinds of issues and are therefore also best avoided. Space characters can be replaced by hyphens (-) and underscores (_) and the two can be combined in a meaningful way. For example, in the label Thai-Birds-Eye-Chilli_31-Jan-2028, the _ distinguishes between two different pieces of information, whilst the - helps humans to parse individual words within a piece of information. Using such patterns consistently not only helps humans to read file names efficiently, it also means that computers can easily ‚Äòparse‚Äô, i.e., break down such names into meaningful items. This can be very useful to search for files or automatically extract metadata from file names.\n\n\n\n\n\n\nFigure¬†3.2: To help us remember the different, systematic ways to use letter case, hyphens, and underscores in naming conventions, these patterns have fun names (art work by @allison_horst).\n\n\n\nIt is fine to use both lower-case and upper-case letters in file and folder names. However, some operating systems will treat upper-case and lower-case letters as the same, whilst others will not. This means that you should avoid having file names that are only distinguishable by case.\nFinally, it is worth noting that file names cannot be infinitely long! The maximum length of a file name depends on the operating system and the application that you use1 but, as a rule of thumb, if you can display the entire file name in a reasonably sized Finder window (on macOS) or File Explorer window (on Windows), its length is unquestionably both human- and computer-friendly.\n\n\n\n\n\n\nQuiz time!\n\n\n\n1) In which case is this file name? my_first_file_name.R\n\n\n\n\ncamelCase\n\n\nkebab-case\n\n\nUpperCamel\n\n\nlower_snake\n\n\nUPPER_SNAKE\n\n\n\n\n\n\n\n¬†\n2) Why is this file name problematic? MyDocument final.1a.docx\n\n\n\n\nMixed capitalisation\n\n\nLack of clarity\n\n\nUse of special character other than _ or -\n\n\nSpaces in file name\n\n\n\n\n\n\n\n¬†\n3) Which of these file names are both human-friendly and computer-friendly?\n\n\n\n\nAnalysis_24April.R\n\n\n05.01.24_Draft.docx\n\n\nMANUSCRIPT_CORRECTIONS.docx\n\n\nMC1.png\n\n\n2024-01-05_TermPaper.docx\n\n\n\n\n\n\n\n\n\nIt is also important to ensure that file names are easily sortable. If you have a series of files that document a process, consider beginning each file name with a number that correspond to the order of the process, e.g., 01_DataPreparation.R, 02_DataAnnotation.R, 03_AnnotationEvaluation.R. Left-padding the numbers with one or more 0 will mean that the files are sorted numerically, even when files are listed alphabetically (see Figure¬†3.3 (b)).\n\n\n\n\n\n\n\n\n\n\n\n(a) File names without additional zeros numbers\n\n\n\n\n\n\n\n\n\n\n\n(b) File names with left-padded numbers\n\n\n\n\n\n\n\nFigure¬†3.3: Why left-padding file names is good file naming practice.\n\n\n\nIt is often a good idea to include the date in file names. However, many date formats are not easily sortable (see Figure¬†3.4 (a)). Formatting dates using the ‚ÄòYYYY-MM-DD‚Äô format as in Figure¬†3.4 (b) will allow you to easily sort your files in chronological order.\n\n\n\n\n\n\n\n\n\n\n\n(a) File names with a non-ordered date format\n\n\n\n\n\n\n\n\n\n\n\n(b) File names with an ordered date format\n\n\n\n\n\n\n\nFigure¬†3.4: Why using the YYYY-MM-DD is good file naming practice.\n\n\n\nEven though computers have gotten much better at dealing with folder and file names containing spaces and special characters, using anything other than basic Latin alphanumeric characters, - and _ in file and folder names will - sooner or later - cause you or your colleagues some serious issues. This is especially true when you start coding. Do not delay getting used to using systematic, human- and computer-friendly folder and file names! In the long run, these simple guidelines will make your digital life much smoother and save you much time and unnecessary stress.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "3_DataManagement.html#sec-FoldersPaths",
    "href": "3_DataManagement.html#sec-FoldersPaths",
    "title": "3¬† Data management",
    "section": "3.3 Folders and paths",
    "text": "3.3 Folders and paths\nNow that you know how to name your files and folders sensibly, we can turn to best practices for organising these files and folders. Returning to our kitchen analogy, imagine that, over many years, you collected hundreds of recipes from friends and family. These recipes are jotted down on individual sheets of paper, all of which have been thoughtlessly tossed into a large kitchen drawer called ‚ÄòDocuments‚Äô, which also happens to contain receipts for kitchen appliances still under warranty, takeaway brochures, and various other bits of paper. In such a kitchen, finding Aunt Sophie‚Äôs famous caramelised apple cake could take a while! If, however, you had a dedicated kitchen drawer for recipes which contained neatly labelled folders different types of dishes, you would know to look for this cake recipe in the Desserts folder. Within the Desserts folder, you could have sub-folders for different types of desserts (e.g., cakes, ice creams, trifles). This would make finding Aunt Sophie‚Äôs recipe an absolute piece of cake!\nThinking about how to structure folders and sub-folders for your projects is about creating a kind of road map that should be readily interpretable by both humans and computers. This is where the concept of ‚Äòpaths‚Äô arises. Paths, in simple terms, describe the location of a file or a folder in a computer‚Äôs filesystem. There are different types of paths. An absolute path provides a complete path from the computer‚Äôs ‚Äúroot folder‚Äù. If our house were our root folder, the absolute path to Aunt Sophie‚Äôs recipe would be \"/Kitchen/Recipes/Desserts/Cakes/Apple-Cake_Aunt-Sophie\". Hence, just like your home‚Äôs postal address, which ideally specifies your home‚Äôs absolute location worldwide, an absolute path provides a complete path from a computer‚Äôs root folder to the file or folder in question.\nBy contrast, a relative path represents the location of a file or folder relative to another folder. Hence, if we already have the Dessert folder open in front of us, the relative path to the apple cake recipe would simply be \"Cakes/Apple-Cake_Aunt-Sophie\". However, if we wanted to access a recipe in the Starters folder from the Cakes folder, we would first have to go ‚Äúback up the path‚Äù from the Cakes folder to the Recipes drawer. This is achieved by adding ../ to the front of the relative path, e.g., \"../Starters/Soups/Pea-Mint-Soup_Barbara\".\nFor example, \"/Users/lefoll/Documents/Teaching/RstatsTextbook/ToDo.txt\" is the absolute path from my computer‚Äôs root folder to the file containing my to-do list in relation to this textbook project. By contrast, a ‚Äúrelative path‚Äù represents the location of a file or folder relative to another folder. Hence, if I am already in the directory \"/Users/lefoll/Documents/Teaching/RstatsTextbook/\", the relative path to my to-do list is only \"ToDo.txt\".\nNote that, here, we use the term ‚Äúfolder‚Äù as a metaphor for a computer file directory. Most modern operating systems use folder icons that look like the kind of paper file folders that office workers use to have piled up on their desks as a means of visually representing directories in computer file systems.\nTo complicate things a little, the way file paths are written varies depending on the computer‚Äôs operating system. In Unix-based systems like Linux and macOS, paths are written using forward slashes (e.g., \"/Users/elen/Documents/Teaching/RstatsTextbook/ToDo.txt\"), whereas on Windows, paths are written using backslashes (e.g., \"C:\\Users\\elen\\Documents\\Teaching\\RstatsTextbook\\ToDo.txt\").\nThere are many ways to find out where your files are stored on your computer. Let us begin by opening a Finder window (on macOS) or a File Explorer window (on Windows). Navigate to the folder which contains the file for which you want to find the absolute path. Alternatively you could use your computer‚Äôs search function to search for the file. Once you have found it:\n\non Windows: Right-click on the file (in some older Windows versions, you may also need to press the ‚Äúshift‚Äù key). Among the options presented to you, click on the one to copy the file path (e.g., ‚ÄúCopy as path‚Äù or similar in the language of your operating system).\non macOS: Right-click on the file and then press the Option/‚å• key on your keyboard. Pressing down this key will change the options you are given after having right-clicked. One of these options should now be ‚ÄúCopy ‚Ä¶ as Pathname‚Äù (or something equivalent in the language of your operating system). Click on this option.\n\nThen, open any text-editing programme (e.g., LibreOffice Writer, Microsoft Word, TextEdit, or NotePad++) and use the shortcut Ctrl/Cmd + V to paste your file‚Äôs path in the empty document. If you are on Windows, your path should have backslashes, whereas if you are on Linux or macOS, your path should have forward slashes.\n\n\n\n\n\n\nQuiz time!\n\n\n\n\n\n\n\n\n\nFigure¬†3.5: Screenshot of a Finder window showing the hierarchical folder structure within the UzK folder (which stands for University of Cologne)\n\n\n\n4) What is the absolute path to the highlighted file in Figure¬†3.5?\n\n\n\n\nUsers\\lefoll\\Documents\\UzK\\2024_SoSe_Stats\\Rscripts\\2_ErrorsAreFun.R\n\n\nUsers/lefoll/Documents/UzK/2024_SoSe_Stats/Rscripts/2_ErrorsAreFun.R\n\n\nUzK/2024_SoSe_Stats/Rscripts/2_ErrorsAreFun.R\n\n\n../UzK/2024_SoSe_Stats/Rscripts/2_ErrorsAreFun.R\n\n\n\n\n\n\n\n¬†\n5) From the ‚ÄúUzK‚Äù folder, what is the relative path to the highlighted file in Figure¬†3.5?\n\n\n\n\n../UzK/2024_SoSe_Stats/Rscripts/2_ErrorsAreFun.R\n\n\nRscripts/2_ErrorsAreFun.R\n\n\n2024_SoSe_Stats/Rscripts/2_ErrorsAreFun.R\n\n\nUzK/2024_SoSe_Stats/Rscripts/2_ErrorsAreFun.R\n\n\n\n\n\n\n\n¬†\n6) From the ‚ÄúRscripts‚Äù folder, what is the relative path to the folder ‚Äú2023_SoSe_CADS‚Äù (see Figure¬†3.5)?\n\n\n\n\n../../2023-SoSe-CADS\n\n\n../../2023_SoSe_CADS\n\n\n../2023_SoSe_CADS\n\n\n../../../2023_SoSe_CADS\n\n\n\n\n\n\n\nHint: From the Rscript folder, you will need to go ‚Äúback up the path‚Äù twice: once to get to the course folder 2024_SoSe_Stats and a second time to get to the UzK folder, before you can move to the 2023_SoSe_CADS folder. Going back up the path is achieved with ../.\n\n\n\n\n\n\n\n\nTask\n\n\n\nRead the abstract of the following academic article. What was this experimental study about?\n\nTerai, Masato, Junko Yamashita & Kelly E. Pasich. 2021. Effects of Learning Direction in Retrieval Practice on EFL Vocabulary Learning. Studies in Second Language Acquisition 43(5). 1116‚Äì1137. https://doi.org/10.1017/S0272263121000346.\n\na) According to the study, which is the most effective way of learning vocabulary in a foreign language?\n\n\n\n\nBy first reading a word in one's native language, and then reading a translation in the target language.\n\n\nBy first reading a word in the target language, and then a translation in one's native language.\n\n\nIt's impossible to tell as all learners are individuals.\n\n\nBeginners learn better if they are first exposed to a word in their native language and then in the target language. The opposite is true for more advanced learners.\n\n\n\n\n\n\n\n¬†\nThe authors of this article have published the data and materials associated with this study on IRIS. You can find them here: https://iris-database.org/search/?s_publicationAPAInlineReference=Terai%20et%20al.%20(2021)\nb) In which format are the video files associated with this publication?\n\n\n\n\n.mov\n\n\n.mp4\n\n\n.mxf\n\n\n.avi\n\n\n\n\n\n\n\n¬†\nc) In which format is the analysis code which they shared on IRIS?\n\n\n\n\nPython\n\n\nRmarkdown\n\n\nR\n\n\nHTML\n\n\n\n\n\n\n\n¬†\nd) The associated materials also include a section entitled ‚ÄúScores on measures / tests‚Äù. Download the file dataset1_ssla_20210313.csv from this section. Which character is used as the separator in this delimiter-separated values (DSV) file?\n\n\n\n\nSpace\n\n\nSemicolon\n\n\nTab\n\n\nColon\n\n\nComma",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "3_DataManagement.html#backing-up-data-fire-safety-measures-in-the-digital-kitchen",
    "href": "3_DataManagement.html#backing-up-data-fire-safety-measures-in-the-digital-kitchen",
    "title": "3¬† Data management",
    "section": "3.4 Backing up data: ‚ÄòFire safety‚Äô measures in the digital kitchen üßØ",
    "text": "3.4 Backing up data: ‚ÄòFire safety‚Äô measures in the digital kitchen üßØ\nA basic principle of sound data management consists in keeping a copy of all your files in more than one place. This ensures that, should something go awry, your research is not lost forever but instead can be recovered and restored promptly. There are many ways things could go wrong: laptops can get stolen or permanently damaged (laptops are not terribly keen on hot chocolate as it turns out‚Ä¶ üôà), computer files can be corrupted and become unusable, you or someone else may accidentally delete files, your computer can become infested with a nasty virus, etc.\nAn effective way to protect your projects is to abide by the 3-2-1 rule (Schweinberger 2022). It‚Äôs simple:\n\nEnsure that you have at least three copies of your data (e.g., one that you work with on your personal computer and two back-up copies).\nSplit the backup copies between two different storage media (e.g., a hard-drive stored in your office and online in a secure cloud service).\nStore one of these copies in a secure place off-site (i.e., not where your computer usually is).\n\nOne solution is to store your three copies on:\n\nyour personal laptop or computer,\na backup hard drive stored in a secure location, and\na secure online repository such as the data management system provided by your institution, e.g., Sciebo, ownCloud, or GitLab.\n\nChoosing an online repository will protect your data if your computer malfunctions or is damaged or stolen, but remember that it can also potentially make your data accessible to others. This is particularly true of commercial back-up solutions such as Microsoft‚Äôs OneDrive, Google‚Äôs Drive, Apple‚Äôs iCloud, or Dropbox, which although convenient and very user-friendly, should not be used to store sensitive data (e.g., data that may be used to identify individuals, contain financial information, health records, location data, or proprietary research data). Always check if your institution has its own, secure cloud option. If not, keeping a second hard-drive copy in a separate, secure location is likely the safest solution.\nWhilst the 3-2-1 rule stipulates that you should keep at least three copies of each file, in an optimal scenario, each file should exist only once at each location (e.g., on your laptop, a separate hard-drive, and the server of an online repository). It is quite easy to (often unknowingly) end up with several duplicates of the same file on any one machine but this can cause issues if, for example, you end up updating the wrong version of the file. Avoiding and eliminating file duplicates is therefore an important step towards proficient data management.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "3_DataManagement.html#conclusion",
    "href": "3_DataManagement.html#conclusion",
    "title": "3¬† Data management",
    "section": "3.5 Conclusion",
    "text": "3.5 Conclusion\nSound data management - comprising of both good folder and file naming practices and the smart organisation of these folders and files - is the foundation for efficient research workflow. Understanding and applying these basic principles of file management will ensure that everything in your digital ‚Äòkitchen‚Äô has its place, is well labelled, and easy to find. By ensuring that we keep our kitchens clean, tidy, and safe, we can whip out some truly delicious dishes!\n\n\n\n\n\n\nFigure¬†3.6: Artwork by xkcd\n\n\n\nWhilst the above caption is true, if it helps, you might want to imagine that someone very judgemental could actually look in your Documents folder at any given time!\n\n\n\n\n\n\nGoing further\n\n\n\n\n\nThis short online module is ideal to learn more about smarter ways to work with files and data:\nThe University of Queensland Library. 2023. Work with Data and Files. The University of Queensland. https://uq.pressbooks.pub/digital-essentials-data-and-files/. (14 May, 2024).\nTo go further, here are some great in-depth resources to learn more about data management in linguistics and education research specifically:\n\nBerez-Kroeker, Andrea L., Bradley McDonnell, Eve Koller & Lauren B. Collister. 2022. The Open Handbook of Linguistic Data Management. MIT Press. https://doi.org/10.7551/mitpress/12200.001.0001.\nLewis, Crystal. Data Management in Large-Scale Education Research. https://datamgmtinedresearch.com/. (14 May, 2024).\n\nBoth of these are available as Open Educational Resources.\n\n\n\n\n\n\n\nalvinashcraft, alexbuckgit, ArcticLampyrid & bearmannl. 2022. Maximum path length limitation. Learn Microsoft. https://learn.microsoft.com/en-us/windows/win32/fileio/maximum-file-path-limitation.\n\n\nSchweinberger, Martin. 2022. Data management, version control, and reproducibility. https://ladal.edu.au/repro.html.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "3_DataManagement.html#footnotes",
    "href": "3_DataManagement.html#footnotes",
    "title": "3¬† Data management",
    "section": "",
    "text": "For example, many Windows applications have a maximum file path length of 260 characters(alvinashcraft et al. 2022).‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "4_InstallingR.html",
    "href": "4_InstallingR.html",
    "title": "4¬† Installing R and RStudio",
    "section": "",
    "text": "Chapter overview\nThis chapter is designed to help you get started using R and RStudio, assuming no prior use of either. We will be covering the following topics:\nIf you already have some experience of using R and RStudio, please ensure that both are up-to-date. Whilst parts of this chapter will likely be revision, others may be the opportunity to learn some new tips about setting up and using R in RStudio, installing and citing packages. Once you‚Äôve skimmed through this chapter, feel free to swiftly move on to Chapter 5.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Installing `R` and RStudio</span>"
    ]
  },
  {
    "objectID": "4_InstallingR.html#why-learn-r",
    "href": "4_InstallingR.html#why-learn-r",
    "title": "4¬† Installing R and RStudio",
    "section": "4.1 Why learn R?",
    "text": "4.1 Why learn R?\nIn short, because R can do it all! üôÉ This statement is only a slight exaggeration: R is indeed a highly versatile programming language and environment that allows us to do a multitude of tasks relevant to the language sciences. These include data handling and processing, statistical analysis, creating effective and appealing data visualisations, web scraping, text analysis, generating reports in various formats, designing web pages, and interactive apps, and much, much more! üí™\nWhilst some will claim that R has a steep learning curve, this textbook aims to prove that the opposite is true! Whilst it‚Äôs fair to say that, as with all new things, it will take you a while to get the hang of it, once you‚Äôve got started, you will see that your possibilities are (pretty much) endless and that learning how to do new things in R makes for fun and very rewarding challenges. What‚Äôs more, this textbook introduces the {tidyverse} approach to programming in R, which is particularly accessible to beginners. We will also use RStudio to access R, which makes things considerably more intuitive and generally easier to work with.\nWhat‚Äôs more, both R and the RStudio Desktop version that we will be using are free and open source (see Section 1.2), which means that they are accessible to all, regardless of their institutional affiliation or professional status. This is in contrast to proprietary statistical software such as SPSS, for which you or your university needs to buy an expensive license. To get started in R, all you will need is access to the internet, a computer (unfortunately, a tablet will not suffice), and the intrinsic motivation to work your way through the basic skills taught in this textbook.\n\n[U]sing R - it‚Äôs like the green and environment-friendly gardening alternative to buying plastic wrapped tomatoes in the supermarket that have no taste anyway. (Martin Schweinberger 2022)\n\n\n\n\n\n\nFigure¬†4.1: ‚ÄúTomato Harvest, Yellow & Red‚Äù by OakleyOriginals (CC BY 2.0).\n\n\n\n\nLast but not least, in choosing to learn R, you are entering a vibrant community of users. As an open-source programming environment, R is the product of many different people‚Äôs contributions. Everyday, new packages, functions, and resources are being developed, improved, and shared with the community. Given that R has evolved into one of the most popular languages for scientific programming (and has become ‚Äúthe de facto standard in the language sciences‚Äù Winter 2019: xiii), many of these have been created by scientists and are particularly well-suited to research workflows. Moreover, the R community is known for being welcoming, supportive, and inclusive (sadly, the same cannot be said of all communities in the computing world). This is reflected in the strong presence of many community-led initiatives such as RLadies and RainbowR, which encourage under-represented groups to participate in and contribute to the R community. ü§ó\n\n\n\n\n\n\nFigure¬†4.2: Logo of the RLadies Ribeir√£o Preto meet-up group, one of many RLadies chapters.\n\n\n\n\n‚ÄúLook, I am studying languages so why should I learn to code?‚Äù ü§î\nUsing scripts rather than GUI software will help you make your research less error-prone, more transparent, and sustainable. Being open-source, there are no restrictions as to who can run R code and older versions are available ensuring that exact reproduction is possible, even years later. As many other language scientists use R, you will be able to collaborate with others and understand other researchers‚Äô R code. As we will see in a future chapter, in RStudio, it is also very easy to export R code and share your scripts, for example as part of an appendix to your research publication, in various formats (including .html that can be opened in any browser and .pdf).\nIn addition, learning to code in R is an excellent way to understand the basics of data literacy and statistical reasoning. These are skills that are highly valued among employers, both in academia and the industry. Many companies, public institutions (e.g., ministries, hospitals, national agencies) and NGOs hire data scientists who often work in R. And, even if you end up doing little to no coding yourself, understanding the basic principles of programming is undoubtedly a highly useful skill in the modern world.\n\n\n\n\n\n\nWhat about learning Python instead? üêç\n\n\n\n\n\nSome of you may be wondering whether you should be learning Python rather than R. Both are widely used languages in scientific programming and data science. At the time of writing, there are more resources specifically aimed at linguists and education researchers in R than there are in Python simply because it is currently the most widely used language in these disciplines. Should you wish to learn Python at a later stage, many of the same principles that you will have learned in this textbook will apply: it should feel somewhat like learning Italian when you already speak Spanish or French.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Installing `R` and RStudio</span>"
    ]
  },
  {
    "objectID": "4_InstallingR.html#installing-r-and-rstudio",
    "href": "4_InstallingR.html#installing-r-and-rstudio",
    "title": "4¬† Installing R and RStudio",
    "section": "4.2 Installing R and RStudio",
    "text": "4.2 Installing R and RStudio\n\n4.2.1 What are R and RStudio? And why do I need both?\nAs a beginner, it‚Äôs easy to confuse R and RStudio, but it‚Äôs important to understand that they are two very different things. R is a programming environment for statistical computing and graphics that uses the programming language R. Think of it as the engine with which we will learn to perform lots of different tasks. RStudio, by contrast, is a set of tools, a so-called ‚Äòintegrated development environment‚Äô (IDE). It makes working in R much more intuitive and efficient. If R is the engine of our car, you can imagine RStudio as our dashboard. Hence, even though we will later on appear to only be working in RStudio, R will actually be doing the heavy-lifting, under the hood.\n\n\n\n\n\n\n\n\n\n\n\n(a) Logo of the programming language and environment R\n\n\n\n\n\n\n\n\n\n\n\n(b) Logo of the IDE RStudio (RStudio¬Æ is a trademark of Posit Software, PBC)\n\n\n\n\n\n\n\nFigure¬†4.3: Even the two logos are easy to confuse, but remember that R and RStudio are two very different things!\n\n\n\n\n\n\n\n\n\nUsing other IDEs to work in R\n\n\n\n\n\nAt the time of writing, RStudio is the most widely used Integrated Development Environment (IDE) to work in R. However, it is worth noting that many other IDEs that can be used to access R. These include:\n\nJupyter notebook\nVisual Studio Code\nPyCharm\nEclipse\n\nWhilst this textbook will assume that everyone is working in RStudio, if you are already familiar with another IDE that works well with R, you are welcome to continue working in that IDE. Each IDE has a different feel to it and offers different functions so, ultimately, it‚Äôll be up to you to find the one that suits you best!\n\n\n\n\n\n4.2.2 Installing R\n\nGo to the website of the Comprehensive R Archive Network (CRAN): https://cran.r-project.org.\nClick on the ‚ÄúDownload R for ‚Ä¶‚Äù link that matches your operating system (Linux, macOS or Windows), then:\n\nFor Windows, click on the top ‚Äòbase‚Äô link, also marked as ‚Äúinstall R for the first time‚Äù (Note that you should also use this link if you are updating your R version). On the next page, click on the top ‚ÄúDownload R‚Äù link.\nFor MacOS, click on either the top .pkg link if you have an Apple silicon Mac (e.g., M1, M2, M3) or the second .pkg link, if you have an older Intel Mac.\nFor Linux, click on your Linux distribution and then follow the instructions on the following pages.\n\n\n\n\nOnce you have downloaded one of these R versions, navigate to the folder where you have saved it (by default, this will be your Downloads folder), and double click on the executable file to install R.\nFollow the on-screen instructions to install R.\nTest that R is correctly installed. On Windows and MacOS, navigate to your Applications folder and double click on the R icon. On Linux, open up R by typing R in your terminal. This should open up an R Console. You can type R commands into the Console after the command prompt &gt;. Type the following R code after the command prompt and then press enter: plot(1:10).\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Test command in the R Console\n\n\n\n\n\n\n\n\n\n\n\n(b) Resulting plot (note that the proportions of your plot may be different depending on the size of your window)\n\n\n\n\n\n\n\nFigure¬†4.4: Testing R\n\n\n\n‚úÖ If you see the plot above, you have successfully installed and tested R and you can go on to installing RStudio.\n‚ö†Ô∏è If that‚Äôs not the case, make a note of the errors produced (copy and paste them into a text document or take a screenshot) and search for solutions on the internet. It is very likely that many other people have already encountered the same problem as you and that someone from the R community has posted a solution online.\n\n\n\n\n\n\nWhat to do if you cannot get R and/or RStudio working on your computer\n\n\n\n\n\nThe aim of this chapter is to install both R and R Studio on your own computer so that you can write and run your own scripts locally (i.e., on your own computer without the need for an internet connection). In some cases, however, this might not be possible. For example, because the programmes are not available for your operating system, or because you do not have admin rights on your computer, or because your disk is full and you cannot delete anything. None of these situations are ideal to do research, but don‚Äôt give up on learning R: there is an alternative!\nYou can sign up to Posit Cloud. Posit Cloud will allow you to run R in RStudio in a browser (e.g., Firefox or Chrome) without having to install anything on your computer. Although Posit Cloud‚Äôs free plan is limited, it will suffice to learn the contents of this textbook. You will be able to follow the textbook in exactly the same way as everyone else. However, you will need a stable internet connection and you may find that you need to be a bit more patient as things are likely to run a little slower. If you decide to opt for the Posit Cloud solution, create a free account and then go straight to Setting up RStudio.\n\n\n\n\n\n4.2.3 Installing RStudio\nWhen you head over to their website, it may be confusing to you that the company that provides RStudio, Posit, also offers paid-for versions of RStudio and other paying services. Do not worry, we will not need any of these: These are products designed for companies and large organisations. The version of RStudio Desktop that we will be using, however, is completely free and, given that it is open source, even if Posit decided to stop working on this product one day, others in the R community would take over. Such is the beauty of open-source software! ü§ó\n\nHead over to this page https://posit.co/download/rstudio-desktop/ to download the latest version of RStudio Desktop.\nAs you have already installed R, you can jump straight to the section entitled ‚Äú2: Install RStudio‚Äù. The website should have detected which operating system your computer is running on, so that you can most likely simply click on the ‚ÄúDownload RStudio Desktop‚Ä¶‚Äù button. Your download should start straight away.\n\nIf an incorrect operating system is detected, simply scroll down the page to find your operating system and download the corresponding version of RStudio.\n\n\n\n\nOnce you have downloaded RStudio, navigate to the folder where the downloaded file has been saved (by default, this will be your Downloads folder), and double-click on the executable file to install RStudio.\nFollow the on-screen instructions to install RStudio.\n\nIf you run into any issues that you cannot solve with existing online posts, the Posit Community forums are a good place to ask for help.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Installing `R` and RStudio</span>"
    ]
  },
  {
    "objectID": "4_InstallingR.html#setting-up-rstudio",
    "href": "4_InstallingR.html#setting-up-rstudio",
    "title": "4¬† Installing R and RStudio",
    "section": "4.3 Setting up RStudio",
    "text": "4.3 Setting up RStudio\nFrom now on, we will only be accessing R through RStudio. When you open up RStudio for the first time, you might find the layout rather intimidating. The application window is divided into several sections, which we call ‚Äòpanes‚Äô. Each pane also has several tabs. Although it may seem overwhelming at first, you will soon see that these different panes and tabs will actually make life much easier.\n\n4.3.1 Global options\nBefore we get staRted properly, however, we need to change some of the default settings of RStudio. The first set of changes that we are going to make ensure that, each time we launch a new R session in RStudio, we start afresh.\nTo do so, head over to the ‚ÄòTools‚Äô drop-down menu and click on ‚ÄòGlobal Options‚Äô. Make sure that the first three boxes are unticked (see Figure¬†4.5 (a)). Under ‚ÄúSave workspace to .RData on exit‚Äù, select the option ‚ÄúNever‚Äù. Always starting afresh is good programming practice. It avoids any problems being carried over from previous R sessions. You can think of it like cooking in a freshly cleaned, tidy kitchen. It‚Äôs much safer than preparing a meal in a messy, possibly even contaminated kitchen! Or use the keyboard shortcut Ctrl/Command + ,\n\n\n\n\n\n\n\n\n\n\n\n(a) General tab\n\n\n\n\n\n\n\n\n\n\n\n(b) Code tab\n\n\n\n\n\n\n\nFigure¬†4.5: RStudio‚Äôs Global Options\n\n\n\nNext, under the ‚ÄòGlobal Options‚Äô tab ‚ÄòCode‚Äô of the ‚ÄòGlobal Options‚Äô window, ensure that the fourth option ‚ÄúUse native pipe operator‚Äù is ticked (see Figure¬†4.5 (b)). This is a new feature in R that is very useful so we will make use of it in this textbook. The other options are not relevant for now.\nFinally, head over to the ‚ÄòPane Layout‚Äô tab. From here, you can rearrange the panes of your RStudio window. To do so, click on the ÔπÄ symbols to get a drop-down menu corresponding to each pane. You can also select which tabs you would like to see in each pane. If you are already familiar with RStudio, feel free to stick to your favourite set-up. Personally, I use the panes layout below and, if you are new to R, I recommend that you select this layout, too. You can always go back to these settings to change this setup at any stage. Don‚Äôt forget to click on ‚ÄòOK‚Äô at the bottom of the ‚ÄòGlobal Options‚Äô page to save your settings. Then, the panes in your RStudio window should be ordered as in Figure¬†4.6 (b).\n\n\n\n\n\n\n\n\n\n\n\n(a) Panes Layout tab\n\n\n\n\n\n\n\n\n\n\n\n(b) Customised panes layout\n\n\n\n\n\n\n\nFigure¬†4.6: Recommended RStudio panes layout\n\n\n\n\n\n4.3.2 Testing RStudio\nIt is now time we tested whether RStudio is communicating well with R. To do so, let‚Äôs run the same test as in the R Console. This time, head over to the ‚ÄòConsole‚Äô tab in the top right pane of your RStudio window and, after the command prompt &gt;, type: plot(1:10) and then press enter. You should see the same plot as earlier on (see Figure¬†4.4 (b)), appearing in the Plots tab of the bottom-right pane of your RStudio window.\nIf you get the following error message Error in plot.new() : figure margins too large, this is because your bottom-right pane is hidden from view or too small for the plot to be printed there. Click on the small two-window icon in the bottom-right corner if it is hidden (see Figure¬†4.7 (a)). Or, if it is too small, click on the dividing line between the two right-hand side panes and, whilst still holding down the mouse button, drag up the line until it is about halfway up. Then, re-type the command plot(1:10) in the Console pane and press enter again. The plot should appear as in Figure¬†4.7 (b).\n\n\n\n\n\n\n\n\n\n\n\n(a) Hidden (minimised) bottom-right pane\n\n\n\n\n\n\n\n\n\n\n\n(b) Now the dividing line between the two panes is halfway up and the plot has been successfully output in the Plots pane\n\n\n\n\n\n\n\nFigure¬†4.7: Testing that RStudio is communicating well with your R installation.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Installing `R` and RStudio</span>"
    ]
  },
  {
    "objectID": "4_InstallingR.html#installing-r-packages",
    "href": "4_InstallingR.html#installing-r-packages",
    "title": "4¬† Installing R and RStudio",
    "section": "4.4 Installing R packages",
    "text": "4.4 Installing R packages\n\n4.4.1 What are packages?\nYou now have a base installation of R. Base R is very powerful and comes with many standard packages and functions that R users use on a daily basis. If you click on the Packages tab in the bottom-right pane and scroll down, you will see that there are many packages available. Only a few are selected. These are part of the base R installation.\nYou can think of base R as a fully functional student kitchen. It is rather small and only has the most essential ingredients and equipment, but it still has everything you need to cook simple, delicious meals. Downloading and installing additional packages is like buying fancier ingredients (i.e., packages with datasets) or more sophisticated and specialised kitchen devices (i.e., packages that provide additional functions).\nIn addition to the members of the R Core Team who develop and maintain base R, thousands of R users develop and share additional R packages every day. These enable us to vastly increase the capacities of base R. Packages are a very helpful way to bundle together a set of functions, data, and documentation files so that other R users can easily download these bundles and add them to their local R installation.\nThroughout this textbook, the names of packages will be enclosed in curly brackets like this: {ggplot2}.\n\n\n\n\n\n\nQuiz time!\n\n\n\n1) Which of these packages is not part of base R?\n\n\n\n\n{graphics}\n\n\n{stats}\n\n\n{ggplot2}\n\n\n{datasets}\n\n\n\n\n\n\n\n¬†\n2) Is it possible to create an R package that provides access to the full texts of all of Jane Austen‚Äôs published novels for computational text analysis in R?\n\n\n\n\nYes, pretty much anything is possible in R!\n\n\nNo way, that sounds impossible!\n\n\n\n\n\n\n\n¬†\n3) Is the {janeaustenr} package installed as part of base R?\n\n\n\n\nYes\n\n\nNo\n\n\n\n\n\n\n\n\n\n\n\n4.4.2 Installing packages\nTo install a package, you will first need to download it from the internet. Packages are typically stored on different websites (online repositories), but the most trustworthy one and easiest to work with is CRAN (Comprehensive R Archive Network). To install the {janeaustenr} package from CRAN, simply type the following command in the Console pane and then type enter: install.packages(\"janeaustenr\").\nThis command will take a few seconds to run (or longer depending on how slow your internet connection is). You should then see a message in red in the Console indicating (among other things that you can ignore) that the package has been successfully downloaded and its size (here: 1.5 megabyte), as well as the path to where the package‚Äôs content has been saved on your computer (see Figure¬†4.8). You do not need to worry about any of the other information.\n\n\n\n\n\n\nFigure¬†4.8: Screenshot showing that the package has been correctly installed.\n\n\n\nTo check that the package has been successfully downloaded and installed, head over to the Packages tab of the bottom-right pane and scroll down to the {janeaustenr} package, or search for it using the search window within this same tab. The {janeaustenr} package should now be visible, which tells us that the package is installed on your computer. Note, however, that the checkbox next to it is currently empty. This means that the package hasn‚Äôt been loaded in our current R session and therefore cannot be used yet.\n\n\n\n\n\n\nMore ways of installing R packages\n\n\n\n\n\nThere are other ways to install packages, e.g., from Bioconductor and GitHub.\nTo find out more, read Section 1.5 from Douglas et al. (2024), which is available as an Open Educational Resource (see Chapter 1).\n\n\n\n\n\n4.4.3 Loading packages\nIf you want to use the fancy ingredient or new kitchen device that was delivered in the package that you installed, you first need to get it out of the fridge or the cupboard and place it on your kitchen counter. This is the equivalent of ‚Äúloading‚Äù a package. The command to load a package is library(). This is because, rather confusingly, once they are unpacked (i.e., installed), packages are usually referred to as libraries.\nTo load the {janeaustenr} package, enter the following command in the Console:\n\nlibrary(janeaustenr)\n\nIf you correctly installed the package and have not misspelt the command, it may look like nothing has happened, as the Console returns nothing (see first red ellipse on Figure¬†4.9). However, if you go back to your Packages tab and scroll down to the {janeaustenr} package, you will see that the box next to it is now ticked (see second ellipse on Figure¬†4.9). This means that the package is loaded and ready to be used.\n\n\n\n\n\n\nFigure¬†4.9: Loading a library\n\n\n\nNote that whilst you only need to install each package once, you will need to load it every time we want to use it in a new R session. This is because, when we close Rand start a new R session, our kitchen is perfectly clean and tidy and everything is back in storage. And the good news is that we don‚Äôt even need to do the washing-up! üôÉ",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Installing `R` and RStudio</span>"
    ]
  },
  {
    "objectID": "4_InstallingR.html#package-documentation",
    "href": "4_InstallingR.html#package-documentation",
    "title": "4¬† Installing R and RStudio",
    "section": "4.5 Package documentation",
    "text": "4.5 Package documentation\nTo find out more about any package or function, simply use the command help() or its shortcut ?. For example, to find out more about the {janeaustenr} package, enter the command help(janeaustenr) or ?janeaustenr in the Console. The help file will open up in the Help tab of the bottom-right pane. It contains the name of the package and a short description, as well as the name of the package maintainer, Julia Silge, and some additional links.\nOne of these links takes us to the package creator‚Äôs GitHub repository. This is where we can find a source code for the package, should we want to check how it works under the hood, or amend it in any way. Click on this link and scroll down the package‚Äôs GitHub page to consult its README file. This document informs us that the package includes plain text versions of Jane Austen‚Äôs six completed, published novels and tells us under what name they are stored within the library. For example, to access Pride and Prejudice, we need to load the library object prideprejudice. Note that the object names in R cannot contain spaces or hyphens.\nPick your favourite Jane Austen novel and enter its corresponding object name in the Console, e.g., emma. The entire novel will be printed in the Console output! You can print only a few lines by selecting them within square brackets, e.g., the command emma[20:25] will only print lines 20 to 25 of the object emma (see Figure¬†4.10).\n\n\n\n\n\n\nFigure¬†4.10: Screenshot showing a selection of lines from the object emma (note that you can adjust the size of the Console pane to see more or less of the text at any one time).\n\n\n\nTo find out more about a dataset or function within a package, use the functions help() or ?, e.g., help(emma) or ?emma. In this case, the help file provides us with a short description of this object and a link to the original source from which the package creator obtained the novel (which is in the public domain, otherwise it would not be possible to share it in this way).\n\n\n\n\n\n\nQuiz time!\n\n\n\n4) Which is the correct R object name to access Jane Austern‚Äôs novel ‚ÄòSense and Sensibility‚Äô?\n\n\n\n\nsenseandsensibility\n\n\nSense&Sensibility\n\n\nSense and Sensibility\n\n\nSensesensibility\n\n\nsensesensibility\n\n\n\n\n\n\n\n¬†\n5) What is the source for the R object containing Jane Austern‚Äôs novel ‚ÄòSense and Sensibility‚Äô?\n\n\n\n\nhttps://jasna.org/austen/works/sense-sensibility/\n\n\nhttps://www.goodreads.com/book/show/14935.Sense_and_Sensibility\n\n\nhttps://en.wikipedia.org/wiki/Sense_and_Sensibility\n\n\nhttp://www.gutenberg.org/ebooks/161\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\n6) What is the first word of the 66th line in the R object containing Jane Austern‚Äôs novel ‚ÄòSense and Sensibility‚Äô?\n\n\n\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Installing `R` and RStudio</span>"
    ]
  },
  {
    "objectID": "4_InstallingR.html#citing-r-packages",
    "href": "4_InstallingR.html#citing-r-packages",
    "title": "4¬† Installing R and RStudio",
    "section": "4.6 Citing R packages",
    "text": "4.6 Citing R packages\nWhen we use a package that is not part of base R, it is very important to reference the package properly. There are two main reasons for doing this. For a start, the people who create and maintain these packages largely do so in their free time and they deserve full credit for their incredibly valuable work and contribution to science. Hence, whenever you use a package for your research, you should cite it, just like you would other sources.\nThe help page of the {janeaustenr} package already informed us that the maintainer of the package is Julia Silge. To get a full citation, however, we should use the citation() function. Enter citation(\"janeaustenr\") in the Console to find out how to cite this package.\nNote that the recommended bibliographic reference also includes the package version, which is important for reproducibility as the package may evolve and someone wanting to reproduce your analysis (and this may well be future you!) will need to know which version you used. This is the second main reason why we should be diligent about citing the packages that we used. In a research report, thesis, or academic article, you could cite the {janeaustenr} package like this:\n\nWe used the janeaustenr package (Silge 2022) to access Jane Austen‚Äôs six published novels in R (R Core Team 2024).\n\nYou can see the full references by hovering on the in-text citation links or by going to the References section of this book.\n\n\n\n\n\n\nMore about referencing packages\n\n\n\n\n\nYou may also want to install the {report} package, which includes a number of useful functions for citing R versions and R packages:\n\nreport::report_system()\n\nAnalyses were conducted using the R Statistical language (version 4.4.1; R Core\nTeam, 2024) on macOS Sonoma 14.5\n\nreport::cite_packages()\n\n  - Makowski D, L√ºdecke D, Patil I, Th√©riault R, Ben-Shachar M, Wiernik B (2023). \"Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption.\" _CRAN_. &lt;https://easystats.github.io/report/&gt;.\n  - Moroz G (2020). _Create check-fields and check-boxes with checkdown_. &lt;https://CRAN.R-project.org/package=checkdown&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. &lt;https://www.R-project.org/&gt;.\n  - Silge J (2022). _janeaustenr: Jane Austen's Complete Novels_. R package version 1.0.0, &lt;https://CRAN.R-project.org/package=janeaustenr&gt;.\n  - Xie Y (2024). _knitr: A General-Purpose Package for Dynamic Report Generation in R_. R package version 1.47, &lt;https://yihui.org/knitr/&gt;. Xie Y (2015). _Dynamic Documents with R and knitr_, 2nd edition. Chapman and Hall/CRC, Boca Raton, Florida. ISBN 978-1498716963, &lt;https://yihui.org/knitr/&gt;. Xie Y (2014). \"knitr: A Comprehensive Tool for Reproducible Research in R.\" In Stodden V, Leisch F, Peng RD (eds.), _Implementing Reproducible Computational Research_. Chapman and Hall/CRC. ISBN 978-1466561595.\n\nreport::report_packages()\n\n  - report (version 0.5.9; Makowski D et al., 2023)\n  - checkdown (version 0.0.12; Moroz G, 2020)\n  - R (version 4.4.1; R Core Team, 2024)\n  - janeaustenr (version 1.0.0; Silge J, 2022)\n  - knitr (version 1.47; Xie Y, 2024)\n\n\nTo find out more, it is also worth reading Steffi LaZerte‚Äôs blog post on ‚ÄúHow to cite R and R packages‚Äù: https://ropensci.org/blog/2021/11/16/how-to-cite-r-and-r-packages/.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Installing `R` and RStudio</span>"
    ]
  },
  {
    "objectID": "4_InstallingR.html#keeping-things-up-to-date",
    "href": "4_InstallingR.html#keeping-things-up-to-date",
    "title": "4¬† Installing R and RStudio",
    "section": "4.7 Keeping things up to date ‚ú®",
    "text": "4.7 Keeping things up to date ‚ú®\nAs with all software, it is a good idea to keep your installations of RStudio and R up-to-date. New features are constantly being added, bugs are fixed and updates may include important security patches.\n\n4.7.1 Updating RStudio\nBy default, RStudio will let you know when a new version is available in a pop-up window. To update RStudio simply follow the same instructions as for the first installation (see Section 4.2.3). This time, however, when you add RStudio to your apps, you will get a pop-up message warning you that an older version of this programme already exists on your computer (see Figure¬†4.11). You can safely click on the option ‚ÄúReplace‚Äù. All of your previous Global Options settings will be transferred to your updated RStudio version so this should be a quick-and-easy process.\n\n\n\n\n\n\nFigure¬†4.11: Warning message on MacOS when installing an updated version of RStudio\n\n\n\nYou can also check which version of RStudio you are running by clicking on the ‚ÄúHelp‚Äù menu in RStudio‚Äôs top toolbar and then selecting the option ‚ÄúAbout RStudio‚Äù. In the ‚ÄúHelp‚Äù drop-down menu, you also have an option to ‚ÄúCheck for Updates‚Äù.\n\n\n4.7.2 Updating R\nUpdating R is a little more complex because you will also need to update all of your R packages. Some of the packages that you use may not (yet) be available for the latest R version. This is why, for beginners, I do not recommend updating R in the middle of a project. That said, it is a good idea to keep your R version up-to-date. To find out which version of R you are currently working with, run this command in the Console.\n\nR.version.string\n\n[1] \"R version 4.4.1 (2024-06-14)\"\n\n\nCompare this version number with the number of the latest version available on CRAN (see Figure¬†4.12). If the version that you are running is not the same as the latest R version available on CRAN, you might want to update it. As a rule of thumb, it is a good idea to do an update if your version is more than six months old. To proceed with the update, close RStudio on your computer. Then, follow the same instructions as for the first-time installation of R (see Section 4.2.2).\n\n\n\n\n\n\nFigure¬†4.12: CRAN R for macOS page using the latest recommended R version\n\n\n\n\n\n4.7.3 Updating R packages\nOnce you have updated R, it is important that you also update your installed packages. To do so, run the following command in the Console:\n\nupdate.packages(ask = FALSE, checkBuilt = TRUE)\n\nAlternatively, you can also go to the Packages tab of RStudio and click on the button ‚ÄúUpdate‚Äù. A pop-up window will appear with a list of the packages that need updating. Click on ‚ÄúSelect All‚Äù and ‚ÄúInstall Updates‚Äù.\n\n\n\n\n\n\n\n\n\n\n\n(a) ‚ÄòUpdate‚Äô button in RStudio‚Äôs Packages tab\n\n\n\n\n\n\n\n\n\n\n\n(b) ‚ÄòUpdate Packages‚Äô dialogue in RStudio\n\n\n\n\n\n\n\nFigure¬†4.13: Updating packages using RStudio‚Äôs Graphical User Interface (GUI)\n\n\n\nNote that, if you have installed a lot of packages, this updating operation could take a while. It requires a stable internet connection and a bit of patience. üßòüèæ\n\n\n\n\n\n\nAn easier way to update R using {installr} (for Windows only)\n\n\n\n\n\nThe {installr} package simplifies updating R on Windows. To install the package use the usual commands:\n\ninstall.packages(\"installr\") # Run this command the first time you use the package.\n\nlibrary(installr) # Run this command everytime you want to update R using this package.\n\nThen, run the updateR() function, which automates the updating process by detecting your current R version, comparing it with the latest available version, and guiding you through the process of downloading and installing the latest version.\nIt is also possible to customise the update process with arguments like updateR(update_packages = FALSE) to skip package updates. For more details, check the documentation using the command ?updateR.\n\n\n\n\n\n\n\nDouglas, Alex, Deon Roos, Francesca Mancini & David Lusseau. 2024. An introduction to R. https://intro2r.com/.\n\n\nR Core Team. 2024. R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nSilge, Julia. 2022. Janeaustenr: Jane Austen‚Äôs complete novels. https://CRAN.R-project.org/package=janeaustenr.\n\n\nWinter, Bodo. 2019. Statistics for linguists: An introduction using R. Routledge. https://doi.org/10.4324/9781315165547.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Installing `R` and RStudio</span>"
    ]
  },
  {
    "objectID": "5_GettingStaRted.html",
    "href": "5_GettingStaRted.html",
    "title": "5¬† Getting staRted",
    "section": "",
    "text": "Chapter overview\nNow that you have installed and tested R and RStudio, in this chapter, you will learn how to:\nIf you are already familiar with the basics of R and are keen to learn more about doing statistics in R, you can skip most of this chapter. That said, it‚Äôs probably not a bad idea to have a go at the quiz questions and the final task to refresh your memory.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Getting sta`R`ted</span>"
    ]
  },
  {
    "objectID": "5_GettingStaRted.html#using-the-console",
    "href": "5_GettingStaRted.html#using-the-console",
    "title": "5¬† Getting staRted",
    "section": "5.1 Using the Console",
    "text": "5.1 Using the Console\nThis is what you did in the previous chapter when you tested that RStudio was working properly (using the command: plot(1:10)).\nOne way to write R code in RStudio is to use the Console. If you set up RStudio as recommended here, the Console should be in your top-right pane. You can type a line of code immediately after the command prompt &gt; and press ‚ÄúEnter‚Äù.\nData input is the most basic operation in R. Try inputting a number by typing it out in the Console and then pressing ‚ÄúEnter‚Äù. R will interpret the number and return it. You can input both integers (whole numbers, e.g., 13) and decimal numbers (e.g., 0.5).\n\n\n\n\n\n\nFigure¬†5.1: Inputting numbers in the Console\n\n\n\nR can handle not only numbers but also text data, known as ‚Äúcharacter strings‚Äù or just ‚Äústrings‚Äù. Strings must always be enclosed in quotation marks. You can choose to use either double quotation marks \" \" or single quotation marks ' ', but it is important to be consistent. In this textbook, we will use double quotation marks throughout.\nTry first inputting a single word and then an entire sentence in the Console.\n\n\n\n\n\n\nFigure¬†5.2: Inputting strings in the Console\n\n\n\n\n\n\n\n\n\nQuiz time!\n\n\n\n1) What happens if you enter a word without quotation marks?\n\n\n\n\nR returns an error indicating that you probably mistyped the word.\n\n\nR returns an error message because it interprets the word as an object name or command.\n\n\nR returns an error message indicating that it expected a number.\n\n\nR automatically wraps the word in quotation marks and processes it as a string.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Getting sta`R`ted</span>"
    ]
  },
  {
    "objectID": "5_GettingStaRted.html#sec-Maths",
    "href": "5_GettingStaRted.html#sec-Maths",
    "title": "5¬† Getting staRted",
    "section": "5.2 Doing maths in R",
    "text": "5.2 Doing maths in R\nR can also be used as a very powerful calculator. The lines of code in Figure¬†5.3 demonstrate mathematical operations involving addition (+), subtraction (-), division (/), and multiplication (*). Try out a few yourself!\n\n\n\n\n\n\nFigure¬†5.3: Using the R Console as a calculator\n\n\n\n\n\n\n\n\n\nQuiz time!\n\n\n\n2) Try entering 13^2 in the Console. What does the ^ (caret) operator do?\n\n\n\n\nThe ^ operator performs an exponentiation operation, here 13 to the power of 2.\n\n\nThe ^ operator calculates the modulus of a number, here of 13 with 2 as the base.\n\n\nThe ^ operator creates a vector, here with 13 occurrences of the integer 2.\n\n\n\n\n\n\n\n¬†\n3) Compare 13*13 with 13 * 13. What is the difference in the output?\n\n\n\n\nThere is no difference.\n\n\nAdding a space generates an error.\n\n\nIt is impossible to add a space in the R Console.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Getting sta`R`ted</span>"
    ]
  },
  {
    "objectID": "5_GettingStaRted.html#sec-WorkingRObjects",
    "href": "5_GettingStaRted.html#sec-WorkingRObjects",
    "title": "5¬† Getting staRted",
    "section": "5.3 Working with R objects",
    "text": "5.3 Working with R objects\nSo far, we have used the Console like a calculator. It‚Äôs important to understand that, just like with a standard calculator, the output of all of our operations was not saved anywhere. If we want to store values, sequences of values, and the results of computations for later use, R allows us to store these as ‚ÄúR objects‚Äù.\n\n5.3.1 Creating objects\nWe use the assignment operator (&lt;-) to assign a value or sequence of values to an object name.\nWrite out the following line to create an object called my.favourite.number that contains your own favourite number.\n\nmy.favourite.number &lt;- 13\n\nWhen you enter this line in the Console and press ‚ÄúEnter‚Äù, it should look like nothing happened: R does not return anything in the Console. Instead, it saves the output in an object called my.favourite.number. However, if you look in your Environment pane, you should see that an object has appeared (Figure¬†5.4).\n\n\n\n\n\n\nFigure¬†5.4: Created object in the Environment pane\n\n\n\nTo save an object containing a character string, we use quotation marks. Create an object called my.favourite.word containing your favourite word (in any written language of your choice).\n\nmy.favourite.word &lt;- \"empathy\"\n\nYour Environment pane should now contain two objects. You can print the content of a stored object by entering the object name in the Console and then pressing ‚ÄúEnter‚Äù (see Figure¬†5.5).\nüí° Tip: If you‚Äôre feeling lazy or simply want to avoid making a typo, you can type just the first few letters of an object name and then press the ‚ÄúTab‚Äù key (‚Üπ or ‚á•). RStudio will then give you a drop-down menu with possible options. Select the one you want by clicking on it or pressing ‚ÄúEnter‚Äù.\n\n\n\n\n\n\nFigure¬†5.5: Calling up stored objects in the Console to view their content\n\n\n\n\n\n5.3.2 Object types\nThese two objects are of different types. We can use the class() function to find out which type of object an object is.\n\n\n\n\n\n\nFigure¬†5.6: Using the class() function\n\n\n\nHere, my.favourite.number is a numeric object, while my.favourite.word is a character object.\n\n\n5.3.3 Naming objects\nObject naming conventions in R are fairly flexible. We can use dots (.), underscores (_) and capital letters to make our object names maximally informative and easy for us humans to read. However, spaces and other symbols are not allowed. All of these options work:\n\nword2 &lt;- \"cheerful\"\nmy.second.word &lt;- \"cheerful\"\nmy_second_word &lt;- \"cheerful\"\nMySecondWord &lt;- \"cheerful\"\n\n\n\n\n\n\n\nFigure¬†5.7: Environment pane showing all of the objects currently stored in the R session environment\n\n\n\n\n\n\n\n\n\nQuiz time!\n\n\n\n4) Which of these object names are not allowed in R? Try to create an object with each of these names and see if you get an error message or not.\n\n\n\n\nBestWordEver!\n\n\nmy-favourite-word\n\n\n1TopWord\n\n\nTop1Word\n\n\nAgn√®s.Favourite.Word\n\n\ntop word\n\n\n\n\n\n\n\nüòá Hover for a hint\n\n\n\n\n\n\nObject names should not contain spaces or symbols like !, nor should they contain hyphens as the hyphen is reserved for the mathematical operator ‚Äúminus‚Äù. Digits can be used anywhere except at the beginning of an object name. And whilst it is possible to have special characters such as accented letters like ‚Äú√®‚Äù, it is not recommended that you use them for object names.\n\n\n5.3.4 Overwriting and deleting objects\nObject names are unique. If you create a new object with an existing object name, it will overwrite the existing object with the new one. In other words, you will lose the values that you saved in the original object. Try it out by running this line and observing what happens in your Environment pane:\n\nword2 &lt;- \"surprised\"\n\nEarlier on, you created an object called word2 which contained the string ‚Äúcheerful‚Äù. But, by running this new line of code, ‚Äúcheerful‚Äù has been replaced by the string ‚Äúsurprised‚Äù - with no warning that you were about to permanently delete ‚Äúcheerful‚Äù! üò≤\nThe command to delete a single object from your environment is remove() or rm(). Hence, to permanently delete the object MySecondWord, you can use either of these commands:\n\nremove(MySecondWord)\nrm(MySecondWord)",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Getting sta`R`ted</span>"
    ]
  },
  {
    "objectID": "5_GettingStaRted.html#working-with-.r-scripts",
    "href": "5_GettingStaRted.html#working-with-.r-scripts",
    "title": "5¬† Getting staRted",
    "section": "5.4 Working with .R scripts",
    "text": "5.4 Working with .R scripts\nIf we shut down RStudio right now, we will lose all of our work so far. This is because the objects that we have created are only saved in the environment of our current R session. Whilst this might sound reckless, it is actually a good thing: In Section 4.3.1 we set our ‚ÄòGlobal Options‚Äô settings in RStudio such that, whenever we restart RStudio, we begin with a clean slate, or a perfectly clean and tidy kitchen. We don‚Äôt want any dirty dishes or stale ingredients lying around when we enter the kitchen! With this in mind, close RStudio now and open it again to start a new R session.\nYou should now have an empty history in your Console pane and an empty Environment pane. Whilst nobody wants to start cooking in a messy kitchen, it‚Äôs also true that, if we want to remember what we did in a previous cooking/baking session, we should write it down. The pages of our recipe book are .R scripts. In the following, we will see that writing scripts is much better than running everything from the Console. It allows us to save and rerun our entire analysis pipeline any time we want. It also ensures that our analyses are reproducible and saves us time as we don‚Äôt have to rewrite our code every time. Crucially, if we made a mistake at any stage, we can go back and correct it and rerun the entire corrected script at the click of a button.\n\n5.4.1 Creating a new .R script\nThere are three ways to create a new .R script in RStudio. Pick the one that you like best:\n\nNavigate to the top menu item ‚ÄúFile‚Äù, then select ‚ÄúNew File‚Äù, then click on ‚ÄúR Script‚Äù.\nClick on the icon with a white page and a green plus button in the top left corner of the tool bar.\nUse the keyboard shortcut Shift + Ctrl/Cmd + N.\n\nWhichever option you chose, RStudio should have opened an empty file in a fourth pane (see Figure¬†5.8). This is the ‚ÄúSource pane‚Äù and it should have appeared in the top-left corner of your RStudio window.\n\n\n\n\n\n\nFigure¬†5.8: RStudio window showing a new, empty .R script that has yet to be saved\n\n\n\n\n\n5.4.2 Running code from an .R script\nWe can now type our code in this empty .R script in the Source pane, just like we did in the Console. Type the following lines of code in the script (see Figure¬†5.9):\n\n13*13\nmy.favourite.number &lt;- 13\nmy.favourite.word &lt;- \"empathy\"\n\nYou will have noticed that when you pressed ‚ÄúEnter‚Äù after every line, nothing happened: Nowhere can we see the result of 13*13, nor have our two objects been saved to the environment as the Environment pane remains empty (see Figure¬†5.9). Just like a recipe for a cake is not an actual, delicious cake, but simply a set of instructions, a script is only a text file that contains lines of code as instructions. For these instructions to be executed, we need to send them to the R Console where they will be interpreted as R code.\n\n\n\n\n\n\nFigure¬†5.9: Writing code in an .R script\n\n\n\nTo send a line of code to the Console (also referred to as ‚Äúrunning‚Äù a line of code), select the line that you want to excecute, or place your mouse cursor anywhere within that line and then click on the ‚ÄúRun‚Äù button (in the top-right corner of the pane, see Figure¬†5.8) or use the keyboard shortcut Ctrl/Cmd + Enter.\nTry out these two options to run the three lines of code of your script and check that a) you are seeing the result of the mathematical operation in the Console output and b) two objects have been added to your environment.\n\n\n5.4.3 Saving an .R script\nIt is now very easy to rerun this script any time we want to redo this calculation and recreate these two R objects. However, our .R script is not yet saved! RStudio is warning us about this by highlighting the file name ‚ÄúUntitled1*‚Äù in red (see Figure¬†5.8). Just like with any unsaved computer file, if we were to shut RStudio down now, we would lose our work. So, let us save this .R script locally, that is on our own computer. To do so either:\n\nNavigate to the top menu item ‚ÄúFile‚Äù and then click on ‚ÄúSave‚Äù,\nClick on the save icon üíæ, or\nUse the keyboard shortcut Ctrl/Cmd+ S.\n\nGive your script a meaningful file name. Remember that file names should be both computer-readable and human-readable. If you navigate to the folder where you saved your .R script, you should see that its file extension is .R. You should also see that it is a tiny file because it contains nothing more than a few lines of text. If you double click on an .R file, RStudio should automatically open it. However, if you wanted, you could open .R files with any text-processing software, such as LibreOffice Writer or Microsoft Word.\n\n\n5.4.4 Writing comments in scripts\nJust like in a recipe book, in addition to writing the actual instructions, we can also write some notes, for example to remind ourselves of why we did things in a particular way or for what occasion we created a special dish. In programming, notes are called ‚Äúcomments‚Äù and they are typically preceded by the # symbol.\nThus, if a line starts with a # symbol, we say that it is ‚Äúcommented out‚Äù. RStudio helpfully displays lines that are commented out in a different colour. These lines will not be interpreted as code even if you send them to the Console. Write the following lines in your script and then try to run them.\n\n#13^13\n\n#StringObject3 &lt;- \"This line has been commented out so the object will not be saved in the environment even if you try to run it.\"\n\nAs you can see, nothing happens. You can also add comments next to a line of interpretable code. In this case, the code is interpreted up until the #. This can be helpful to make a note of what a line of code does, e.g.:\n\nsqrt(169) # Here the sqrt() function will compute the square root of 169.\n\n[1] 13\n\n\nIt is good practice to comment your code when working in an .R script. Comments are crucial for other people to understand what your code does and how it achieves that. But even if you are confident that you are the only person who will ever use your code, it is still a very good idea to use comments to make notes documenting your intentions and your reasoning as you write your script.\nFinally, writing comments in your code as you work through the examples in this book is a great way to reinforce what you are learning. From this chapter onwards, I recommend that, for each chapter, you create an .R script documenting what you have learnt, adding lots of comments to help you remember how things work. This is generally more efficient (and less error-prone!) than trying to take notes in a separate document (e.g., in a Microsoft Word file) or on paper.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Getting sta`R`ted</span>"
    ]
  },
  {
    "objectID": "5_GettingStaRted.html#sec-RelationalOperators",
    "href": "5_GettingStaRted.html#sec-RelationalOperators",
    "title": "5¬† Getting staRted",
    "section": "5.5 Using relational operators",
    "text": "5.5 Using relational operators\nNow that we have saved some objects in our environment, we can use them in calculations. Try out the following operations (and any other that take your fancy) with your own favourite number:\n\nmy.favourite.number / 2\n\n[1] 6.5\n\nmy.favourite.number * my.favourite.number\n\n[1] 169\n\n\nIn additional to the mathematical operations that we saw in Section 5.2, we can also use relational operators such &gt;, &lt;, &lt;=, &gt;=, == and != to make all kinds of comparisons. Try out the following commands to understand how these relational operators work and then have a go at the quiz questions.\n\nmy.favourite.number &gt; 10\nmy.favourite.number &lt; 10\nmy.favourite.number == 25\nmy.favourite.number &gt;= 13\nmy.favourite.number &lt;= -13\nmy.favourite.number != 25\n\n\n\n\n\n\n\nQuiz time!\n\n\n\n5) What is the relational operator that checks whether a value is ‚Äúmore than or equal to‚Äù another value?\n\n\n\n\n\n\n\n\n\n\nüòá Hover for a hint\n\n\n\n\n¬†\n6) What is the relational operator that checks whether a value ‚Äúis not equal to‚Äù another value?\n\n\n\n\n\n\n\n\n\n\nüòá Hover for a hint\n\n\n\n\n\n\nThe relational operators == and != can also be used with character objects. Find out how they work by first creating a new character object with a word that was added to the 2025 edition of the popular French dictionary Petit Larousse:\n\nNew.French.Word &lt;- \"√©cogeste\"\n\nThen copy these lines of code to test how these relational operators work with string characters.\n\nNew.French.Word == \"√©cogeste\" \nNew.French.Word != \"trottinettiste\"\n\nYou will have noticed that the relational operator == tests whether two strings are the same and returns TRUE if that‚Äôs the case. In contrast, != tests whether two strings are different and will therefore return FALSE if they are not different.\n\n\n\n\n\n\nQuiz time!\n\n\n\nAbove, we created the following R character string object:\n\nNew.French.Word &lt;- \"√©cogeste\"\n\n7) Why does this line of code return FALSE even though New.French.Word was assigned the character string ‚Äú√©cogeste‚Äù?\n\nNew.French.Word == \"ecogeste\"\n\n\n\n\n\nBecause \"√©cogeste\" and \"ecogeste\" are two different strings in R.\n\n\nBecause R automatically removed the accent as object names must be in English.\n\n\nBecause == cannot be used to compare character strings in French.\n\n\n\n\n\n\n\n¬†\n8) Why does this line of code return FALSE?\n\nNew.French.Word == \" √©cogeste\"\n\n\n\n\n\nBecause string objects cannot include any special characters. This includes spaces.\n\n\nBecause R is case-sensitive.\n\n\nBecause this string includes an additional space character.\n\n\n\n\n\n\n\n¬†\n9) Why does this line of code return FALSE?\n\nNew.French.Word == \"√âcogeste\"\n\n\n\n\n\nBecause this word is not in the dictionary of the Acad√©mie Fran√ßaise.\n\n\nBecause R is case-sensitive.\n\n\nBecause strings should never start with a capital letter.\n\n\n\n\n\n\n\n¬†\n10) Why does this line of code return FALSE?\n\nNew.French.Word != \"√©cogeste\"\n\n\n\n\n\nBecause √©cogeste is no longer a new French word.\n\n\nBecause this string is in a different text encoding.\n\n\nBecause this command asks whether New.French.Word is not equal to \"√©cogeste\".",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Getting sta`R`ted</span>"
    ]
  },
  {
    "objectID": "5_GettingStaRted.html#sec-Errors",
    "href": "5_GettingStaRted.html#sec-Errors",
    "title": "5¬† Getting staRted",
    "section": "5.6 Dealing with errors ü§¨",
    "text": "5.6 Dealing with errors ü§¨\nWhen R cannot interpret your code, the Console will display an error message in red. A large part of learning to code is really about learning how to interpret these error messages and developing an intuition for the most common reasons why errors occur.\n\n\n\n\n\n\nFigure¬†5.10: The process of fixing programming errors is called ‚Äúdebugging‚Äù and often involves an array of emotions (artwork by @allison_horst).\n\n\n\nAs you begin your journey of learning to code in R, you are very likely to encounter one problem on a regular basis. So let‚Äôs take a closer look at that error. Copy and paste this exact line of code and try to run it in your R Console:\n\nsqrt(my.favourite.number\n\nNotice that, in this erroneous line of code, we have (intentionally) forgotten to include the final bracket. As a result, after you hit ‚ÄúEnter‚Äù, the Console output shows a ‚Äú+‚Äù instead of the result of the mathematical operation. The ‚Äú+‚Äù indicates that the line is incomplete and therefore cannot be interpreted yet. R is therefore asking you to complete your line of code.\n\n\n\n\n\n\nFigure¬†5.11: Incomplete function in console\n\n\n\nThere are two ways to fix this. The first method is to complete the line of code directly in the Console. In this case, this means adding the closing bracket ‚Äú)‚Äù after the ‚Äú+‚Äù and hitting ‚ÄúEnter‚Äù. Now that the line has been completed, R is able to interpret it as an R command and will output the result of the operation.\nIf you are running a line of code just once, from the Console, this first method is fine. As we have seen above, however, most of the time, you will write your code in a script rather than in the Console. So this first on-the-fly method is only recommendable for lines of code that you will genuinely only need once. These include commands to install packages, like install.packages(\"janeaustenr\"), or to consult documentation files, e.g., help(janeaustenr).\nGiven that we will mostly be working in scripts, let‚Äôs now generate this error from an .R script. To do so, copy and paste the erroneous line of code in your .R script and try to run it by either clicking on the ‚ÄúRun‚Äù icon or using the shortcut Ctrl/Cmd + Enter:\n\nsqrt(my.favourite.number\n\nAgain, our incomplete line of code cannot be interpreted and the ‚Äú+‚Äù symbol appears in the Console. Now, correct the error in your script by adding the missing ‚Äú)‚Äù and try to run the command again:\n\nsqrt(my.favourite.number)\n\nEven though we have corrected the problem, we now get an error! ü§Ø At first sight, this does not make sense, but look carefully at what happened in the Console: The line of code that R tried to interpret is sqrt(my.favourite.number + sqrt(my.favourite.number), i.e., the combination of the incomplete version of the command plus the complete one. This is obviously nonsense and R tells us so by outputting an error message!\n\n\n\n\n\n\nFigure¬†5.12: Error message in console\n\n\n\nTo be able to enter a new line of code, we must see the command prompt &gt; in the Console. So, let‚Äôs generate the error again and learn how to fix it with the second method. Add this erroneous line to your script again and run it:\n\nsqrt(my.favourite.number\n\nThe + situation arises again, but we will now solve it using the second method. Head over to the Console and place your cursor next to the +. This time, instead of completing the line by adding a closing bracket, press ‚ÄúEsc‚Äù on your keyboard. This will cancel the incomplete line of code. Then, you can add the missing ) in your script and rerun the newly completed line of code from the Source pane.\nThis second method is the one you should use when you are documenting your code in a script. If you don‚Äôt make the changes immediately in your script, you will forget and you will run into this error again in the future. Think of it like a pastry chef who realises that they need to put a little more baking powder in a cake batter for the texture to be just right, but does not make a note of that change in their recipe book. Next time, the pastry chef will likely forget and not put the correct amount of baking powder. If it is one of their assistants who prepares the cake, they will not be able to know that the chef made that change!\nLearning to make sense of error messages is a very important skill that, like all skills, takes practice. Most errors are very easy to fix if you keep your cool. In fact, 90% of errors are simply typos.\n\n\n\n\n\n\nTask 1\n\n\n\nCopy and paste the following lines of code in a new .R script. Try to run each line individually. Each line will generate an error of some kind. In some cases, RStudio will warn you in advance that a line of code is likely wrong by displaying a red cross icon to the left of the erroneous line. If you hover over the red cross icon, RStudio will display a message that may help you to fix the error.\nCan you decode the error messages to find out what is causing these errors and fix these ten erroneous commands?\n\nmy.favourite.word &lt;- \"empathy\"\nmy.favourite.number &lt;- 13\n\n# Error 1:\nmy.favourite.number + my.favorite.number\n\n# Error 2:\nNegin-Fav-Word &lt;- \"Ach so!\" \n\n# Error 3:\nmy.favourite.numbers^2\n\n# Error 4:\n√∂mers_favourite_ number &lt;- 52\n\n# Error 5:\n    √∂mers_favorite_number =   my.favourite..number\n\n# Error 6:\nmy.favourite.number*2 -&gt; half.my.fav.number\n\n# Error 7:\nrose's.favourite.number &lt;- 5\n\n# Error 8:\nBestWordEver &lt;- \"supercalifragilisticexpialidocious\n\n# Error 9:\n2FavNumbers &lt;- my.favourite.number + √∂mers_favourite_number\n\n# Error 10:\ngood.luck &lt;- ŸÖŸàŸÅŸÇ ÿ®ÿßÿ¥ŸäÿØ\"\n\n\n\n\n\n\n\n\n\nFigure¬†5.13: Debugging is an unavoidable part of writing code. If you‚Äôre stuck and starting to feel fustrated, the best thing you can usually do is to take a short break (artwork by @allison_horst).\n\n\n\n\n\n\n\n\n\nClick here for the solutions to Task 1\n\n\n\n\n\n\nThe first error was object 'my.favorite.number' not found. This means that the object my.favorite.number is not stored in your environment. If you think it is, the problem is most likely due to a typo. Here, my.favorite.number uses American English spelling, whereas we used British English spelling when we created the object. To correct the error, you need to use exactly the same spelling as when you created the object.\nThe second error is also object 'Negin' not found. However, here we do not expect an object called Negin to be in the environment because what we are actually trying to do is create and save a new object called Negin-Fav-Word! The problem is that R interprets the hyphens in this object name as ‚Äúminus‚Äù and therefore tries to find the object Negin in order to then subtract Fav and Word from it. To correct this error, you need to remove the hyphens or replace them by dots.\nThe third error is yet another object not found error. It is another typo: the correct object name is not in the plural form.\nThe fourth error is Error: unexpected symbol in \"√∂mers_favourite_ number\". In addition, RStudio warned us that there were some ‚Äúunexpected tokens‚Äù in this line of code. The unexpected item is the space between _ and number. To fix this error, you need to remove this space character.\nThe object my.favourite..number is not found because the name of the object saved in the environment does not have two consecutive dots. Note that the error does not come from the fact that this line begins with some white space and includes multiple space characters after the = sign. These added spaces make the line more difficult for us humans to read, but R simply ignores them. Hence, to fix this error, what you need to do is remove one of the consecutive dots in the object name.\n\nIt is also worth noting that, once you‚Äôve removed the extra dot, this line of code replaces the value originally stored in √∂mers_favourite_number with the value stored in my.favourite.number. If you check your environment pane, you will see that the command has changed √∂mers_favourite_number to 13 - with no warning! In other words, here, the equal sign = behaves in the same way as the assignment operator &lt;-.\n\nIf you tried to run this line, you will have noticed that it does not actually generate an error. However, you may have noticed that the assignment operator is in the opposite direction. This means that my.favourite.number is multiplied by two and that this number is then assigned to a new object called half.my.fav.number. With this in mind, you will likely want to amend the line for the outcome to make mathematical sense (or rename the object).\nRunning this line will have caused you to run into a + situation in the console. As explained earlier in Section 5.6, to get out of it, you should first take your mouse cursor to the Console pane and then press the escape key on your keyboard to cancel this erroneous line. Whilst there is no error message to help you understand where the problem is coming from, you may find that RStudio helpfully displays a red cross icon to the left of the line; hovering over it displays a multi-line message. The first line is the relevant one: unexpected token 's.favourite.number &lt;- 5. This tells us that apostrophes are forbidden in object names. Remove the ' and the error will be fixed.\nThis line also causes a + situation. In this case, it is due to a missing quotation mark. To fix this error, first cancel the incomplete line of code by escaping it. Then, add the missing double quotation mark in your script and rerun the completed line.\nThe message Error: unexpected symbol in \"2FavNumbers\" is due to the fact that object names cannot start with a number. Change the object name to something like TwoFavNumbers or Fav2Numbers to fix the error.\nHere, too, the error message reads unexpected symbol. However, it is important to remember that the unexpected symbol is not within the character string, but rather within the command to assign the string to the object name good.luck. Hence, the problem is not that this string is in Persian, but rather that one of the quotation marks is missing. You can fix the error by ensuring that the phrase is enclosed in quotation marks.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Getting sta`R`ted</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html",
    "href": "6_ImpoRtingData.html",
    "title": "6¬† ImpoRting data",
    "section": "",
    "text": "Chapter overview\nMany introductory R textbooks postpone this section until much later by relying on datasets that are directly accessible as R data objects. In real life, however, research data rarely comes neatly packaged as an R data object. Your data will most likely be stored in a spreadsheet table or as text files of some kind. And -let‚Äôs be honest- they will be more messy than you would like to admit, making this chapter and the next crucial for learning to do data analysis in R.\nThis chapter will take you through the process of:\nIn future chapters, we will continue to work with this data. We will learn how to ‚Äúclean it up‚Äù for data analysis, before we begin to explore it using descriptive statistics and data visualisations.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html#accessing-data-from-a-published-study",
    "href": "6_ImpoRtingData.html#accessing-data-from-a-published-study",
    "title": "6¬† ImpoRting data",
    "section": "6.1 Accessing data from a published study",
    "text": "6.1 Accessing data from a published study\nAs we saw in Section 1.1, it is good practice to share both the data and materials associated with research studies so that others can reproduce and replicate the research.\nIn the following chapters, we will focus on data associated with the following study:\n\nDƒÖbrowska, Ewa. 2019. Experience, Aptitude, and Individual Differences in Linguistic Attainment: A Comparison of Native and Nonnative Speakers. Language Learning 69(S1). 72‚Äì100. https://doi.org/10.1111/lang.12323.\n\n\n\n\n\n\n\nFigure¬†6.1: Title page from the journal Language Learning\n\n\n\nFollow the DOI1 link above and read the abstract to find out what the study was about. You do not need to have institutional or paid access to the full paper to read the abstract.\n\n\n\n\n\n\nQuiz time!\n\n\n\n1) What types of data were collected as part of this study?\n\n\n\n\nSociodemographic information about the participants including their age and level of education\n\n\nParticipants' results on a grammar test\n\n\nParticipants' results on a collocations test\n\n\nParticipants' results on a nonverbal intelligence test\n\n\nParticipants' results on a vocabulary test\n\n\nParticipants' results on a language analytic ability test\n\n\n\n\n\n\n\n¬†\n2) On average, how did the English L2 speakers perform compared to the native speakers?\n\n\n\n\nOn average, both groups performed equally well on grammar and vocabulary tasks.\n\n\nThe observed differences in performance between native speakers and L2 speakers were not statistically significant.\n\n\nOn average, L2 speakers performed better on grammar tasks than native speakers\n\n\nOn average, native speakers outperformed L2 speakers on all language tasks, with the most significant difference observed in collocation tasks.\n\n\n\n\n\n\n\n¬†\n3) Did all native speakers perform better than the L2 speakers in the English vocabulary and grammar tests?\n\n\n\n\nYes, the L1 speakers clearly outperformed the L2 speakers in both grammar and vocabulary.\n\n\nThis study only looked at average trends, so no conclusive statement can be made about individual participants.\n\n\nNo, while L1 speakers generally performed better, some L2 speakers demonstrated equally high proficiency in grammar and vocabulary.\n\n\n\n\n\n\n\n¬†\n\n\nThe author, Ewa DƒÖbrowska, has made the data used in this study available on an open repository (see Section 2.4). To find out on which repository, go back to the study‚Äôs DOI link and click on the drop-down menu ‚ÄúSupporting Information‚Äù. It links to a PDF file. Click on the link and scroll to the last page which contains the following information about the data associated with this study:\n\nAppendix S4: Datasets\nDƒÖbrowska, E. (2018). L1 data [Data set]. Retrieved from https://www.iris-database.org/iris/app/home/detail?id=york:935513\nDƒÖbrowska, E. (2018). L2 data [Data set]. Retrieved from https://www.iris-database.org/iris/app/home/detail?id=york:935514\n\n\n\n\n\n\n\nQuiz time!\n\n\n\n4) On which repository/repositories can the data be found?\n\n\n\n\nZenodo\n\n\ndatabase.org\n\n\nIRIS\n\n\nResearchGate\n\n\nAll of the above.\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\n\n\nYou may have noticed that the datasets were published in 2018, whereas the article (DƒÖbrowska 2019) was published in the following year. This is very common in academic publications as it can take many months or even years for an article or book to be published, by which time the author(s) may have already made the data available on a repository. This particular article was actually first published on the journal‚Äôs website on 22 October 2018 as an ‚Äúadvanced online publication‚Äù, but was not officially published until March 2019 as part of Volume 69, Issue S1 of the journal (see https://doi.org/10.1111/lang.12323). This explains the discrepancy between the publication date of the datasets and the publication date of the article recorded in the bibliographic reference.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html#sec-SavingData",
    "href": "6_ImpoRtingData.html#sec-SavingData",
    "title": "6¬† ImpoRting data",
    "section": "6.2 Saving and examining the data",
    "text": "6.2 Saving and examining the data\nClick on the two links listed in Appendix S4 and download the two datasets. Note that the URL may take a few seconds to redirect and load. Save the two datasets in an appropriate place on your computer (see Section 3.3), as we will continue to work with these two files in the following chapters.\n\n\n\n\n\n\nWhat‚Äôs a good place to save these files? ü§î\n\n\n\n\n\nIf you haven‚Äôt already done so, I suggest that you create a folder in which you save everything that you create whilst learning from this textbook. This folder could be called something along the lines of DataLiteracyTextbook, 2024_data_literacy, or LeFoll_2024_DataLiteracy (see Section 3.2). Then, within this folder, I recommend that you create another folder called Dabrowska2019 (note how I have not included the ‚ÄúƒÖ‚Äù character in the folder name as this could cause problems), and within this folder, create another folder called data. This is the folder in which you can save these two files.\n\n\n\n\n\n\n\n\n\nQuiz time!\n\n\n\n5) In which data format are these two files saved?\n\n\n\n\nThey are both .csv files.\n\n\nThey are both .xslx files.\n\n\nThey are both .html files.\n\n\nThey are both .txt files.\n\n\n\n\n\n\n\n¬†\n\n\nThe file L1_data.csv contains data about the study‚Äôs L1 participants. It is a delimiter-separated values (DSV) file (see Section 2.5.1). The first five lines of the file are printed below. Note that this is a very wide table as it contains many columns (you can scroll to the right to view all the columns).\nParticipant,Age,Gender,Occupation,OccupGroup,OtherLgs,Education,EduYrs,ReadEng1,ReadEng2,ReadEng3,ReadEng,Active,ObjCl,ObjRel,Passive,Postmod,Q.has,Q.is,Locative,SubCl,SubRel,GrammarR,Grammar,VocabR,Vocab,CollocR,Colloc,Blocks,ART,LgAnalysis\n1,21,M,Student,PS,None,3rd year of BA,17,1,2,2,5,8,8,8,8,8,8,6,8,8,8,78,95,48,73.33333333,30,68.75,16,17,15\n2,38,M,Student/Support Worker,PS,None,NVQ IV Music Performance,13,1,2,3,6,8,8,8,8,8,8,7,8,8,8,79,97.5,58,95.55555556,35,84.375,11,31,13\n3,55,M,Retired,I,None,No formal (City and Guilds),11,3,3,4,10,8,8,8,8,8,7,8,8,8,8,79,97.5,58,95.55555556,31,71.875,5,38,5\n4,26,F,Web designer,PS,None,BA Fine Art,17,3,3,3,9,8,8,8,8,8,8,8,8,8,8,80,100,53,84.44444444,37,90.625,20,26,15\n\n\n\n\n\n\nQuiz time!\n\n\n\n7) Which character is used to separate the values in the file L1_data.csv?\n\n\n\n\ncolon\n\n\ndouble quotation mark\n\n\ntab\n\n\nspace\n\n\ncomma\n\n\n\n\n\n\n\n¬†\n8) Which character is used to delineate the values?\n\n\n\n\nsingle quotation mark\n\n\nspace\n\n\nnone\n\n\ndouble quotation mark\n\n\ndot",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html#sec-RProject",
    "href": "6_ImpoRtingData.html#sec-RProject",
    "title": "6¬† ImpoRting data",
    "section": "6.3 Using Projects in RStudio",
    "text": "6.3 Using Projects in RStudio\nOne of the advantages of working with RStudio is that it allows us to harness the potential of RStudio Projects. Projects help us to keep our digital kitchen nice and tidy. In RStudio, each project has its own directory, environment, and history which means that we can work on multiple projects at the same time and RStudio will keep them completely separate. This means that we can easily switch between cooking different dishes, say a gluten-free egg curry and vegan pancakes, without fear of accidentally setting the wrong temperature on the cooker or contaminating either dish.\nRegardless of whether or not you‚Äôre a keen multi-tasker, RStudio Projects are a great way to help you keep together all the data, scripts, and outputs associated with a single project in an organised manner. In the long run, this will make your life much, much easier. It will also be an absolute lifesaver as soon as you need to share your work with others (e.g., your supervisor, colleagues, reviewers, etc.).\nTo create a new Project, you have two options. In RStudio, you can select ‚ÄòFile‚Äô, then ‚ÄòNew Project‚Ä¶‚Äô (see ‚Äúa‚Äù on Figure¬†6.2). Alternatively, you can click on the Project button in the top-right corner of your RStudio window and then select ‚ÄòNew Project‚Ä¶‚Äô (see ‚Äúb‚Äù on Figure¬†6.2).\n\n\n\n\n\n\nFigure¬†6.2: Create a new project in RStudio\n\n\n\nBoth options will open up a window with three options for creating a new project:\n\nNew Directory (which allows you to create an entirely new project for which you do not yet have a folder on your computer)\nExisting Directory (which allows you to create a project in an existing folder associated with your project)\nVersion Control (see Bryan 2018).\n\nIn Section 6.2, you should have already saved the data that we want to import in a dedicated folder on your computer. Here, a folder is the same as a directory. Hence, you can select the second option: ‚ÄòExisting Directory‚Äô.\nClicking on this option will open up a new window (Figure¬†6.2). Click on ‚ÄòBrowse‚Ä¶‚Äô to navigate to the folder where you intend to save all your work related to DƒÖbrowska (2019). If you followed my suggestions earlier on, this would be a folder called something along the lines of Dabrowska2019. Once you have selected the correct folder, select the option ‚ÄòOpen in a new session‚Äô and then click on ‚ÄòCreate Project‚Äô.\n\n\n\nNew project window\n\n\nCreating an RStudio project generates a new file in your project folder called Dabrowska2019.Rproj. You can see it in the Files pane of RStudio. Note that the extension of this newly created file is .Rproj. Such .Rproj files store information about your project options, which you will not need to edit. More usefully, .Rproj files can be used as shortcuts for opening your projects. To see how this works, shut down RStudio. Then, in your computer file system (e.g., using a File Explorer window on Windows and a Finder window on macOS), navigate to your project folder to locate your .Rproj file (see Figure¬†6.3 (a)). Double-click on the file. This will automatically launch RStudio with all the correct settings for this particular project. Alternatively, you can use the Project button in the top-right corner of your RStudio window to open up a project from RStudio itself (see Figure¬†6.3 (b)).\n\n\n\n\n\n\n\n\n\n\n\n(a) Launching a Project from the File Finder\n\n\n\n\n\n\n\n\n\n\n\n(b) Launching a Project from RStudio\n\n\n\n\n\n\n\nFigure¬†6.3: The two options to open an RProject.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html#sec-WorkingDirectories",
    "href": "6_ImpoRtingData.html#sec-WorkingDirectories",
    "title": "6¬† ImpoRting data",
    "section": "6.4 Working directories",
    "text": "6.4 Working directories\nThe folder in which the .Rproj file was created corresponds to your project‚Äôs working directory. Once you have opened a Project, you can see the path to your project‚Äôs working directory at the top of the Console pane in RStudio. The Files pane should also show the content of this directory.\n\n\n\nContents of the project folder as displayed by RStudio\n\n\nClick on the ‚ÄúNew Folder‚Äù icon in your Files pane to create a new subfolder called analysis. Your folder Dabrowska2019 should now contain an .RProj file and two subfolders called analysis and data.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html#sec-ImportingDataCSV",
    "href": "6_ImpoRtingData.html#sec-ImportingDataCSV",
    "title": "6¬† ImpoRting data",
    "section": "6.5 Importing data from a .csv file",
    "text": "6.5 Importing data from a .csv file\nWe will begin by creating a new R script in which we will write the code necessary to import the data from DƒÖbrowska (2019)‚Äòs study in R. To do so, from the Files pane in RStudio, click on the analysis folder to open it and then click on the ‚ÄôNew Blank File‚Äô icon in the menu bar of the Files pane and select ‚ÄòR Script‚Äô. This will open a new, empty R script in your Source pane. It is best to always begin by saving a newly created file. Save this empty script with a computer- and human-friendly file name such as 1_DataImport.R (Section 3.2). It should now appear in your analysis folder in the Files pane.\nGiven that we want to import two .csv files, we are going to use the function read.csv(). You can find out what this function does by running the command ?read.csv or help(read.csv) in the Console to open up the documentation. This help file contains information about several base R functions used to import data. Scroll down to find the information about the read.csv() function. It reads:\nread.csv(file, header = TRUE, sep = \",\", quote = \"\\\"\",\n         dec = \".\", fill = TRUE, comment.char = \"\", ...)\nThis line from the documentation informs us that this function‚Äôs first argument is the path to the file from which we want to import the data. It also informs us that file is the only argument that does not have a default value (as it is not followed by an equal sign and a value). In this function, file is therefore the only argument that is compulsory. Hence, in theory, all we need to write to import the data is:\n\nL1.data &lt;- read.csv(file = \"data/L1_data.csv\")\n\nIn fact, we could shorten things even further as, unless otherwise specified, R will assume that the first value listed after a function corresponds to the function‚Äôs first argument which, here, is file. In other words, this command and the one above are equivalent:\n\nL1.data &lt;- read.csv(\"data/L1_data.csv\")\n\nThe file path \"data/L1_data.csv\" informs R that the data is located in a subfolder of the project‚Äôs working directory called data and that, within this data subfolder, the file that we want to import is called L1_data.csv. Note that the file extension must be specified (see Section 2.3). Note, also, the file path is separated with a single forward slash /. In R, this should work regardless of the operating system that you are using and, in order to be able to easily share your scripts with others, it is recommended that you use forward slashes even if you are running Windows (Section 3.3).\nAlthough the command above did the job, in practice, it is often safer to spell things out further to remind ourselves of some of the default settings of the function that we are using in case they need to be checked or changed at a later stage. In this example, we will therefore import the data with the following command:\n\nL1.data &lt;- read.csv(file = \"data/L1_data.csv\",\n                    header = TRUE,\n                    sep = \",\",\n                    quote = \"\\\"\",\n                    dec = \".\")\n\nIn the command above, header = TRUE, explicitly tells R to import the first row of the .csv table as column headers rather than values. This is not strictly necessary because, as we saw from the function‚Äôs help file, TRUE is already set as the default value for this argument, but it is good to remind ourselves of how this particular dataset is organised.\nThe arguments sep and quote specify the characters that, in this .csv file are used to separate the values on the one hand, and delineate them, on the other (see Section 2.5.1). As we saw above, DƒÖbrowska (2019)‚Äôs .csv files use the comma as the separator and the double quotation mark as the quoting character. Note that the \" character needs to be preceded by a backslash (\\) (we say it needs to be ‚Äúescaped‚Äù) because otherwise R will interpret it as part of the command syntax, which would lead to an error. Finally, the argument dec = \".\" explicitly tells R that this .csv file uses the dot as the decimal point. In some countries, e.g., Germany and France, the comma is used to represent decimal places so, if you obtain data from a German or French colleague, this setting may need to be changed to dec = \",\" for the data to be imported correctly.\n\n\n\n\n\n\n‚ÄúHell is empty, and all the devils are {here}.‚Äù üòà\n\n\n\n\n\nThis section title borrows a quote from The Tempest by William Shakespeare to reflect the fact that file paths are perhaps the most frequent source of frustration among (beginner) coders. Section 6.6 explains how to deal with the most frequent error messages. Ultimately, however, these errors are typically due to poor data management (see Chapter 3). That‚Äôs because the devil‚Äôs in the detail (remember: no spaces, special characters, differences between different operating systems, etc.). As a result, even advanced users of R and other programming languages frequently find that file path issues continue to plague their work, if they fail to take file management seriously.\nTo make your projects more robust to such issues, I strongly recommend working with the {here} package in addition to RProjects. You will first need to install the package:\n\ninstall.packages(\"here\")\n\nWhen you load the package, it automatically runs the here() function with no argument, which returns the path to your project directory, as determined by the location of the .RProj file associated with your project.\n\nlibrary(here)\n\nYou can now use the here() function to build paths relative to this directory with the following syntax:\n\nhere(\"data\", \"L1_data.csv\")\n\n[1] \"/Users/lefoll/Documents/UzK/RstatsTextbook/data/L1_data.csv\"\n\n\nAnd you can embed this path in your import command like this:\n\nlibrary(here)\n\nL1.data &lt;- read.csv(file = here(\"data\", \"L1_data.csv\"))\n\nMuch like wearing a helmet for extra safety (Figure¬†6.4), {here} makes the paths that you include in your code far more robust. In other words, they are far less likely to fail and break your code when you share your scripts with your colleagues, or run them yourself from different directories or operating systems. For more reasons to use {here}, check out the blog post ‚ÄúWhy should I use the here package when I‚Äôm already using projects?‚Äù by Barrett (2018).\n\n\n\n\n\n\nFigure¬†6.4: Although a fairly common way of working with data in R, using setwd() (see Section 6.12.1) is dangerous and will, sooner or later, cause you and/or your colleagues some nasty accidents. A combination of using RProj and {here} as described above is much safer!",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html#sec-ImportingErrors",
    "href": "6_ImpoRtingData.html#sec-ImportingErrors",
    "title": "6¬† ImpoRting data",
    "section": "6.6 Import errors and issues ü•∫",
    "text": "6.6 Import errors and issues ü•∫\nIt is crucial that you check whether your data has genuinely been correctly imported. Here‚Äôs a list of things to check (in that order):\n\nWere you able to run the import command without producing any errors? If you are getting an error, remember that this is most likely due to a typo (see Section 5.6)!\n\nIf part of the error message reads ‚ÄúNo such file or directory‚Äù, this means that either the file path or the file name is incorrect. Carefully check the path that you specified in your import command (if you‚Äôre struggling to find the correct path, you may want to try out the import method explained in Section 6.12.2). To ensure that you are not misspelling the name of the file, you can press the tab key on your keyboard to get RStudio to auto-complete the file name for you.\nIf the error message includes the statement ‚Äúcould not find function‚Äù, this means that you have either misspelled the name of the function or this is not a base R function and you have forgotten to load the library to which this function belongs (see Section 6.8).\nAs usual whenever you get an error message, also check that you have included all of the necessary brackets and quotation marks (see Section 5.6).\n\nHas the R data object appeared in your Environment pane? Does it have the expected number of rows (observations) and columns (variables)? L1.data contains 90 observations and 31 variables. If you are getting different numbers, this might be because you previously opened the .csv file with Excel or that your computer converted it to Excel format automatically. To remedy this, ensure that you have followed all the steps described in Section 2.5.2.\nTo view the entire table, use the function View() with the name of your data object as the first and only argument, e.g., View(L1.data)2. This will open up a new tab in your Source pane that displays the full table, much like in a spreadsheet programme. You can search and filter the table in this tab, but you cannot edit it in any way (and that‚Äôs a good thing because, if we want to edit things, we want to ensure that we keep track of our changes in a script!). Browse through the table and check that everything ‚Äúlooks healthy‚Äù. This is much like visually inspecting and smelling ingredients before using them in a recipe. It‚Äôs not perfect but if something is really off, you should notice it. Check that each cell appears to have one and only one value.\nFinally, use the str() function to view the structure of your data object in a more compact way. Using the command str(L1.data) will display a summary of the data.frame in the Console. The summary begins by informing us that this data object is a data.frame, that contains 90 observations and 31 variables. Then, it lists all of the variables, followed by the type of values stored in this variable (e.g., character strings or integers) and then the first few values for each variable. Especially with very wide tables that contain a lot of variables, it is often easier to check the summary of the imported data with str() than with View(), though I would always recommend taking a few seconds to do both. This is time well spent!\n\n\n\n\n\n\n\nTask 1\n\n\n\nImport both data files from DƒÖbrowska (2019) using the read.csv function as described above. Save the first as the R object L1.data (as in the example above) and the second as L2.data. Then, answer the following questions.\na) In the two data files from DƒÖbrowska (2019), each row corresponds to one participant. How many L1 participants were included in this study?\n\n\n\n\n17\n\n\n2790\n\n\n31\n\n\n221\n\n\n90\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\nb) How many L2 participants were included in DƒÖbrowska (2019)‚Äôs study?\n\n\n\n\n45\n\n\n67\n\n\n306\n\n\n90\n\n\n220\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\nc) Compare the data frames containing the L1 and L2 data. Which dataset contains more variables?\n\n\n\n\nL2.data\n\n\nL1.data\n\n\nThey have the same number of variables\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\nd) You have saved the two datasets to your local R environment as L1.data and L2.data. What kind of R objects are L1.data and L2.data? You can find out by using the command class(). It simply takes the name of the object as its only argument.\n\n\n\n\ntibble\n\n\nlist\n\n\ntable\n\n\ninteger\n\n\ndata frame\n\n\ncharacter\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\ne) Why does the L2 dataset contain the variable NativeLg, but not the L1 dataset?\n\n\n\n\nBecause Dr. DƒÖbrowska decided not to collect this information for L1 participants.\n\n\nBecause some or all of the L1 participants did not wish to answer this question.\n\n\nBecause this variable was removed from the dataset for data protection reasons.\n\n\nBecause, in this study, all L1 participants have English as their native language.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html#importing-tabular-data-in-other-formats",
    "href": "6_ImpoRtingData.html#importing-tabular-data-in-other-formats",
    "title": "6¬† ImpoRting data",
    "section": "6.7 Importing tabular data in other formats",
    "text": "6.7 Importing tabular data in other formats\nWe have seen how to load data from a .csv file into R by creating an R data frame object that contains the data extracted from a .csv file. But, as we saw in Chapter 2, not all datasets are stored as .csv files. Fear not: there are many import functions in R, with which you can import pretty much all kinds of data formats! This section introduces a few of the most useful ones for research in the language sciences.\nWe begin with the highly versatile function read.table(). The read.csv() is actually a variant of read.table(). You recall that when we called up the help file for the former using ?read.csv(), we obtained a combined help file for several functions, the first of which was read.table(). By specifying the following arguments as we did earlier, we can actually use the read.table() function to import our .csv file with exactly the same results:\n\nL1.data &lt;- read.table(file = \"data/L1_data.csv\",\n                    header = TRUE,\n                    sep = \",\",\n                    quote = \"\\\"\",\n                    dec = \".\")\n\n\n6.7.1 Tab-separated file\nIn Task 3 in Section 2.5.2, you downloaded and examined a DSV file with a .txt extension that was separated by tabs: offlinedataLearners.txt from Schimke et al. (2018).\nIf we change the separator character argument to \\t for tab, we can also import this dataset in R using the read.table() function:\n\nOfflineLearnerData &lt;- read.table(file = \"data/offlinedataLearners.txt\",\n                                        header = TRUE,\n                                        sep = \"\\t\",\n                                        dec = \".\")\n\nFor the command above to work, you will first need to save the file offlinedataLearners.txt to the folder specified in the path. Otherwise, you will get an error message informing you that there is ‚ÄúNo such file or directory‚Äù (see Section 6.6).\n\n\n6.7.2 Semi-colon-separated file\nFigure¬†6.5 displays an extract of the dataset AJT_raw_scores_L2.csv from an experimental study by Busterud et al. (2023). Although this DSV file has a .csv extension, it is actually separated by semicolons. As you can see in Figure¬†6.5, in the file AJT_raw_scores_L2.csv, the comma is used to show the decimal place.\n\n\n\n\n\n\nFigure¬†6.5: Extract of data file AJT_raw_scores_L2.csv from\n\n\n\nIf you look carefully, you will also see that this dataset has some empty cells. This data can be downloaded from https://doi.org/10.18710/JBMAPT. It is delivered with a README text file. It is good practice to include a README file when publishing datasets or code and, as the name suggests, it is always a good idea to actually read README files! üôÉ Among other things, this particular README explains that, in this dataset: ‚ÄúMissing data are represented by empty cells.‚Äù\nIf you call up the help file for the read.table() function again, you will see that there is an argument called na.strings. The default value is NA. When we import this dataset AJT_raw_scores_L2.csv from Busterud et al. (2023), we will therefore need to change this argument to ensure that empty cells are recognised as missing values.\nIn addition to the file path, the command to import this dataset specifies the separator character as the semicolon (sep = \";\"), the character used to represent decimals (dec = \",\"), and empty cells as missing values (na.strings = \"\"):\n\nAJT.raw.scores.L2 &lt;- read.table(file = \"data/AJT_raw_scores_L2.csv\",\n                          header = TRUE,\n                          sep = \";\",\n                          dec = \",\",\n                          na.strings = \"\")\n\nOnce we have run this command, we should check that the data have been correctly imported, for example by using the View() function:\n\nView(AJT.raw.scores.L2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID\nL3\nYears.of.L3\nGender\nL3.selfasses\nL3.grade\nL2.selfasses\nL2.grade\n\n\n\n\nBKRE452\n2\n4\n2\n2.5\n3\n4\n3\n\n\nSHEL876\n2\n4\n2\n3.0\n5\n6\n5\n\n\nSVI√ò510\n2\n4\n1\n4.0\n4\n6\n5\n\n\nEHEA194\n2\n4\n1\n2.0\n2\n6\n4\n\n\nERAO442\n2\n4\n2\n3.0\n3\n5\n4\n\n\nSEIO103\n2\n4\n1\n2.0\n3\n4\n3\n\n\nNMOI241\n2\n4\n1\n3.0\n4\n4\n4\n\n\nBBIE911/77\n2\n4\n1\nNA\n3\nNA\n4\n\n\nUUNO561\n2\n4\n1\n2.0\n3\n3\n4\n\n\nSMAO470\n2\n4\nNA\n3.0\nNA\n6\nNA\n\n\nSSID616\n2\n3\n1\n2.0\n2\n6\n4\n\n\nSHRI714\n2\n1\n2\n4.0\n3\n3\n3\n\n\nHALI620\n2\n1\n2\n5.0\n6\n4\n4\n\n\n\n\n\n\nHere, we can see that the data have been correctly imported as a table. The commas have been correctly converted to decimal points and the empty cells are now labelled NA.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html#sec-readr",
    "href": "6_ImpoRtingData.html#sec-readr",
    "title": "6¬† ImpoRting data",
    "section": "6.8 Using {readr} from the {tidyverse} to import tabular files",
    "text": "6.8 Using {readr} from the {tidyverse} to import tabular files\nThe {tidyverse} is a family of packages that we will use a lot in future chapters. This family of package includes the {readr} package which features some very useful functions to import data into R. You can install and load the {readr} package either individually or as part of the {tidyverse} bundle:\n\n# Install the package individually:\ninstall.packages(\"readr\")\n\n# Or install the full tidyverse (this will take a little longer):\ninstall.packages(\"tidyverse\")\n\n# Load the library:\nlibrary(readr)\n\n\nDelimiter-separated values (DSV) files\nThe {readr} package includes functions to import DSV files that are similar, but not identical to the base R functions explained above. The main difference is that the {readr} functions load data into an R object of type ‚Äútibble‚Äù rather than ‚Äúdata frame‚Äù. In practice, this will not make a difference for our work in future chapters. Hence, the following two commands can equally be used to import L1_data.csv:\n\n# Import .csv file using the base R function read.csv():\nL1.data &lt;- read.csv(file = \"data/L1_data.csv\", \n                    header = TRUE, \n                    quote = \"\\\"\")\n\nclass(L1.data)\n\n[1] \"data.frame\"\n\n# Import .csv file using the {readr} function read_csv():\nL1.data &lt;- read_csv(file = \"data/L1_data.csv\", \n                    col_names = TRUE, \n                    quote = \"\\\"\")\n\nclass(L1.data)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nNote that instead of the argument header = TRUE, the {readr} function read_csv() takes the argument col_names = TRUE, which has the same effect.\nThere are a few more differences between the two functions that are worth noting:\n\nIf the column headers in your original data file contain spaces, these will be automatically replaced by dots (.) when you import data using base R functions. By contrast, with the {readr} functions, the spaces will, by default, be retained. As we will see later, this behaviour can represent both an advantage and disadvantage, depending on what you want to do.\nThe {readr} functions are quicker and are therefore recommended if you are importing large datasets.\nIn general, the behaviour of {readr} functions is more consistent across different operating systems and locale settings (e.g., the language in which your operating system is set).\n\nNote that, just like read.csv() was a special case of read.table, the {readr} function read_csv() is a special variant of the more general function read_delim() that can be used to import data from all kinds of DSV files. Check the help file to find out all the options using ?read_delim.\nThe help file informs us that the package includes a function specifically designed to import semi-colon separated file with the the comma as the decimal point: read_csv2(). It further states that ‚Äú[t]his format is common in some European countries.‚Äù If you scroll down the help page, you will see that its usage is summarised in the following way:\nread_csv2(\n  file,\n  col_names = TRUE,\n  col_types = NULL,\n  col_select = NULL,\n  id = NULL,\n  locale = default_locale(),\n  na = c(\"\", \"NA\"),\n  quoted_na = TRUE,\n  quote = \"\\\"\",\n  comment = \"\",\n  trim_ws = TRUE,\n  skip = 0,\n  n_max = Inf,\n  guess_max = min(1000, n_max),\n  progress = show_progress(),\n  name_repair = \"unique\",\n  num_threads = readr_threads(),\n  show_col_types = should_show_types(),\n  skip_empty_rows = TRUE,\n  lazy = should_read_lazy()\n)\nThis overview of the read_csv2 function shows all of the arguments of the function and their default values. For instance, with na = c(\"\", \"NA\"), it tells us that, by default, both empty cells and cells with the value NA will be interpreted by the function as NA values.\nHaving checked the default values for all of the arguments of the read_csv2 function, we may conclude that we can safely use this {readr} function to import the file AJT_raw_scores_L2.csv from Busterud et al. (2023) without changing any of these default values. Hence, all we need is:\n\nAJT.raw.scores.L2 &lt;- read_csv2(file = \"data/AJT_raw_scores_L2.csv\")\n\nNote that, whereas when we used the base R function read.table() the header for the third variable in the file was imported as Years.of.L3, using the {readr} function, the variable is entitled Years of L3.\n\n\nFixed width files\nFixed width files (with file extensions such as .gz, .bz2 or .xz) are a less common type of data source in the language sciences. In these text-based files, the values are separated not by a specific character such as the comma or the tab, but by a set amount of white/empty space other than a tab. Fixed width files can be loaded using the read_fwf() function from {readr}. Fields can be specified by their widths with fwf_widths() or by their positions with fwf_positions().",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html#importing-files-from-spreadsheet-software",
    "href": "6_ImpoRtingData.html#importing-files-from-spreadsheet-software",
    "title": "6¬† ImpoRting data",
    "section": "6.9 Importing files from spreadsheet software",
    "text": "6.9 Importing files from spreadsheet software\nIf your data are currently stored in a spreadsheet software (e.g., LibreOffice Calc, Google Sheets, or Microsoft Excel), you can export them to .csv or .tsv. However, if you do not wish to do this (e.g., because your colleague wishes to maintain the spreadsheet format that includes formatting elements such as bold or coloured cells), there are functions to import these file formats directly into R.\n\n6.9.1 LibreOffice Calc\nFor LibreOffice Calc (which you should have installed in Section 1.2), you can install the {readODS} package and use its read_ods() function to import .ods files. Details about all the options can be found here https://www.rdocumentation.org/packages/readODS/versions/2.3.0.\n\n# Install from CRAN (safest option):\ninstall.packages(\"readODS\")\n\n# Or install the development version from Github:\nremotes::install_github(\"ropensci/readODS\")\n\n# Load the library:\nlibrary(readODS)\n\n# Import your .ods data:\nMyLibreOfficeData &lt;- read_ods(\"data/MyLibreOfficeTable.ods\",\n                            sheet = 1,\n                            col_names = TRUE,\n                            na = NA)\n\n\n\n6.9.2 Microsoft Excel\nVarious packages can be used to import Microsoft Excel file formats, but the simplest is {readxl}, which is part of the {tidyverse}. It allows users to import data in both .xlsx and the older .xls format. You can find out more about its various options here: https://readxl.tidyverse.org/.\n\n# Install from CRAN (safest option):\ninstall.packages(\"readxl\")\n\n# Or install the development version from Github:\nremotes::install_github(\"tidyverse/readxl\")\n\n# Load the library:\nlibrary(readxl)\n\n# Import your .ods data:\nMyExcelData &lt;- read_excel(\"data/MyExcelSpreadsheet.xlsx\",\n                            sheet = 1,\n                            col_names = TRUE,\n                            na = NA)\n\n\n\n6.9.3 Google Sheets\nThere are also several ways to import data from Google Sheets. The simplest is to export your tabular data as a .csv, .tsv, .xslx, or .ods file by selecting Google Sheet‚Äôs menu option ‚ÄòFile‚Äô &gt; ‚ÄòDownload‚Äô. Then, you can simply import this downloaded file in R using the corresponding function as described above.\nHowever, if you want to directly import your data from Google Sheets and be able to dynamically update the analyses that you conduct in R even as the input data is amended on Google Sheets, you can use the {googlesheets4} package (which is part of the {tidyverse}):\n\n# Install from CRAN (safest option):\ninstall.packages(\"googlesheets4\")\n\n# Or install the development version from Github:\nremotes::install_github(\"tidyverse/googlesheets4\")\n\n# Load the library:\nlibrary(googlesheets4)\n\n# Import your Google Sheets data using your (spread)sheet's URL:\nMySheetsData &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077\",\n                            sheet = 1,\n                            col_names = TRUE,\n                            na = \"NA\")\n\n# Or import your Google Sheets data using just the sheet's ID:\nMySheetsData &lt;- read_sheet(\"1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077\",\n                            sheet = 1,\n                            col_names = TRUE,\n                            na = \"NA\")\n\n\n\n\n\n\n\nFigure¬†6.6: Dialogue box to consent to the {tidyverse} API Packages having access to your Google Drive to import directly from a Google Sheet. Read this carefully before clicking on ‚ÄòContinue‚Äô.\n\n\n\n\n\n6.9.4 Importing spreadsheet files with multiple sheets/tabs\nNote that, as spreadsheet software typically allow users to have several ‚Äúsheets‚Äù or ‚Äútabs‚Äù within a file that each contains separate tables, the functions read_excel(), read_ods(), and read_sheet include an argument called sheet which allows you to specify which sheet should be imported. The default value is 1, which simply means that the first one is imported. If your sheets have names, you can also use its name as the argument value, e.g.:\n\nMyExcelData &lt;- read_excel(\"data/MyExcelSpreadsheet.xlsx\",\n                            sheet = \"raw data\",\n                            col_names = TRUE,\n                            na = NA)",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html#importing-data-files-from-spss-sas-and-stata",
    "href": "6_ImpoRtingData.html#importing-data-files-from-spss-sas-and-stata",
    "title": "6¬† ImpoRting data",
    "section": "6.10 Importing data files from SPSS, SAS and Stata",
    "text": "6.10 Importing data files from SPSS, SAS and Stata\nIf you‚Äôve recently switched from working in SPSS, SAS, or Stata (or are collaborating with someone who uses these programmes), it might be useful to know that you can also import the data files created by programmes directly into R using the {haven} package. Details of all the options can be found here: https://haven.tidyverse.org/.\n\n# Install from CRAN (safest option):\ninstall.packages(\"haven\")\n\n# Or install the development version from Github:\nremotes::install_github(\"tidyverse/haven\")\n\n# Load the library:\nlibrary(haven)\n\n# Import an SAS file\nMySASData &lt;- read_sas(\"MySASDataFile.sas7bdat\")\n\n# Import an SPSS file\nMySPSSDataFile &lt;- read_sav(\"MySPSSDataFile.sav\")\n\n# Import a Stata file\nMyStataData &lt;- read_dta(\"MyStataDataFile.dta\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html#importing-other-file-formats",
    "href": "6_ImpoRtingData.html#importing-other-file-formats",
    "title": "6¬† ImpoRting data",
    "section": "6.11 Importing other file formats",
    "text": "6.11 Importing other file formats\nIn this textbook, we will only deal with DSV files (Section 2.5.1) but, as you can imagine, there are many more R packages and functions that allow you to import all kinds of other file formats. These include .xml, .json and .html files, various database formats, and other files with complex structures (see, e.g., https://rc2e.com/inputandoutput).\nIn addition, fellow linguists are constantly developing new packages to work with file formats that are specific to our discipline. In the spirit of Open Science (see Chapter 1), many are making these packages available to the wider research community by releasing them under open licenses. For example, Linguistics M.A.¬†students Katja Wiesner and Nicolas Werner wrote an R package to facilitate the import of .eaf files generated by the annotation software ELAN (Lausberg & Sloetjes 2009) into R as part of a seminar project supervised by Dr.¬†Fahime (Fafa) Same at the University of Cologne (https://github.com/relan-package/rELAN/?tab=readme-ov-file).",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html#quick-and-dirty-aka-bad-ways-to-import-data-in-r",
    "href": "6_ImpoRtingData.html#quick-and-dirty-aka-bad-ways-to-import-data-in-r",
    "title": "6¬† ImpoRting data",
    "section": "6.12 Quick-and-dirty (aka bad!) ways to import data in R",
    "text": "6.12 Quick-and-dirty (aka bad!) ways to import data in R\nFeel free to skip this section if you got on just fine with the importing method introduced above as the following two methods are problematic for a number of reasons. However, they may come in useful in special cases, which is why both are briefly explained below.\n\n6.12.1 Hardcoding file paths in R scripts ü•¥\nWhilst it is certainly not recommended (see, e.g., Bryan 2017), it is nonetheless worth understanding this method of working with file paths in R as you may well come across it in other people‚Äôs code.\nInstead of creating an RProject to determine a project‚Äôs working directory (as we did in Section 6.3), it is possible to begin a script with a line of code that sets the working directory for the script using the function setwd(), e.g.:\n\nsetwd(\"/Users/lefoll/Documents/UzK/RstatsTextbook/Dabrowska2019\")\n\nAfterwards, data files can be imported using a relative path from the working directory just like we did earlier.\n\nL1.data &lt;- read.csv(file = \"data/L1_data.csv\")\n\nIf you have to work with an R script that uses this method, you will need to amend the path designated as the working directory by setwd() to the corresponding path on your own computer. This might not sound like much of an issue, but as data scientist, R expert, and statistics professor Jenny Bryan (2017) explains:\n\nThe chance of the setwd() command having the desired effect ‚Äì making the file paths work ‚Äì for anyone besides its author is 0%. It‚Äôs also unlikely to work for the author one or two years or computers from now. The project is not self-contained and portable.\n\nIn the language sciences, not everyone is aware of the severity of these issues. Hence, it is not uncommon for researchers to make their scripts even less reproducible by not setting a working directory at all and, instead, relying exclusively on absolute paths (Section 3.3). Hence, every time they want to import data (and, as we will see later on, export objects from R, too), they write out the full file path in the command like this:\n\nL1.data &lt;- read.csv(file = \"/Users/lefoll/Documents/UzK/RstatsTextbook/Dabrowska2019/data/L1_data.csv\")\n\nHaving to work with such a script is particularly laborious because it means that, if you inherit such a script from a colleague, you will have to manually change every single file path in the script to the corresponding file paths on your own computer. And, as Bryan (2017) points out, this will also apply if you change anything in your own computer directory structure! I hope I‚Äôve made clear that the potential for making errors in the process is far too important to even consider going down that route.\nHowever, should you have to use this method at some point for whatever reason, you can make use of Section 3.3 which explained how to copy full file paths from a file Explorer or Finder window. Note that if there are spaces or other special characters other than _ or - anywhere in your file path, your import command will fail (see Section 3.2 on naming conventions for folders and files). The following command, for instance, will fail and return an error (see Figure¬†6.7) because the folder ‚ÄúUni Work‚Äù contains a space.\n\nL1.data &lt;- read.csv(file = \"/Users/lefoll/Documents/Uni Work/RstatsTextbook/Dabrowska2019/data/L1_data.csv\")\n\n\n\n\n\n\n\nFigure¬†6.7: Error message due to an error in the file path\n\n\n\nThe only way to fix this issue is to remove the space in the name of the folder (in your File Finder or Navigator window) and then amend the file path in your R script accordingly.\n\n\n6.12.2 Importing data using RStudio‚Äôs GUI ü´§\nYou may have noticed that, if you click on a data file from the Files pane in RStudio (Figure¬†6.8), RStudio will offer to import the dataset for you. This looks like (and genuinely is) a very convenient way to import data in an R session using RStudio‚Äôs GUI (graphical user interface).\n\n\n\n\n\n\nFigure¬†6.8: Importing a file from RStudio‚Äôs File pane\n\n\n\nClicking on ‚ÄòImport Dataset‚Äô opens up RStudio‚Äôs ‚ÄòImport Text Data‚Äô dialogue box, which is similar to the one that we saw in LibreOffice Calc (Section 2.5.2). It allows you to select the relevant options to correctly import the file and displays a preview to check that the options that you have selected are correct. You can also specify the name of the R object to which you want to assign the imported data. By default, the name of the data file (minus the file extension and any special characters) is suggested.\n\n\n\n\n\n\nFigure¬†6.9: RStudio‚Äôs ‚ÄòImport Text Data‚Äô dialogue\n\n\n\nAs soon as you click on the ‚ÄòImport‚Äô button, the data is imported and opened using the View() function for you to check the sanity of the data.\nThis importing method works a treat, so what‚Äôs not to like? Well, the first problem is that you are not in full control. You cannot select which import function is used; RStudio decides for you. You may have noticed that it chooses to use the {readr} import functions, rather than the base R ones. There are lots of good reasons to use the {readr} functions (see Section 6.8), but it may not be what you wanted to do. When we do research, it is important for us to be in control of every step of the analysis process.\nSecond, your data import settings are not saved in an .R script as the commands were only sent to the Console: they are part of your script. This means that if you import your data in this way, do some analyses, and then close RStudio, you will have no way of knowing with which settings you imported the data to obtain the results of your analysis! This can have serious consequences for the reproducibility of your work.\nWhilst there is no way of remedying the first issue, the second can easily be fixed. After you have successfully imported your data from RStudio‚Äôs Files pane, you can (and should!) immediately copy the import commands from the Console into your .R script. In this way, the next time you want to re-run your analysis, you can begin by running these import commands directly from your .R script rather than by via RStudio‚Äôs Files pane.\nIf you are running into errors due to incorrect file paths, it can be useful to try to import your data using RStudio‚Äôs GUI to see where you are going wrong by comparing your own attempts with the import commands that RStudio generated.\n\n\n\n\nBarrett, Malcolm. 2018. Why should i use the here package when i‚Äôm already using projects? - malcolm barrett. https://malco.io/articles/2018-11-05-why-should-i-use-the-here-package-when-i-m-already-using-projects.\n\n\nBryan, Jennifer. 2018. Let‚Äôs git started | happy git and GitHub for the useR. Open Education Resource. https://happygitwithr.com/.\n\n\nBryan, Jenny. 2017. Project-oriented workflow. Tidyverse.org. https://www.tidyverse.org/blog/2017/12/workflow-vs-script/.\n\n\nBusterud, Guro, Anne Dahl, Dave Kush & Kjersti Faldet Listhaug. 2023. Verb placement in L3 french and L3 german: The role of language-internal factors in determining cross-linguistic influence from prior languages. Linguistic Approaches to Bilingualism. John 13(5). 693‚Äì716. https://doi.org/10.1075/lab.22058.bus.\n\n\nDƒÖbrowska, Ewa. 2019. Experience, aptitude, and individual differences in linguistic attainment: A comparison of native and nonnative speakers. Language Learning 69(S1). 72‚Äì100. https://doi.org/10.1111/lang.12323.\n\n\nLausberg, Hedda & Han Sloetjes. 2009. Coding gestural behavior with the NEUROGES-ELAN system. Behavior Research Methods 41(3). 841‚Äì849. https://doi.org/10.3758/BRM.41.3.841.\n\n\nParsons, Sam, Fl√°vio Azevedo, Mahmoud M. Elsherif, Samuel Guay, Owen N. Shahim, Gisela H. Govaart, Emma Norris, et al. 2022. A community-sourced glossary of open scholarship terms. Nature Human Behaviour. Nature 6(3). 312‚Äì318. https://doi.org/10.1038/s41562-021-01269-4.\n\n\nSchimke, Sarah, Israel de la Fuente, Barbara Hemforth & Saveria Colonna. 2018. First language influence on second language offline and online ambiguous pronoun resolution. Language Learning 68(3). 744‚Äì779. https://doi.org/10.1111/lang.12293.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "6_ImpoRtingData.html#footnotes",
    "href": "6_ImpoRtingData.html#footnotes",
    "title": "6¬† ImpoRting data",
    "section": "",
    "text": "‚ÄúDigital Object Identifiers (DOI) are alpha-numeric strings that can be assigned to any entity, including: publications (including preprints), materials, datasets, and feature films - the use of DOIs is not restricted to just scholarly or academic material. DOIs ‚Äúprovides a system for persistent and actionable identification and interoperable exchange of managed information on digital networks.‚Äù (https://doi.org/hb.html). There are many different DOI registration agencies that operate DOIs, but the two that researchers would most likely encounter are Crossref and Datacite.‚Äù (Parsons et al. 2022)‚Ü©Ô∏é\nNote that, unlike the functions that we have used so far, the View() function begins with a capital letter. R is a case-sensitive programming language, which means that view() and View() are not the same thing!‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Impo`R`ting data</span>"
    ]
  },
  {
    "objectID": "7_VariablesFunctions.html",
    "href": "7_VariablesFunctions.html",
    "title": "7¬† VaRiables and functions",
    "section": "",
    "text": "Chapter overview\nIn this chapter, you will learn how to:",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Va`R`iables and functions</span>"
    ]
  },
  {
    "objectID": "7_VariablesFunctions.html#inspecting-a-dataset-in-r",
    "href": "7_VariablesFunctions.html#inspecting-a-dataset-in-r",
    "title": "7¬† VaRiables and functions",
    "section": "7.1 Inspecting a dataset in R",
    "text": "7.1 Inspecting a dataset in R\nIn Section 6.6, we saw that we can use the View() function to display tabular data in a format that resembles that of a spreadsheet programme (see Figure¬†7.1).\nThe two datasets from DƒÖbrowska (2019) are both long and wide so you will need to scroll in both directions to view all the data. RStudio also provides a filter option and a search tool (see Figure¬†7.1). Note that both of these tools can only be used to visually inspect the data. You cannot alter the dataset in any way using these tools (and that‚Äôs a good thing!).\n\nView(L1.data)\n\n\n\n\n\n\n\nFigure¬†7.1: The L1.data object as visualised using the View() function in RStudio\n\n\n\n\n\n\n\n\n\nQuiz time!\n\n\n\nQ1. The View() function is more user-friendly than attempting to examine the full table in the Console. Try to display the full L2.dataset in the Console by using the command L2.data which is shorthand for print(L2.data). What happens?\n\n\n\n\nThe R Console prints out all the data, but not the column headers.\n\n\nR produces an error message because there are too many rows and the Console window is not long enough.\n\n\nThe R Console prints the data in a randomly jumbled way.\n\n\nR only displays the first 22 rows and the columns are not aligned because the Console window is not wide enough.\n\n\n\n\n\n\n\nüòá Hover for a hint\n\n\n\n\n¬†\n\n\nIn practice, it is often useful to printing subsets of a dataset in the Console to quickly check the sanity of the data. To do so, we can use the function head() that prints the first six rows of a tabular dataset.\n\nhead(L1.data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParticipant\nAge\nGender\nOccupation\nOccupGroup\nOtherLgs\nEducation\nEduYrs\nReadEng1\nReadEng2\nReadEng3\nReadEng\nActive\nObjCl\nObjRel\nPassive\nPostmod\nQ.has\nQ.is\nLocative\nSubCl\nSubRel\nGrammarR\nGrammar\nVocabR\nVocab\nCollocR\nColloc\nBlocks\nART\nLgAnalysis\n\n\n\n\n1\n21\nM\nStudent\nPS\nNone\n3rd year of BA\n17\n1\n2\n2\n5\n8\n8\n8\n8\n8\n8\n6\n8\n8\n8\n78\n95.0\n48\n73.33333\n30\n68.750\n16\n17\n15\n\n\n2\n38\nM\nStudent/Support Worker\nPS\nNone\nNVQ IV Music Performance\n13\n1\n2\n3\n6\n8\n8\n8\n8\n8\n8\n7\n8\n8\n8\n79\n97.5\n58\n95.55556\n35\n84.375\n11\n31\n13\n\n\n3\n55\nM\nRetired\nI\nNone\nNo formal (City and Guilds)\n11\n3\n3\n4\n10\n8\n8\n8\n8\n8\n7\n8\n8\n8\n8\n79\n97.5\n58\n95.55556\n31\n71.875\n5\n38\n5\n\n\n4\n26\nF\nWeb designer\nPS\nNone\nBA Fine Art\n17\n3\n3\n3\n9\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n80\n100.0\n53\n84.44444\n37\n90.625\n20\n26\n15\n\n\n5\n55\nF\nHomemaker\nI\nNone\nO‚ÄôLevels\n12\n3\n2\n3\n8\n8\n8\n8\n8\n8\n8\n7\n8\n8\n8\n79\n97.5\n55\n88.88889\n36\n87.500\n16\n31\n14\n\n\n6\n58\nF\nRetired\nI\nNone\nO‚ÄôLevels\n12\n1\n1\n2\n4\n8\n5\n1\n8\n8\n7\n6\n7\n8\n8\n66\n65.0\n48\n73.33333\n21\n40.625\n8\n15\n3\n\n\n\n\n\n\n\n\n\n\n\n\nQuiz time!\n\n\n\nQ2. Six is the default number of rows printed by the head() function. Have a look at the function‚Äôs help file using the command ?head to find out how to change this default setting. How would you get R to print the first 10 lines of L2.data?\n\n\n\n\nhead(L2.data, 10)\n\n\nhead(L2.data, n = 10L)\n\n\nhead(L2.data, rows = 10)\n\n\nhead(L2.data, n = 10)\n\n\nhead(L2.data n = 10L)\n\n\nhead(L2.data, L = 10)\n\n\n\n\n\n\n\nüòá Hover for a hint",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Va`R`iables and functions</span>"
    ]
  },
  {
    "objectID": "7_VariablesFunctions.html#working-with-variables",
    "href": "7_VariablesFunctions.html#working-with-variables",
    "title": "7¬† VaRiables and functions",
    "section": "7.2 Working with variables",
    "text": "7.2 Working with variables\n\n7.2.1 Types of variables\nIn statistics, we differentiate between numeric (or quantitative) and categorical (or qualitative) variables. Each variable type can be subdivided into different subtypes. It is very important to understand the differences between these types of data as we frequently have to use different statistics and visualisations depending on the type(s) of variable(s) that we are dealing with.\nSome numeric variables are continuous: they contain measured data that, at least theoretically, can have an infinite number of values within a range (e.g., time). In practice, however the number of possible values depends on the precision of the measurement (e.g., are we measuring time in years, as in the age of adults, or milliseconds, as in participants‚Äô reaction times in a linguistic experiment). Numeric variables for which only a defined set of values are possible are called discrete variables (e.g., number of occurrences of a word in a corpus). Most often, discrete numeric variables represent counts of something.\n\n\n\n\n\nCategorical variables can be nominal or ordinal. Nominal variables contain unordered categorical values (e.g., participants‚Äô mother tongue or nationality), whereas ordinal variables have categorical values that can be ordered meaningfully (e.g., participants‚Äô proficiency in a specific language where the values beginner, intermediate and advanced or A1, A2, B1, B2, C1 and C2 have a meaningful order). However, the difference between each category (or level) is not necessarily equal. Binary variables are a special case of nominal variable which only has two mutually exclusive outcomes (e.g., true or false in a quiz question).\n\n\n\n\n\n\n\nQuiz time!\n\n\n\nQ3. Which type of variable is stored in the Occupation column in L1.data?\n\n\n\n\nDiscrete\n\n\nBinary\n\n\nContinuous\n\n\nOther\n\n\nNominal\n\n\n\n\n\n\n\n¬†\nQ4. Which type of variable is stored in the Gender column in L1.data?\n\n\n\n\nOther\n\n\nContinuous\n\n\nDiscrete\n\n\nNominal\n\n\nBinary\n\n\n\n\n\n\n\n¬†\nQ5. Which type of variable is stored in the column VocabR in L1.data?\n\n\n\n\nOther\n\n\nNominal\n\n\nContinuous\n\n\nDiscrete\n\n\nBinary\n\n\n\n\n\n\n\n¬†\n\n\n\n\n7.2.2 Inspecting variables in R\nIn tidy data tabular formats (see Chapter 8), each row corresponds to one observation and each column to a variable. Each cell, therefore, corresponds to a single data point, which is the value of a specific variable (column) for a specific observation (row). As we will see in the following chapters, this data structure allows for efficient and intuitive data manipulation, analysis, and visualisation.\nThe names() functions returns the names of all of the columns of a data frame. Given that the datasets from DƒÖbrowska (2019) are ‚Äòtidy‚Äô, this means that names(L1.data) returns a list of all the column names in the L1 dataset.\n\nnames(L1.data)\n\n [1] \"Participant\" \"Age\"         \"Gender\"      \"Occupation\"  \"OccupGroup\" \n [6] \"OtherLgs\"    \"Education\"   \"EduYrs\"      \"ReadEng1\"    \"ReadEng2\"   \n[11] \"ReadEng3\"    \"ReadEng\"     \"Active\"      \"ObjCl\"       \"ObjRel\"     \n[16] \"Passive\"     \"Postmod\"     \"Q.has\"       \"Q.is\"        \"Locative\"   \n[21] \"SubCl\"       \"SubRel\"      \"GrammarR\"    \"Grammar\"     \"VocabR\"     \n[26] \"Vocab\"       \"CollocR\"     \"Colloc\"      \"Blocks\"      \"ART\"        \n[31] \"LgAnalysis\" \n\n\n\n\n7.2.3 R data types\nA useful way to get a quick and informative overview of a large dataset is to use the function str(), which was mentioned in Section 6.6. It returns the ‚Äúinternal structure‚Äù of any R object. It is particular useful for large tables with many columns\n\nstr(L1.data)\n\n'data.frame':   90 obs. of  31 variables:\n $ Participant: chr  \"1\" \"2\" \"3\" \"4\" ...\n $ Age        : int  21 38 55 26 55 58 31 58 42 59 ...\n $ Gender     : chr  \"M\" \"M\" \"M\" \"F\" ...\n $ Occupation : chr  \"Student\" \"Student/Support Worker\" \"Retired\" \"Web designer\" ...\n $ OccupGroup : chr  \"PS\" \"PS\" \"I\" \"PS\" ...\n $ OtherLgs   : chr  \"None\" \"None\" \"None\" \"None\" ...\n $ Education  : chr  \"3rd year of BA\" \"NVQ IV Music Performance\" \"No formal (City and Guilds)\" \"BA Fine Art\" ...\n $ EduYrs     : int  17 13 11 17 12 12 13 11 11 11 ...\n $ ReadEng1   : int  1 1 3 3 3 1 3 2 1 2 ...\n $ ReadEng2   : int  2 2 3 3 2 1 2 2 1 2 ...\n $ ReadEng3   : int  2 3 4 3 3 2 3 3 1 2 ...\n $ ReadEng    : int  5 6 10 9 8 4 8 7 3 6 ...\n $ Active     : int  8 8 8 8 8 8 7 8 8 8 ...\n $ ObjCl      : int  8 8 8 8 8 5 8 4 7 5 ...\n $ ObjRel     : int  8 8 8 8 8 1 8 8 3 8 ...\n $ Passive    : int  8 8 8 8 8 8 8 8 2 8 ...\n $ Postmod    : int  8 8 8 8 8 8 7 7 6 8 ...\n $ Q.has      : int  8 8 7 8 8 7 8 1 3 0 ...\n $ Q.is       : int  6 7 8 8 7 6 7 8 7 8 ...\n $ Locative   : int  8 8 8 8 8 7 8 8 8 8 ...\n $ SubCl      : int  8 8 8 8 8 8 8 8 7 8 ...\n $ SubRel     : int  8 8 8 8 8 8 8 8 7 8 ...\n $ GrammarR   : int  78 79 79 80 79 66 77 68 58 69 ...\n $ Grammar    : num  95 97.5 97.5 100 97.5 65 92.5 70 45 72.5 ...\n $ VocabR     : int  48 58 58 53 55 48 39 48 31 42 ...\n $ Vocab      : num  73.3 95.6 95.6 84.4 88.9 ...\n $ CollocR    : int  30 35 31 37 36 21 29 33 22 29 ...\n $ Colloc     : num  68.8 84.4 71.9 90.6 87.5 ...\n $ Blocks     : int  16 11 5 20 16 8 8 10 7 9 ...\n $ ART        : int  17 31 38 26 31 15 7 10 6 6 ...\n $ LgAnalysis : int  15 13 5 15 14 3 4 5 2 6 ...\n\n\nAt the top of its output, the function str(L1.data) first informs us that L1.data is a data frame object, consisting of 90 observations (i.e.¬†rows) and 31 variables (i.e.¬†columns). Then, it returns a list of all of the variables included in this data frame. Each line starts with a $ sign and corresponds to one column First, the name of the column (e.g.¬†Occupation) is printed, followed by the column‚Äôs R data type (e.g.¬†chr for a character string vector), and then its values for the first few rows of the table (e.g.¬†we can see that the first participant in this dataset was a ‚ÄúStudent‚Äù and the second a ‚ÄúStudent/Support Worker‚Äù).\nCompare the outputs of the str() and head() functions in the Console with that of the View() function to understand the different ways in which the same dataset can be examined in RStudio.\n\n\n\n\n\n\nQuiz time!\n\n\n\nQ6. Use the str() function to examine the internal structure of the L2 dataset. How many columns are there in the L2 dataset?\n\n\n\n\n\n\n\n\n\n\n¬†\nQ7. Which of these columns can be found in the L2 dataset, but not the L1 one?\n\n\n\n\nEngWork\n\n\nOtherLgs\n\n\nArrival\n\n\nFirstExp\n\n\nNativeLg\n\n\nEduYrs\n\n\n\n\n\n\n\nüòá Hover for a hint\n\n\n\n\n¬†\nQ8. Which type of R object is the variable Arrival stored as?\n\n\n\n\nintelligence\n\n\ndigit\n\n\nindex\n\n\ninterest\n\n\nstring character\n\n\ninteger\n\n\n\n\n\n\n\nüòá Hover for a hint\n\n\n\n\n¬†\nQ9. How old was the third participant listed in the L2 dataset when they first moved to an English-speaking country?\n\n\n\n\n\n\n\n\n\n\nüòá Hover for a hint\n\n\n\n\n¬†\nQ10. In both datasets, the column Participant contains anonymised participant IDs. Why is the variable Participant stored as string character vector in L1.data, but as an integer vector in L2.data?\n\n\n\n\nBecause the L1 participants' IDs only contain whole numbers with no decimal points.\n\n\nBecause there are more L1 participants than L2 participants.\n\n\nBecause some of the L1 participants' IDs contain letters as well as numbers.\n\n\nBecause the L1 participants' IDs are written out as words rather than digits.\n\n\n\n\n\n\n\nüòá Hover for a hint\n\n\n\n\n¬†\n\n\n\n\n7.2.4 Accessing individual columns in R\nWe can call up individual columns within a data frame using the $ operator. This displays all of the participants‚Äô values for this one variable. As shown below, this works for any type of data.\n\nL1.data$Gender\n\n [1] \"M\" \"M\" \"M\" \"F\" \"F\" \"F\" \"F\" \"M\" \"M\" \"F\" \"F\" \"M\" \"M\" \"F\" \"M\" \"F\" \"M\" \"F\" \"F\"\n[20] \"F\" \"F\" \"F\" \"F\" \"F\" \"F\" \"M\" \"F\" \"M\" \"F\" \"M\" \"F\" \"F\" \"F\" \"M\" \"F\" \"F\" \"M\" \"F\"\n[39] \"F\" \"F\" \"F\" \"F\" \"M\" \"M\" \"F\" \"F\" \"M\" \"F\" \"F\" \"F\" \"F\" \"F\" \"F\" \"F\" \"M\" \"M\" \"M\"\n[58] \"F\" \"F\" \"M\" \"M\" \"M\" \"M\" \"F\" \"M\" \"M\" \"M\" \"M\" \"M\" \"M\" \"M\" \"M\" \"F\" \"M\" \"F\" \"F\"\n[77] \"M\" \"M\" \"M\" \"F\" \"F\" \"M\" \"M\" \"F\" \"F\" \"M\" \"M\" \"M\" \"F\" \"M\"\n\nL1.data$Age\n\n [1] 21 38 55 26 55 58 31 58 42 59 32 27 60 51 32 29 41 57 60 18 41 60 21 25 26\n[26] 60 57 60 52 25 23 42 59 30 21 21 60 51 62 65 19 65 29 38 37 42 20 32 29 29\n[51] 27 28 29 25 33 25 25 25 52 25 53 22 65 60 61 65 65 61 30 30 32 30 39 29 55\n[76] 18 32 31 20 38 44 18 17 17 17 17 17 17 17 17\n\n\nBefore doing any data analysis, it is crucial to carefully visually examine the data to spot any problems. Ask yourself:\n\nDo the values look plausible?\nAre there any missing values?\n\nLooking at the Gender and Age variables, we can see that all the L1 participants declared being either ‚Äòmale‚Äô (\"M\") or ‚Äòfemale‚Äô (\"F\"), that the youngest were 17 years old, and that no participant was improbably old. A single improbable value is likely to be the result of a data entry error, e.g.¬†a participant or researcher entered 188 as an age, instead of 18. If you spot lots of improbable or outright weird values (e.g.¬†C, I and PS as age values!), something is likely to have gone wrong during the data import process (see Section 6.6).\nJust like we can save individual numbers and words as R objects to our R environment, we can also save individual variables as individual R objects. As we saw in Section 5.3, in this case, the values of the variable are not printed in the Console, but rather saved to our R environment.\n\nL1.Occupation &lt;- L1.data$Occupation\n\nIf we want to display the content of this variable, we must print our new R object by calling it up with its name, e.g.¬†L1.Occupation. Try it out! As listing all of the all of the L1 participant‚Äôs jobs makes for a very long list, below, we only display the first six values using the head() function.\n\nhead(L1.Occupation)\n\n[1] \"Student\"                \"Student/Support Worker\" \"Retired\"               \n[4] \"Web designer\"           \"Homemaker\"              \"Retired\"",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Va`R`iables and functions</span>"
    ]
  },
  {
    "objectID": "7_VariablesFunctions.html#sec-SquareBrackets",
    "href": "7_VariablesFunctions.html#sec-SquareBrackets",
    "title": "7¬† VaRiables and functions",
    "section": "7.3 Accessing individual data points in R",
    "text": "7.3 Accessing individual data points in R\nWe can also access individual data points from a variable using the index operator, the square brackets ([]). For example, we can access the Occupation value for the fourth L1 participant by specifying that we only want the fourth element of the R object L1.Occupation.\n\nL1.Occupation[4]\n\n[1] \"Web designer\"\n\n\nWe can also do this from the L1.data data frame object directly. To this end, we use a combination of the $ and the [] operators.\n\nL1.data$Occupation[4]\n\n[1] \"Web designer\"\n\n\nWe can access a continuous range of data points using the : operator.\n\nL1.data$Occupation[10:15]\n\n[1] \"Housewife\"             \"Admin Assistant\"       \"Content Editor\"       \n[4] \"School Crossing Guard\" \"Carer/Cleaner\"         \"IT Support\"           \n\n\nOr, if they are not continuous, we can list the numbers of the values that we are interesting in using the combine function (c()) and commas separating each index value.\n\nL1.data$Occupation[c(11,13,29,90)]\n\n[1] \"Admin Assistant\"       \"School Crossing Guard\" \"Dental Nurse\"         \n[4] \"Student\"              \n\n\nIt is also possible to access data points from a table by specifying both the number of the row and the number of the column of the relevant data point(s) using the following pattern:\n[row,column]\nFor example, given that we know that Occupation is stored in the fourth column of L1.data, we can find out the occupation of the L1 participant in the 60th row of the dataset like this:\n\nL1.data[60,4]\n\n[1] \"Train Driver\"\n\n\nAll of these approaches can be combined. For example, here we access the values of the second, third, and fourth columns for the 11th, 13th, 29th, and 90th L1 participants.\n\nL1.data[c(11,13,29,90),2:4]\n\n   Age Gender            Occupation\n11  32      F       Admin Assistant\n13  60      M School Crossing Guard\n29  52      F          Dental Nurse\n90  17      M               Student\n\n\n\n\n\n\n\n\nQuiz time!\n\n\n\nThe following two quiz questions focus on the NativeLg variables from the L2 dataset (L2.data).\nQ11. Use the index operators to find out the native language of the 26th L2 participant.\n\n\n\n\nCantonese\nChinese\nGerman\nItalian\nGreek\nLithuanian\nMandarin\nPolish\nRussian\nSpanish\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\nQ12. Which command(s) can you use to display only the Gender, Occupation, Native language, and Age of the last participant listed in the L2 dataset?\n\n\n\n\nL2.data[-1:c(2,3,5,9)]\n\n\nL2.data[67,c(2:3,5,9)]\n\n\nL2.data[67,c(2,3,5,9)]\n\n\nL2.data[90,c(2:3,5,9)]\n\n\nL2.data[67 , c(2,3,5,9)]\n\n\nL2.data[67:c(2,3,5,9)]\n\n\n\n\n\n\n\nüòá Hover for a hint",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Va`R`iables and functions</span>"
    ]
  },
  {
    "objectID": "7_VariablesFunctions.html#sec-RFunctions",
    "href": "7_VariablesFunctions.html#sec-RFunctions",
    "title": "7¬† VaRiables and functions",
    "section": "7.4 Using built-in R functions",
    "text": "7.4 Using built-in R functions\nWe know from our examination of the L1 dataset from DƒÖbrowska (2019) that it includes 90 English native speaker participants. To find out their mean average age, we could add up all of their ages and divide the sum by 90 (see Section 8.1 for more ways to report the central tendency of a variable).\n\n(21 + 38 + 55 + 26 + 55 + 58 + 31 + 58 + 42 + 59 + 32 + 27 + 60 + 51 + 32 + 29 + 41 + 57 + 60 + 18 + 41 + 60 + 21 + 25 + 26 + 60 + 57 + 60 + 52 + 25 + 23 + 42 + 59 + 30 + 21 + 21 + 60 + 51 + 62 + 65 + 19 + 65 + 29 + 38 + 37 + 42 + 20 + 32 + 29 + 29 + 27 + 28 + 29 + 25 + 33 + 25 + 25 + 25 + 52 + 25 + 53 + 22 + 65 + 60 + 61 + 65 + 65 + 61 + 30 + 30 + 32 + 30 + 39 + 29 + 55 + 18 + 32 + 31 + 20 + 38 + 44 + 18 + 17 + 17 + 17 + 17 + 17 + 17 + 17 + 17) / 90\n\n[1] 37.54444\n\n\nOf course, we would much rather not write all of this out! Especially, as we are very likely to make errors in the process. Instead, we can use the base R function sum() to add up all of the L1 participant‚Äôs ages and divide that by 90.\n\nsum(L1.data$Age) / 90\n\n[1] 37.54444\n\n\nThis already looks much better, but it‚Äôs still less than ideal: What if we decided to exclude some participants (e.g., because they did not complete all of the experimental tasks)? Or decided to add data from more participants? In both these cases, 90 will no longer be the correct denominator to calculate their average age! That‚Äôs why it is better to work out the denominator by computing the total number of values in the variable of interest. To this end, we can use the length() function, which returns the number of values in any given vector.\n\nlength(L1.data$Age)\n\n[1] 90\n\n\nWe can then combine the sum() and the length() functions to calculate the participants‚Äô average age.\n\nsum(L1.data$Age) / length(L1.data$Age)\n\n[1] 37.54444\n\n\nBase R includes lots of useful functions, especially to do statistics. Hence, it will come as no surprise to find that there is a built-in function to calculate mean average values. It is called mean() and is very simple to use.\n\nmean(L1.data$Age)\n\n[1] 37.54444\n\n\nIf you save the values of a variable to your R session environment, you do not need to use the name of the dataset and the $ sign to calculate its mean. Instead, you can directly apply the mean() function to the stored R object.\n\n# Saving the values of the Age variable to a new R object called L1.Age:\nL1.Age &lt;- L1.data$Age\n\n# Applying the mean() function to this new R object:\nmean(L1.Age)\n\n[1] 37.54444\n\n\n\n\n\n\n\n\nQuiz time!\n\n\n\nQ13. How does the average age of the L2 participants in DƒÖbrowska (2019) compare to that of the L1 participants?\n\n\n\n\nAge is not comparable across two different datasets.\n\n\nOn average, the L2 participants are younger than the L1 participants.\n\n\nOn average, the L2 participants are older than the L1 participants.\n\n\nOn average, the L2 participants are the same age than the L1 participants.\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\nTask 1\n\n\n\nFor this task, you first need to check that you have saved the following two variables from the L1 dataset to your R environment.\n\nL1.Age &lt;- L1.data$Age\nL1.Occupation &lt;- L1.data$Occupation\n\n1) Below is a list of useful base R functions. Try them out with the variable L1.Age. What does each function do? Make a note by writing a comment next to each command (see Section 5.4.4). The first one has been done for you.\n\nmean(L1.Age) # The mean() function returns the mean average of a set of number.\nmin()\nmax()\nsort()\nlength()\nmode()\nclass()\ntable()\nsummary()\n\n2) Age is a numeric variable. What happens if you try these same functions with a character string variable? Find out by trying them out with the variable L1.Occupation which contains words rather than numbers.\n¬†\n\n\n\n\n\n\n\n\nClick here for the solutions to Task 1\n\n\n\n\n\nAs you will have seen, often the clue is in the name of the function - but not always! üòâ\n\nmean(L1.Age) # The mean() function returns the mean average of a set of number.\nmean(L1.Occupation) # It does not make sense to calculate a mean average value of a set of words, therefore R returns an 'NA' (not applicable) and a warning in red explaining that the mean() function expects a numeric or logical argument.\n\nmin(L1.Age) # For a numeric variable, min() returns the lowest numeric value.\nmin(L1.Occupation) # For a string variable, min() returns the first value sorted alphabetically.\n\nmax(L1.Age) # For a numeric variable, min() returns the highest numeric value.\nmax(L1.Occupation) # For a string variable, max() returns the last value sorted alphabetically.\n\nsort(L1.Age) # For a numeric variable, sort() returns all of the values of the variable ordered from the smallest to the largest.\nsort(L1.Occupation) # For a string variable, sort() returns of all of the values of the variable in alphabetical order.\n\nlength(L1.Age) # The function length() returns the number of values in the variable.\nlength(L1.Occupation) # The function length() returns the number of values in the variable.\n\nmode(L1.Age) # The function mode() returns the R data type that the variable is stored as.\nmode(L1.Occupation) # The function mode() returns the R data type that the variable is stored as.\n\nclass(L1.Age) # The function mode() returns the R object class that the variable is stored as.\nclass(L1.Occupation) # The function mode() returns the R object class that the variable is stored as.\n\ntable(L1.Age) # For a numeric variable, the function table() outputs a table that tallies the number of occurrences of each unique value in a set of values and sorts them in ascending order.\ntable(L1.Occupation) # For a string variable, the function table() outputs a table that tallies the number of occurrences of each unique value in a set of values and sorts them alphabetically.\n\nsummary(L1.Age) # For a numeric variable, the function summary() outputs six values that, together, summarise the set of values contained in this variable: the minimum and maximum values, the first and third quartiles (more on this in Chapter *), and the mean and median (more on this in Chapter *).\nsummary(L1.Occupation) # For a string variable, the summary() function only outputs the length of the string vector, its object class and data mode. \n\n\n\n\n\n7.4.1 Function arguments\nAll of the functions that we have looked at this chapter so far work with just a single argument: either a vector of values (e.g.¬†a variable from our dataset as in mean(L1.data$Age)) or an entire tabular dataset (e.g.¬†str(L1.data)). When we looked at the head() function, we saw that, per default, it displays the first six rows but that we can change this by specifying a second argument in the function. In R, arguments within a function are always separated by a comma.\n\nhead(L1.Age, n = 6)\n\n[1] 21 38 55 26 55 58\n\n\nThe names of the argument can be specified but do not have to be if they are listed in the order specified in the documentation. You can check the ‚ÄòUsage‚Äô section of a function‚Äôs help file (e.g.¬†using help(head) function or ?head) to find out the order of the arguments. Run the following commands and compare their output:\n\nhead(x = L1.Age, n = 6)\nhead(L1.Age, 6)\nhead(n = 6, x = L1.Age)\nhead(6, L1.Age)\n\nWhilst the first three return exactly the same output, the fourth returns an error because the argument names are not specified and are not in the order specified in the function‚Äôs help file. To avoid making errors and confusing your collaborators and/or future self, it‚Äôs good practice to explicitly name all the arguments except the most obvious ones.\n\n\n\n\n\n\nQuiz time!\n\n\n\nLook at the two lines of code and their outputs below.\n\nL1.data$Vocab\n\n [1] 73.333333 95.555556 95.555556 84.444444 88.888889 73.333333 53.333333\n [8] 73.333333 35.555556 60.000000 40.000000 95.555556 86.666667 53.333333\n[15] 88.888889 46.666667 86.666667 84.444444 86.666667 77.777778 93.333333\n[22] 91.111111 68.888889 82.222222 75.555556 80.000000 86.666667 88.888889\n[29] 75.555556 57.777778 88.888889 95.555556 60.000000 77.777778 55.555556\n[36] 80.000000 88.888889 93.333333 93.333333 95.555556 75.555556 77.777778\n[43] 82.222222 80.000000 44.444444 62.222222 57.777778 93.333333 57.777778\n[50] 66.666667 48.888889 77.777778 51.111111 68.888889 80.000000 80.000000\n[57] 55.555556 77.777778 80.000000 82.222222 91.111111 71.111111 28.888889\n[64] 82.222222 80.000000 62.222222 95.555556 68.888889 13.333333  8.888889\n[71] 26.666667 37.777778 55.555556 82.222222 86.666667 40.000000 86.666667\n[78] 71.111111 46.666667 64.444444 60.000000 22.222222 64.444444 48.888889\n[85] 42.222222 60.000000 53.333333 42.222222 51.111111 68.888889\n\nround(L1.data$Vocab)\n\n [1] 73 96 96 84 89 73 53 73 36 60 40 96 87 53 89 47 87 84 87 78 93 91 69 82 76\n[26] 80 87 89 76 58 89 96 60 78 56 80 89 93 93 96 76 78 82 80 44 62 58 93 58 67\n[51] 49 78 51 69 80 80 56 78 80 82 91 71 29 82 80 62 96 69 13  9 27 38 56 82 87\n[76] 40 87 71 47 64 60 22 64 49 42 60 53 42 51 69\n\n\nQ14. Based on your observations, what does the round() function do?\n\n\n\n\nThe round() function rounds off numbers to the nearest whole number.\n\n\nThe round() function is designed to save screen space for smaller displays.\n\n\nThe round() function displays just the first two digits of any number.\n\n\nThe round() function displays fewer values for ease of reading.\n\n\n\n\n\n\n\n¬†\nQ15. Check out the ‚ÄòUsage‚Äô section of the help file on the round() function to find out how to round the Vocab values in the L1 dataset to two decimal places. How can this be achieved?\n\n\n\n\nround(L1.data$Vocab, 2)\n\n\nround(L1.data$Vocab, digits = -4)\n\n\nround(L1.data$Vocab: digits = 2)\n\n\nround(L1.data$Vocab, digits = 2)\n\n\n\n\n\n\n\nüòá Hover for a hint",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Va`R`iables and functions</span>"
    ]
  },
  {
    "objectID": "7_VariablesFunctions.html#combining-functions-in-r",
    "href": "7_VariablesFunctions.html#combining-functions-in-r",
    "title": "7¬† VaRiables and functions",
    "section": "7.5 Combining functions in R",
    "text": "7.5 Combining functions in R\nCombining functions is where the real fun starts with programming! In Section 7.4, we already combined two functions using a mathematical operator (/). But what if we want to compute L1 participant‚Äôs average age to two decimal places? To do this, we need to combine the mean() function and the round() function. We can do this in two steps.\n\n# Step 1:\nL1.mean.age &lt;- mean(L1.Age)\n# Step 2:\nround(L1.mean.age, digits = 2)\n\n[1] 37.54\n\n\nIn step 1, we compute the mean value and save it as an R object and, in step 2, we pass this object through the round() function with the argument digits = 2. There is nothing wrong with this method, but it often require lots of intermediary R objects, which can get rather tiresome.\nIn the following, we will look at two further ways to combine functions in R: nesting and piping.\n\n7.5.1 Nested functions\nThe first method involves lots of brackets (also known as ‚Äòparentheses‚Äô). This is because in nested functions, one function is placed inside another function. The inner function is evaluated first, and its result is passed to the next outer function. Here‚Äôs an example:\n\nround(mean(L1.Age))\n\n[1] 38\n\n\nIn this example, the mean() function is nested inside the round() function. The mean() function calculates the mean of L1.Age, and the result is passed to the round() function, which rounds the result to the nearest integer.\nYou can also pass additional arguments to any of the functions, but you must make sure that you place the arguments within the correct set of brackets.\n\nround(mean(L1.Age), digits = 2)\n\n[1] 37.54\n\n\nIn this example, the argument digits = 2 belongs to the outer function round(); hence it must be placed within the outer set of brackets.\nIn theory, you can nest as many functions as you like, but things can get quite chaotic after more than a couple of functions. You need to make sure that you can trace back which arguments and which brackets belong to which function (see Figure¬†7.2).\n\n\n\n\n\n\nFigure¬†7.2: A schematic representations of a) one function with two arguments, b) two nested functions each with two arguments, and c) three nested functions each with two arguments\n\n\n\n\n\n\n\n\n\nTime to think!\n\n\n\nConsider the three lines of code below. Without running them, can you tell which of the three lines of code will output the square root of L1 participant‚Äôs average age to two decimal places?\n\nround(sqrt(mean(L1.Age) digits = 2))\n\nsqrt(round(mean(L1.Age), digits = 2))\n\nround(sqrt(mean(L1.Age)), digits = 2)\n\nThe first line will return an ‚Äúunexpected symbol‚Äù error because it is missing a comma before the argument digits = 2. The second line actually outputs 6.126989, which has more than two decimal places! This is because R interprets the functions from the inside out: first, it calculates the mean value, then it rounds that off to two decimal places, and only then does it compute the square root of that rounded off value. The third line, in contrast, does the rounding operation as the last step. Note that, in the two lines of code that do not produce an error, the brackets around the argument digits = 2 are also located in different places.\nIt is very easy to make bracketing errors when writing code and especially so when nesting functions (see Figure¬†7.2). Watch your commas and brackets (see also Section 5.6)!\n\n\n\n\n7.5.2 Piped Functions\nIf you found all these brackets overwhelming: fear not! There is a second method for combining functions in R, which is often more convenient and almost always easier to decipher. It involves the pipe operator, which in R is |&gt;.1\nThe |&gt; operator passes the output of one function on to the first argument of the next function. This allows us to chain multiple functions together in a much more intuitive way.\n\nL1.Age |&gt; \n mean() |&gt; \n round()\n\n[1] 38\n\n\nIn this example, the object L1.Age is passed on to the first argument of the mean() function. This calculates the mean of L1.Age. Next, this result is passed to the round() function, which rounds the mean value to the nearest integer.\nIf we want to pass additional arguments to any function in the pipeline, we simply at it in the brackets corresponding to the function in question.\n\nL1.Age |&gt; \n mean() |&gt; \n round(digits = 2)\n\n[1] 37.54\n\n\nLike many of the relational operators we saw in Section 5.5, the R pipe is a combination of two symbols, the computer pipe symbol | and the right angle bracket &gt;. Don‚Äôt worry if you‚Äôre not sure where these two symbols are on your keyboard as RStudio has a handy shortcut for you: Ctrl/Cmd + Shift + M2 (see Figure¬†7.3). I strongly recommend that you write this shortcut on a prominent post-it and learn it asap, as you will need it a lot when you are working in R!\n\n\n\n\n\n\nFigure¬†7.3: Remix of Ren√© Magritte‚Äôs ‚ÄúLa Trahison des images‚Äù (1928-1929) with the native R pipe and its RStudio shortcut (based on an image from Wikiart.org). This image is licensed under CC-BY Elen Le Foll3.\n\n\n\n\n\n\n\n\n\nQuiz time!\n\n\n\nQ16. Using the R pipe operator, calculate the average mean age of the L2 participants and round off this value to two decimal places. What is the result?\n\n\n\n\n\n\n\n\n\n\n¬†\nQ17. Unsurprisingly, in DƒÖbrowska (2019)‚Äòs study, English L1 participants, on average, scored higher in an English vocabulary test than L2 participants. Calculate the difference between L1 and L2 participants‚Äô mean Vocab test results and round off this means difference to two decimal places.\n\n\n\n\n\n\n\n\n\n\nüòá Hover for a hint\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\nClick here for a detailed answer to Q16\n\n\n\n\n\nThey are lots of ways to tackle question 16. Here is one approach:\n\n(mean(L1.data$Vocab) - mean(L2.data$Vocab)) |&gt; \n  round(digits = 2)\n\n[1] 16.33\n\n\nNote that this approach requires a set of brackets around the first subtraction operation, otherwise only the second mean value is rounded off to two decimal places. Compare the following lines of code:\n\nmean(L1.data$Vocab) - mean(L2.data$Vocab)\n\n[1] 16.33315\n\n(mean(L1.data$Vocab) - mean(L2.data$Vocab)) |&gt; \n  round(digits = 2)\n\n[1] 16.33\n\nmean(L1.data$Vocab) - round(mean(L2.data$Vocab), digits = 2)\n\n[1] 16.3358\n\n\nAnother solution would be to store the difference in means as an R object and pass this object to the round() function.\n\nmean.diff.vocab &lt;- mean(L1.data$Vocab) - mean(L2.data$Vocab)\nround(mean.diff.vocab, digits = 2)\n\n[1] 16.33\n\n\nOr, if you want to use the pipe:\n\nmean.diff.vocab &lt;- mean(L1.data$Vocab) - mean(L2.data$Vocab)\nmean.diff.vocab |&gt; \n  round(digits = 2)\n\n[1] 16.33\n\n\n\n\n\n\n\n\n\nDƒÖbrowska, Ewa. 2019. Experience, aptitude, and individual differences in linguistic attainment: A comparison of native and nonnative speakers. Language Learning 69(S1). 72‚Äì100. https://doi.org/10.1111/lang.12323.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Va`R`iables and functions</span>"
    ]
  },
  {
    "objectID": "7_VariablesFunctions.html#footnotes",
    "href": "7_VariablesFunctions.html#footnotes",
    "title": "7¬† VaRiables and functions",
    "section": "",
    "text": "This is the native R pipe operator, which was introduced in May 2021 with R version 4.1.0. As a result, you will not find it in code written in earlier versions of R. Previously, piping required an additional R library, the {magrittr} library. The {magrittr} pipe looks like this: %&gt;%. At first sight, they appear to work is in the same way, but there are some important differences. If you are familiar with the {magrittr} pipe and want to understand how it differs from the native R pipe, I recommend this excellent blog post by Isabella Vel√°squez: https://ivelasq.rbind.io/blog/understanding-the-r-pipe/.‚Ü©Ô∏é\nIf, in your version of RStudio, this shortcut produces %&gt;% instead of |&gt;, you have probably not activated the native R pipe option in your RStudio global options (see instructions in Section 4.3.1).‚Ü©Ô∏é\nI would appreciate you referencing this textbook or textbook chapter when reusing this image. Thank you!‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Va`R`iables and functions</span>"
    ]
  },
  {
    "objectID": "8_DescriptiveStats.html",
    "href": "8_DescriptiveStats.html",
    "title": "8¬† DescRiptive statistics",
    "section": "",
    "text": "Chapter overview\nIn this chapter, you will learn how to:",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Desc`R`iptive statistics</span>"
    ]
  },
  {
    "objectID": "8_DescriptiveStats.html#sec-CentralTendency",
    "href": "8_DescriptiveStats.html#sec-CentralTendency",
    "title": "8¬† DescRiptive statistics",
    "section": "8.1 Measures of central tendency",
    "text": "8.1 Measures of central tendency\nIn Section 7.4, we calculated the mean average age of L1 and L2 participants. Averages are a very useful way to describe the central tendency of a numeric variable - both in science and everyday life. For example, it is useful for me to know if a particular bus journey lasts, on average, 12 minutes or 45 minutes. As it‚Äôs an average value, I am not expecting it to last exactly 12 or 45 minutes, but the average duration is nonetheless helpful to plan my schedule.\nIn science, we use averages to describe the central tendency of numeric variables that are too large for us to be able to examine every single data point. With very small datasets, averages are unnecessary. Imagine that a Breton1 language class in Fiji has five students. Their teacher hardly needs to calculate an average of the students‚Äô vocabulary test results to get an understanding of how her students are doing. She can simply examine all five results!\nNot only are averages of very small datasets unnecessary they can, in fact, be misleading. Imagine that the five Breton learners got the following results (out of 100) on their vocabulary test:\n\n5, 82, 86, 89, 91\n\nIf we calculate the average result of the class, we get:\n\nmean(c(5, 82, 87, 89, 91))\n\n[1] 70.8\n\n\nThis average grade does not describe very well how any of the students did: Four did much better than that, while one did considerably worse! The results of quantitative studies, however, typically involve much larger datasets so that averages can be a very useful way to describe central tendencies within the data. But it‚Äôs important to understand that, depending on the data, different measures of central tendency make sense. Later on, we will also see that measures of central tendency do not suffice to describe numeric variables: measures of variability (Section 8.3) and good data visualisation (Chapter 10) are also crucial.\n\n8.1.1 Mean\nThe measure of central tendency that we have looked at so far is the arithmetic mean. When people speak of averages, they typically mean mean values.\nIn Section 7.4, we saw that means are calculated by adding up all the values and dividing the sum by the total of values.\n\nsum((c(5, 82, 87, 89, 91))) / 5\n\n[1] 70.8\n\n\nMeans are useful because they are commonly reported and widely understood. Their disadvantage is that they are very susceptible to outliers and skew (which far fewer people actually understand, see Section 8.2). As we saw in the example above, the fact that one ‚Äòoutlier‚Äô learner did very poorly in her Breton vocabulary test led to a much lower average grade than we would expect considering that the other four test-takers did much better than the mean.\nMeans are also frequently misinterpreted as ‚Äúmost likely value‚Äù. This is rarely the case. For example, in this example, 71.2 is not a score that any of the five students obtained!\n\n\n8.1.2 Median\nAnother way to report the central tendency of a set of numeric values like test results is to look for its ‚Äúmiddle value‚Äù. If we order our five Breton learners‚Äô test results from the lowest to the highest value, we can see that the middle value is 86. This is the median.\n\n5, 82, 86, 89, 91\n\nFor datasets with an even number of values (e.g., 2, 4, 6, 8, etc.), we take the mean of the two middle values. Hence, in the following extended dataset with six Breton learners, the median test score is 86.5 because the two middle test results are 86 and 87 and (86¬†+¬†87)¬†/¬†2¬†=¬†86.5.\n\n5, 82, 86, 87, 89, 91\n\nBy now, you will probably not be surprised to learn that there is an R function called median(), which allows us to easily calculate the median value of any set of numbers.\n\nmedian(c(5, 82, 86, 89, 91))\n\n[1] 86\n\nmedian(c(5, 82, 86, 87, 89, 91))\n\n[1] 86.5\n\n\nNow, it‚Äôs time to turn to real data!\n\n\n8.1.3 Mode\nThe mean and median are measures of central tendency that only work with numeric variables. However, data in the language sciences frequently also includes categorical data (see Section 7.2.1). In the data from DƒÖbrowska (2019), this includes variables such as Gender, NativeLg, OtherLgs, and Occupation. We also need to be able to describe these variables as part of our data analysis. For such categorical variables, the only available measure of central tendency is the mode, which corresponds to the most frequent value in a variable.\nThe table() function outputs how often each unique value occurs in a variable.\n\ntable(L1.data$Gender)\n\n\n F  M \n48 42 \n\n\nFrom this output, we can tell that the mode of the Gender variable in the L1 dataset is F, which stands for ‚Äúfemale‚Äù.\nWhen there are many different unique values (or levels), it makes sense to order them according to their frequency. To do so, we can pipe the output of the table() function into the sort() function (piping was covered in Section 7.5.2). Note that, by default, R sorts by ascending order (decreasing = FALSE). We can change this default to TRUE.\n\ntable(L1.data$Occupation) |&gt; \n  sort(decreasing = TRUE)\n\n\n                  Retired                   Student                Unemployed \n                       14                        14                         4 \n                Housewife            Shop Assistant                   Teacher \n                        3                         3                         3 \n          Admin Assistant            Factory Worker                 Policeman \n                        2                         2                         2 \n        Quantity Surveyor             Admin Officer             Administrator \n                        2                         1                         1 \n              Boilermaker             Care Assisant             Carer/Cleaner \n                        1                         1                         1 \n       Catering Assistant             Civil Servant                   Cleaner \n                        1                         1                         1 \n                    Clerk            Content Editor    Creative Writing Tutor \n                        1                         1                         1 \n Customer Service Advisor              Dental Nurse         Finance Assistant \n                        1                         1                         1 \n   Functions Co-ordinator                 Homemaker           Human Resources \n                        1                         1                         1 \n               IT Support             Manual worker           Nail Technician \n                        1                         1                         1 \nOffice Admin Co-Ordinator         P/T Administrator         Personal Searcher \n                        1                         1                         1 \n      Project Coordinator              Receptionist                    Roofer \n                        1                         1                         1 \n          Sales Assistant     School Crossing Guard    School Crossing Patrol \n                        1                         1                         1 \n          Senior Lecturer                    Singer         Student (college) \n                        1                         1                         1 \n   Student/Support Worker     Supermarket Assistant            Support Worker \n                        1                         1                         1 \n             Train Driver                 Unemploed       University lecturer \n                        1                         1                         1 \n                 Waitress       Warehouse Operative              Web designer \n                        1                         1                         1 \n\n\nWe can see that, among the L1 participants, there were as many ‚ÄúRetired‚Äù participants as there were ‚ÄúStudent‚Äù participants.2 Hence, we have two modes. In general, modal values rarely make good summaries of variables with many different possible values or levels. This is why the mode is not suitable for numeric variables, unless there are only a few possible discrete numeric values (e.g., the values of a five or seven-point Likert scale3).\nCross-tabulations of more than one categorical variable (or numeric variable with just a few unique values) can easily be generated using the table() function. In the following, we cross-tabulate the additional languages that the L1 participants speak with their gender. This allows us to see that most male and female L1 participants did not speak another language other than English. Hence, for both the male and female subsets of L1 participants the mode of the variable OtherLgs is ‚ÄúNone‚Äù.\n\ntable(L1.data$OtherLgs, L1.data$Gender)\n\n         \n           F  M\n  French   1  1\n  German   2  1\n  None    44 40\n  Spanish  1  0\n\n\n\n\n\n\n\n\nQuiz time!\n\n\n\nIn comparative studies, it is important to ensure that comparisons are fair and meaningful. For example, it would probably not be very meaningful to compare the linguistic knowledge of a group of undergraduate student learners of English with a group of retired native speakers. In this quiz, you will examine how similar the L1 and the L2 participants in DƒÖbrowska (2019) were in terms of age.\nQ1. What was the mean age of the L1 participants in DƒÖbrowska (2019)? Use the round() function to round off the mean value to two decimal places (see Section 7.5.2 for a reminder as to how to combine two functions).\n\n\n\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\nQ2. On average, were the L1 participants in DƒÖbrowska (2019) older or younger than the L2 participants?\n\n\n\n\nOn average, the L2 participants were older.\n\n\nIt's impossible to tell based on the available data.\n\n\nIt depends whether you base the comparison on mean or median values.\n\n\nOn average, the L1 participants were older.\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\nQ3. Which of the following statements is true about the L1 and L2 participants in DƒÖbrowska (2019)?\n\n\n\n\nThe difference between the average ages of the two groups is greater when comparing mean than median ages.\n\n\nThe difference between the average ages of the two groups is greater when comparing median than mean ages.\n\n\nThe difference remains the same no matter what type of central tendency measure is used.\n\n\n\n\n\n\n\nüòá Hover for a hint",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Desc`R`iptive statistics</span>"
    ]
  },
  {
    "objectID": "8_DescriptiveStats.html#sec-Distributions",
    "href": "8_DescriptiveStats.html#sec-Distributions",
    "title": "8¬† DescRiptive statistics",
    "section": "8.2 Distributions",
    "text": "8.2 Distributions\nData analysis typically begins with the description of individual variables from a dataset. This is referred to as univariate descriptive statistics and is all about describing the distribution of the variables. A distribution is a way to summarise how the values of a variable are dispersed. It tells us things like the variable‚Äôs most frequent values, its range of values, and how the values are clustered or spread out. Examining the shapes and patterns of distributions can help us understand the typical values of the variables of our data, identify outliers, and make informed decisions about how to analyse and visualise our data.\n\n8.2.1 Distributions of categorical variables\nTables can be an effective way to examine the distribution of categorical variables. The table() function outputs the frequency of each level of a categorical variable. By default, the levels are ordered alphabetically.\n\ntable(L1.data$OtherLgs)\n\n\n French  German    None Spanish \n      2       3      84       1 \n\n\nWe saw that we can use the sort() function to change this behaviour.\n\ntable(L1.data$OtherLgs) |&gt; \n    sort(decreasing = TRUE)\n\n\n   None  German  French Spanish \n     84       3       2       1 \n\n\nThe proportions() function allows us to describe the frequency of each level of a categorical variable as a proportion of all data points. This is especially useful if we want to compare the distribution of a categorical variable across different (sub)datasets of different sizes.\n\ntable(L1.data$OtherLgs) |&gt; \n  sort(decreasing = TRUE) |&gt; \n  proportions()\n\n\n      None     German     French    Spanish \n0.93333333 0.03333333 0.02222222 0.01111111 \n\n\nWhen computing proportions, 0 corresponds to 0% and 1 to 100%. If we want to obtain percentages, we therefore need to multiply these numbers by 100. We can therefore see that more than 90% of L1 participants reported not being competent in any language other than English, their native language.\n\nOtherLgs.prop &lt;- \n  table(L1.data$OtherLgs) |&gt; \n  sort(decreasing = TRUE) |&gt; \n  proportions()*100\n\nOtherLgs.prop\n\n\n     None    German    French   Spanish \n93.333333  3.333333  2.222222  1.111111 \n\n\nTo round the values to two decimal places, we can pipe the R object that we created in the previous chunk (OtherLgs.prop) into the round() function.\n\nOtherLgs.prop |&gt; \n  round(digits = 2)\n\n\n   None  German  French Spanish \n  93.33    3.33    2.22    1.11 \n\n\nIn addition to using frequency tables, we can visualise data distributions graphically. Bar plots allow us to easily compare the distribution of categorical variables across different datasets and subsets of data. For example, in Figure¬†8.1, we can see that the distribution of additional languages spoken by the L1 participants is very similar in both the female and the male subset of participants.\n\n\n\n\n\n\n\n\nFigure¬†8.1: Additional languages spoken by L1 participants in DƒÖbrowska (2019)\n\n\n\n\n\nIn Chapter 10, you will learn how to make plots like Figure¬†8.1 in R using the {ggplot2} package.\n\n\n8.2.2 Distributions of numeric variables\nIn DƒÖbrowska (2019), on average, the L2 participants were younger than the L1 participants.\n\nmean(L1.data$Age) - mean(L2.data$Age)\n\n[1] 4.828027\n\n\nThe difference in mean age was more than four years. But are these two mean values good summaries of the central tendencies of participants‚Äô ages? To check, it is important that we examine the full distribution of participants‚Äô ages. We begin with the distribution of L2 participants‚Äô ages.\nWe first use the table() function to tally L2 participants‚Äô ages.\n\ntable(L2.data$Age)\n\n\n20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 37 38 39 40 41 42 46 47 48 51 \n 1  1  5  3  2  3  2  2  6  3  4  5  2  3  2  2  3  2  5  1  1  1  2  1  1  1 \n52 55 62 \n 1  1  1 \n\n\nAs the above table contains a lot of different values, it‚Äôs easier to visualise these numbers in the form of a bar chart (also called bar plot). The mode (28) has been highlighted in black.\n\n\nShow the R code to produce the plot below (but note that data visualisation is covered in Chapter 11).\nbarplot.mode &lt;- \n  \n  # Take the L2.data data frame and pipe it into the ggplot function:\n  L2.data |&gt;\n\n  # Start a ggplot, mapping Age to the x-axis:\n  ggplot(mapping = aes(x = Age)) + \n\n  # Add a bar plot layer, conditionally fill the bars; bars representing 28 years of age will have a different colour:\n  geom_bar(aes(fill = (Age == 28))) +    \n\n  # Manually control the colours of the bar fill: set the bar representing Age == 28 to \"#0000EE\", and remove the legend:\n  scale_fill_manual(values = c(\"TRUE\" = \"black\"), guide = \"none\") +  \n  \n    # Apply ggplot2's classic theme:\n  theme_classic() +\n\n  # Ensure that there are tick marks for every single whole number and do not extend the limits of y-scale to avoid white space on the plot:\n  scale_y_continuous(name = \"Number of L1 participants\",\n                     breaks = scales::breaks_width(1), \n                     expand = c(0, 0)) +\n\n  # Set the x-axis breaks and remove white space:\n  scale_x_continuous(breaks = scales::breaks_width(1),\n                     expand = c(0, 0)) +\n  \n  # Add label for mode:\n  annotate(\"text\", \n           x = 25, \n           y = 5.8, \n           label = \"mode\", \n           colour = \"black\",\n           family = \"mono\") +\n  \n  # Add curved arrow for mode:\n  annotate(\n    geom = \"curve\",\n    x = 25,\n    y = 5.65, \n    xend = 27.2,\n    yend = 5, \n    curvature = 0.5,\n    arrow = arrow(length = unit(0.2, \"cm\")), \n    colour = \"black\")\n\n# Print the plot\nbarplot.mode\n\n\n\n\n\n\n\n\n\nThanks to this bar chart, it‚Äôs much easier to see that the second most frequent ages after the mode of 28 are 22, 31 and 39. How do these ages compare to the median age?\n\n\nShow R code to generate the plot below.\nbarplot.mode.median &lt;- \n  barplot.mode +\n  geom_bar(aes(fill = ifelse(Age == 31, \"31\", ifelse(Age == 28, \"28\", \"Other\")))) +\n  scale_fill_manual(values = c(\"28\" = \"black\", \"31\" = \"darkred\"), guide = \"none\") +\n  # Add label for median:\n  annotate(\"text\", \n           x = 30.5, \n           y = 5.5, \n           label = \"median\", \n           colour = \"darkred\",\n           family = \"mono\") +\n  \n  # Add curved arrow for median:\n  annotate(\n    geom = \"curve\",\n    x = 30.4,\n    y = 5.35, \n    xend = 30.4,\n    yend = 4.9, \n    curvature = 0.6,\n    arrow = arrow(length = unit(0.2, \"cm\")), \n    colour = \"darkred\")\n\nbarplot.mode.median\n\n\n\n\n\n\n\n\n\nWe can compare the mode (28) and median (31) to the mean (32.72), which, on the following bar chart, is represented as a blue dashed line.\n\n\nShow R code to generate the plot below.\nbarplot.mode.median +\n  geom_vline(aes(xintercept = mean(Age)), \n             color = \"#0000EE\", \n             linetype = \"dashed\",\n             linewidth = 0.8) +\n  \n  # Add label for mean:\n  annotate(\"text\", \n           x = 36, \n           y = 5.3, \n           label = \"mean\", \n           colour = \"#0000EE\",\n           family = \"mono\") +\n  \n  # Add curved arrow for mean:\n  annotate(\n    geom = \"curve\",\n    x = 36,\n    y = 5.15, \n    xend = 33.2,\n    yend = 4.4, \n    curvature = -0.4,\n    arrow = arrow(length = unit(0.2, \"cm\")), \n    colour = \"#0000EE\")\n\n\n\n\n\n\n\n\n\nNext, we can reduce the number of bars by adding together the number of L2 participants aged 20-22, 22-24, 24-26, etc. This is what we call a histogram. Histograms are used to visualise distributions and their bars are called bins because they ‚Äúbin together‚Äù a number of values.\n\n\nShow R code to generate the plot below.\nage.histo &lt;- \n  L2.data |&gt;\n  ggplot(mapping = aes(x = Age)) + \n    geom_vline(aes(xintercept = mean(Age)), \n             color = \"#0000EE\", \n             linetype = \"dashed\",\n             linewidth = 0.8) +\n    geom_vline(aes(xintercept = 28), \n             color = \"black\", \n             linewidth = 0.8) +\n    geom_vline(aes(xintercept = 31), \n             color = \"darkred\", \n             linewidth = 0.8) +  \n  \n  # Add label for mode:\n  annotate(\"text\", \n           x = 24, \n           y = 2.9, \n           label = \"mode\", \n           colour = \"black\",\n           family = \"mono\") +\n  \n  # Add curved arrow for mode:\n  annotate(\n    geom = \"curve\",\n    x = 24,\n    y = 2.6, \n    xend = 27.2,\n    yend = 2, \n    curvature = 0.5,\n    arrow = arrow(length = unit(0.2, \"cm\")), \n    colour = \"black\") +\n  \n  # Add label for mean:\n  annotate(\"text\", \n           x = 36, \n           y = 1.4, \n           label = \"mean\", \n           colour = \"#0000EE\",\n           family = \"mono\") +\n  \n  # Add curved arrow for mean:\n  annotate(\n    geom = \"curve\",\n    x = 36,\n    y = 1.1, \n    xend = 33.2,\n    yend = 0.4, \n    curvature = -0.4,\n    arrow = arrow(length = unit(0.2, \"cm\")), \n    colour = \"#0000EE\") +\n  \n    # Add label for median:\n  annotate(\"text\", \n           x = 25, \n           y = 1.4, \n           label = \"median\", \n           colour = \"darkred\",\n           family = \"mono\") +\n  \n  # Add curved arrow for median:\n  annotate(\n    geom = \"curve\",\n    x = 25,\n    y = 1.1, \n    xend = 30.7,\n    yend = 0.4, \n    curvature = 0.4,\n    arrow = arrow(length = unit(0.2, \"cm\")), \n    colour = \"darkred\") +\n  \n  theme_classic() +\n  scale_y_continuous(name = \"Number of L2 participants\", \n                     breaks = scales::breaks_width(1), \n                     expand = c(0, 0)) +\n  scale_x_continuous(breaks = scales::breaks_width(2), \n                     expand = c(0, 0))\n\nage.histo +\n    geom_histogram(position = \"identity\", \n                 binwidth = 2,\n                 fill = \"black\",\n                 alpha = 0.4)\n\n\n\n\n\n\n\n\n\nIf we reduce the number of bins by having them cover three years instead of two, the histogram looks like this.\n\n\nShow R code to generate the plot below.\nage.histo +\n    geom_histogram(position = \"identity\", \n                 binwidth = 3,\n                 fill = \"black\",\n                 alpha = 0.4) +\n    scale_x_continuous(breaks = scales::breaks_width(3), \n                     expand = c(0, 0))\n\n\n\n\n\n\n\n\n\nAlternatively, we can apply a density function to smooth over the bins of the histogram to generate a density plot of L2 participants‚Äô ages (see purple curve in Figure¬†8.2). Such smoothed curves allow for a better comparison of distribution shapes across different groups and datasets. Note that, in a density plot, the values on the y-axis are no longer counts, but rather density probabilities. We will not use any fancy formulae to work this out mathematically, but you should understand that the total area under the curve (in purple) will always equal to 1, which corresponds to 100% probability. In this dataset, this is because there is a 100% probability that an L2 participant‚Äôs age is between 20 and 62.\n\n\nShow R code to generate the plot below.\n# There is no in-built function in R to calculate the mode of a numeric vector but we can define one ourselves:\nget_mode &lt;- function(x) {\n  ux &lt;- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\nL2.data |&gt;\n  ggplot(mapping = aes(x = Age)) + \n  geom_histogram(aes(x = Age, y = after_stat(density)),\n                 binwidth = 3,\n                 fill = \"black\",\n                 alpha = 0.4) + \n  geom_density(colour = \"purple\",\n               fill = \"purple\",\n               alpha = 0.2,\n               linewidth = 0.8) +\n  geom_vline(aes(xintercept = mean(Age)),\n             color = \"#0000EE\",\n             linetype = \"dashed\",\n             linewidth = 0.8) +\n  geom_vline(aes(xintercept = get_mode(Age)),\n             color = \"black\",\n             linewidth = 0.8) +\n  geom_vline(aes(xintercept = median(Age)),\n             color = \"darkred\",\n             linewidth = 0.8) +  \n  # Add label for mode:\n  annotate(\"text\",\n           x = 25,\n           y = 0.029,\n           label = \"mode\",\n           colour = \"black\",\n           family = \"mono\") +\n\n  # Add curved arrow for mode:\n  annotate(\n    geom = \"curve\",\n    x = 25,\n    y = 0.028,\n    xend = 27.5,\n    yend = 0.025,\n    curvature = 0.6,\n    arrow = arrow(length = unit(0.2, \"cm\")),\n    colour = \"black\") +\n\n  # Add label for mean:\n  annotate(\"text\",\n           x = 36,\n           y = 0.014,\n           label = \"mean\",\n           colour = \"#0000EE\",\n           family = \"mono\") +\n\n  # Add curved arrow for mean:\n  annotate(\n    geom = \"curve\",\n    x = 36,\n    y = 0.011,\n    xend = 33.2,\n    yend = 0.004,\n    curvature = -0.4,\n    arrow = arrow(length = unit(0.2, \"cm\")),\n    colour = \"#0000EE\") +\n  \n  # Add label for median:\n  annotate(\"text\",\n           x = 25.5,\n           y = 0.01,\n           label = \"median\",\n           colour = \"darkred\",\n           family = \"mono\") +\n\n  # Add curved arrow for median:\n  annotate(\n    geom = \"curve\",\n    x = 25.5,\n    y = 0.008,\n    xend = 30.8,\n    yend = 0.004,\n    curvature = 0.4,\n    arrow = arrow(length = unit(0.2, \"cm\")),\n    colour = \"darkred\") +  \n\n  theme_classic() +\n  scale_y_continuous(name = \"Density\",\n                     breaks = scales::breaks_width(0.01),\n                     expand = c(0, 0)) +\n  scale_x_continuous(breaks = scales::breaks_width(3),\n                     expand = c(0, 0))\n\n\n\n\n\n\n\n\nFigure¬†8.2: Density plot showing the distribution of L2 participants‚Äô ages\n\n\n\n\n\nIf we wanted to work out the probability of an L2 participant being between 42 and 62 years old, we would have to calculate the area under the curve between these two points on the x-axis. Even without doing any maths, you can see that this area is considerably smaller than between the ages of 22 and 42. This means that, in this dataset, participants are considerably more likely to be between 22 and 42 than between 42 and 62 years old.4\nThe density plot of L2 participants‚Äô ages features a characteristic bell-shaped curve, which indicates that the distribution resembles a normal distribution. However, it also features a long tail towards the older years. We are therefore dealing with a skewed distribution. Skewness is a measure of asymmetry in the a distribution. Skewed distributions occur when one tail end of the bell is longer than the other. Here, the asymmetry is due to the fact that DƒÖbrowska (2019)‚Äôs L2 data includes quite a few participants who were older than 40 at the time of the study, whereas there were none who were younger than 20. As the tail is to the right of the plot, this is a right skewed (or positive) distribution.\nThe median is usually better than the mean for describing the central tendency of a skewed distribution because it is less susceptible to the outlier(s) contained in the tail of a skewed distribution (see Section 8.1.2). Figure¬†8.2 confirms that the median is a better approximation of L2 participants‚Äô ages than the mean.\n\n\n8.2.3 Normal (or Gaussian) distributions\nIn a perfectly normally distributed variable, the mean and the median are exactly the same. They are both found at the centre of the distribution and the bell shape of the distribution is perfectly symmetrical. Hence, the skewness of a normal distribution is near zero.\nPerfectly normal distributions, however, are very rarely found in real life! Here is what the normal distribution of 10,000 participants‚Äô age might look like in real life (using numbers randomly generated from a perfectly normal distribution thanks to the R function rnorm()).\n\n\nShow R code to generate the plot below.\n# The {truncnorm} package contains density, probability, quantile and random number generation functions for the truncated normal distribution:\n#install.packages(\"truncnorm\")\nlibrary(truncnorm)\n\nset.seed(42)\nnormal.age.sd8 &lt;- round(rtruncnorm(mean = 35, sd = 8, n = 10000, a = 10, b = 100))\n#get_mode(normal.age.sd8) \n\nggplot(mapping = aes(x = normal.age.sd8)) + \n    geom_vline(aes(xintercept = mean(normal.age.sd8)),\n             color = \"#0000EE\",\n             linetype = \"dashed\",\n             linewidth = 0.8) +\n    geom_vline(aes(xintercept = median(normal.age.sd8)),\n             color = \"darkred\",\n             #linetype = \"dotted\",\n             linewidth = 0.6) +\n    # geom_vline(aes(xintercept = get_mode(normal.age.sd8)),\n    #          color = \"black\",\n    #          linewidth = 0.8) +  \n  \n  # Add label for mean:\n  annotate(\"text\",\n           x = 30.6,\n           y = 0.014,\n           label = \"mean\",\n           colour = \"#0000EE\",\n           family = \"mono\") +\n\n  # Add curved arrow for mean:\n  annotate(\n    geom = \"curve\",\n    x = 30.5,\n    y = 0.013,\n    xend = 34.7,\n    yend = 0.008,\n    curvature = 0.5,\n    arrow = arrow(length = unit(0.2, \"cm\")),\n    colour = \"#0000EE\") +  \n  \n  # Add label for median:\n  annotate(\"text\",\n           x = 38,\n           y = 0.007,\n           label = \"median\",\n           colour = \"darkred\",\n           family = \"mono\") +\n\n  # Add curved arrow for median:\n  annotate(\n    geom = \"curve\",\n    x = 38,\n    y = 0.006,\n    xend = 35.2,\n    yend = 0.004,\n    curvature = -0.5,\n    arrow = arrow(length = unit(0.2, \"cm\")),\n    colour = \"darkred\") +\n  theme_classic() +\n  scale_y_continuous(name = \"Density\",\n                     breaks = scales::breaks_width(0.01),\n                     expand = c(0, 0)) +\n  scale_x_continuous(name = \"Age\",\n                     breaks = scales::breaks_width(2),\n                     expand = c(0, 0)) +\n  geom_histogram(aes(x = normal.age.sd8, y = after_stat(density)),\n                 binwidth = 2,\n                 fill = \"black\",\n                 alpha = 0.4) + \n  geom_density(colour = \"purple\",\n               linewidth = 0.8,\n               fill = \"purple\",\n               alpha = 0.3)\n\n\n\n\n\n\n\n\nFigure¬†8.3: A normal distribution of the age of a fictitious group of participants\n\n\n\n\n\nIn Figure¬†8.3, the mean (34.9235) and the median (35) age of our 10,000 fictitious learners are very close to each other. So close that, on the plot, the lines overlap. The skew is near zero, hence the density curve forms near-symmetrical bell shape. This means that the purple area under the curve to the left of the central tendency is pretty much the same as the area to the right of the line. In other words, there are as many people whose age is below the central tendency (50%) as there are people whose age is above the central tendency (50%). These are the characteristics of a normal distribution. Understanding these is important as many statistical tests assume that the variables entered in these tests are (approximately) normally distributed (see Chapter 12).\n\n\n8.2.4 Non-normal (or non-parametric) distributions\nWe saw that the distribution of L2 participants‚Äô ages in DƒÖbrowska (2019) was close to a normal distribution but with a right skew towards older years. This meant that the mean age was higher than median age.\nDoes the distribution of L1 participants‚Äô ages follow a similar shape? Are we dealing with a distribution that is normal, left or right skewed, or something entirely different?\n\n\n\n\n\n\nQuiz time!\n\n\n\nQ4. What were the modal ages of the L1 and L2 participants in DƒÖbrowska (2019)?\n\n\n\n\n17 (for L1 participants) and 28 (L2 participants)\n\n\n29 (for L1 participants) and 28 (L2 participants)\n\n\n28 (for L1 participants) and 29 (L2 participants)\n\n\n32 (for L1 participants) and 31 (L2 participants)\n\n\n\n\n\n\n\nüòá Hover for a hint\n\n\n\n\n¬†\nQ5. Which of the following statements is true?\n\n\n\n\nThe mean and median age of the L1 group are almost the same.\n\n\nThe difference between mean and median age is smaller in the L1 group than in the L2 group.\n\n\nThe difference between the mean and median age is greater in the L1 group than in the L2 group.\n\n\n\n\n\n\n\n¬†\nQ6. Which measure of central tendency best describes L1 participants‚Äô ages?\n\n\n\n\nThe mean.\n\n\nThe median.\n\n\nThe mode.\n\n\nNone of them.\n\n\n\n\n\n\n\n¬†\n\n\nFigure¬†8.4 shows the distribution of L1 participants‚Äô ages both as a histogram (in grey) and a density plot (in purple). Both of these visualisations make quite clear that this distribution of ages is not at all normal! It is non-normal or non-parametric. This is because it does not consist of one more or less symmetrical bell shape. Instead, we can see several small bell shapes.\n\n\nShow R code to generate the plot below.\nL1.data |&gt;\n  ggplot(mapping = aes(x = Age)) + \n  geom_histogram(aes(x = Age, y = after_stat(density)),\n                 binwidth = 2,\n                 fill = \"black\",\n                 alpha = 0.4) + \n  geom_density(colour = \"purple\",\n               fill = \"purple\",\n               alpha = 0.2,\n               linewidth = 0.8) +\n  geom_vline(aes(xintercept = mean(Age)),\n             color = \"#0000EE\",\n             linetype = \"dashed\",\n             linewidth = 0.8) +\n  geom_vline(aes(xintercept = get_mode(Age)),\n             color = \"black\",\n             linewidth = 0.8) +\n  geom_vline(aes(xintercept = median(Age)),\n             color = \"darkred\",\n             linewidth = 0.8) + \n  \n  # Add label for mode:\n  annotate(\"text\",\n           x = 20.5,\n           y = 0.064,\n           label = \"mode\",\n           colour = \"black\",\n           family = \"mono\") +\n\n  # Add curved arrow for mode:\n  annotate(\n    geom = \"curve\",\n    x = 20.5,\n    y = 0.062,\n    xend = 18,\n    yend = 0.058,\n    curvature = -0.4,\n    arrow = arrow(length = unit(0.2, \"cm\")),\n    colour = \"black\") +\n\n  # Add label for mean:\n  annotate(\"text\",\n           x = 40,\n           y = 0.03,\n           label = \"mean\",\n           colour = \"#0000EE\",\n           family = \"mono\") +\n\n  # Add curved arrow for mean:\n  annotate(\n    geom = \"curve\",\n    x = 40,\n    y = 0.028,\n    xend = 37.8,\n    yend = 0.025,\n    curvature = -0.4,\n    arrow = arrow(length = unit(0.2, \"cm\")),\n    colour = \"#0000EE\") +\n  \n  # Add label for median:\n  annotate(\"text\",\n           x = 28,\n           y = 0.01,\n           label = \"median\",\n           colour = \"darkred\",\n           family = \"mono\") +\n\n  # Add curved arrow for median:\n  annotate(\n    geom = \"curve\",\n    x = 28,\n    y = 0.008,\n    xend = 31.7,\n    yend = 0.004,\n    curvature = 0.4,\n    arrow = arrow(length = unit(0.2, \"cm\")),\n    colour = \"darkred\") +  \n\n  theme_classic() +\n  scale_y_continuous(name = \"Density\",\n                     breaks = scales::breaks_width(0.01),\n                     expand = c(0, 0)) +\n  scale_x_continuous(breaks = scales::breaks_width(2),\n                     expand = c(0, 0))\n\n\n\n\n\n\n\n\nFigure¬†8.4: Density plot showing the distribution of L1 participants‚Äô ages\n\n\n\n\n\nThe histogram also shows that the most frequent age (the mode) corresponds to the lowest age in the dataset (17) and that both the median and mean are far removed from most participants‚Äô ages. This distribution of L1 participants‚Äô ages points to the limits of measures of central tendency. They are useful to describe approximately normally distributed variables, but are far less informative when it comes to other types of distributions.\n\n\n\n\n\n\nQuiz time!\n\n\n\nQ7. What can we reasonably deduce from the distribution of L1 participants‚Äô ages visualised in Figure¬†8.4?\n\n\n\n\nPeople in their 40s are most likely to be willing to participate in linguistic studies.\n\n\nThe researcher excluded 34 year-olds from this study.\n\n\nIt was easier to recruit teenagers to participate in this study.\n\n\nIt was easier to recruit adults in their 50s and 60s to participate in this study.\n\n\nFor this study, the researcher specifically targeted 17 and 60 year-olds.\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\nQ8. What are the pros of reporting the median rather than the mean to describe the central tendency of a variable?\n\n\n\n\nThe median is the most widely used measure of central tendency.\n\n\nAs the middle value, the median is fairly easy to interpret.\n\n\nThe median is less susceptible to outliers.\n\n\nThe median is less susceptible to skew.\n\n\nThe median has the highest probability of being the true central value.\n\n\nThe median also works well with nominal variables.\n\n\nThe median is ideal for very small datasets.\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\nQ9. What are the cons of reporting the median rather than the mean to describe the central tendency of a variable?\n\n\n\n\nThe median is more susceptible to outliers.\n\n\nThe median is often less meaningful with small sample sizes.\n\n\nThe median does not take all values into account.\n\n\nThe median can be misleading if it is not a value in the dataset.\n\n\nThe median is more susceptible to skew.\n\n\nThe median only works with odd numbers of values.\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Desc`R`iptive statistics</span>"
    ]
  },
  {
    "objectID": "8_DescriptiveStats.html#sec-Variability",
    "href": "8_DescriptiveStats.html#sec-Variability",
    "title": "8¬† DescRiptive statistics",
    "section": "8.3 Measures of variability",
    "text": "8.3 Measures of variability\nMeasures of central tendency should never be reported alone. As we saw with L1 participants‚Äô age in Section 8.2.4, measures of central tendency are not always very informative and can even be misleading. But, even when they are informative, they only tell us part of the story: the average value of a dataset, but not the spread or variability of the data. For example, a mean age of 25 might suggest a group of young adults, but without a measure of variability, we can‚Äôt tell if the group is relatively homogeneous (e.g., all students in their twenties) or heterogeneous (e.g., with some participants in their teens and others in their thirties or older). Therefore, it is essential to report measures of central tendency in conjunction with measures of variability, such as the range, interquartile range, or standard deviation, to provide a more complete picture of the data.\nConsider the three distributions of ages presented in Figure¬†8.5. As you can tell from their shapes, these are three normal distributions. They each have exactly the same mean and median of 35; yet they evidently correspond to very different groups of people!\n\n\nShow R code to generate the plot below.\n# The {truncnorm} package contains density, probability, quantile and random number generation functions for the truncated normal distribution. You will need to install it before you can load it.\n\n#install.packages(\"truncnorm\")\nlibrary(truncnorm)\n\nset.seed(42)\nnormal.age.A &lt;- rtruncnorm(mean = 35, sd = 1, n = 10000, a = 10, b = 64)\nnormal.age.B &lt;- rtruncnorm(mean = 35, sd = 5, n = 10000, a = 10, b = 64)\nnormal.age.C &lt;- rtruncnorm(mean = 35, sd = 10, n = 10000, a = 10, b = 64)\n\nnormal.density &lt;- function(ages) {\n  ggplot(mapping = aes(x = ages)) + \n      geom_vline(aes(xintercept = mean(ages)),\n               color = \"#0000EE\",\n               linetype = \"dashed\",\n               linewidth = 0.8) +\n    theme_classic() +\n    scale_y_continuous(name = \"Density\",\n                       #breaks = scales::breaks_width(0.01),\n                       expand = c(0, 0)) +\n    scale_x_continuous(name = \"Age\",\n                       breaks = scales::breaks_width(2),\n                       limits = c(10,66),\n                       expand = c(0, 0)) +\n    geom_histogram(aes(x = ages, y = after_stat(density)),\n                   binwidth = 1,\n                   fill = \"black\",\n                   alpha = 0.4) + \n    geom_density(colour = \"purple\",\n                 linewidth = 0.8,\n                 fill = \"purple\",\n                 alpha = 0.3)\n}\n\n# The three plots are printed as one figure using the {patchwork} library. You will need to install this library before you can load it and use it.\n\n#install.packages(\"patchwork\")\nlibrary(patchwork)\n\nnormal.density(normal.age.A) / normal.density(normal.age.B) / normal.density(normal.age.C) +\n    # Add captions A, B, C\n    plot_annotation(tag_levels = 'A')\n\n\n\n\n\n\n\n\nFigure¬†8.5: Three normal distributions of ages with a mean/median of 35 years.\n\n\n\n\n\nWhereas Group A only includes adults aged 32 to 39, the Group C includes children as young as 10 as well as adults well into their 50s and early 60s - even though they both have the same mean/median on 35. This is why both measures of central tendency and variability are important when describing numeric variables! Measures of variability help us to understand how far each data point is from the central tendency. Hence, for Group A in Figure¬†8.5, we can say that all data points are pretty close to the mean/median of 35. In Group B, participants‚Äô ages are, on average, more ‚Äòspread out‚Äô to the left and right of the central tendency. And this is even more notable in Group C.\n\n8.3.1 Range\nThe most basic measure of variability is one that you will already be familiar with: range. It is easily calculated by subtracting the highest value of a variable from its lowest value. For example, in DƒÖbrowska (2019), the range of results obtained by the L1 participants in the English grammar comprehension test is:\n\nmax(L1.data$GrammarR) - min(L1.data$GrammarR)\n\n[1] 22\n\n\nBy contrast, the range of results in this same test among the L2 participants is:\n\nmax(L2.data$GrammarR) - min(L2.data$GrammarR)\n\n[1] 40\n\n\nIn practice, the range is usually reported by explicitly mentioning a variable‚Äôs lowest and highest values as this is usually much more informative than the range itself. Here is how DƒÖbrowska (2019) reports the age of the participants in the published article:\n\nThe L1 participants were all born and raised in the United Kingdom and were selected to ensure a range of ages, occupations, and educational backgrounds. The age range was from 17 to 65 years [‚Ä¶]. The nonnative participants ranged in age from 20 to 62 years [‚Ä¶] (DƒÖbrowska 2019: 6).\n\n\n\n\n\n\n\nTask 1\n\n\n\nComplete the description of the GrammarR variable in L1.data and L2.data below.\nCopy and paste the following paragraph into a text processor (e.g., LibreOffice Writer or Microsoft Word) and fill in the six blanks using figures that you calculated in R. If necessary, round off values to two decimal places.\n\nOn average, English native speakers performed only marginally better in the English grammatical comprehension test (median = ______) than English L2 learners (median = ______). However, L1 participants‚Äô grammatical comprehension test results ranged from ______to ______, whereas L2 participants‚Äô results ranged from ______to ______. ¬†\n\n\n\n\n\n\n\n\n\nClick here for the solution to Task 1\n\n\n\n\n\nYour paragraph should read as follows:\n\nOn average, English native speakers performed only marginally better in the English grammatical comprehension test (median = 76) than English L2 learners (median = 75). L1 participants‚Äô grammatical comprehension test results ranged from 58 to 80. In this same test, L2 participants‚Äô results ranged 40 to 80.\n\nThe following lines of R code can be used to obtain these numbers.\n\nmedian(L1.data$GrammarR)\n\n[1] 76\n\nmedian(L2.data$GrammarR)\n\n[1] 75\n\nmin(L1.data$GrammarR)\n\n[1] 58\n\nmax(L1.data$GrammarR)\n\n[1] 80\n\nmin(L2.data$GrammarR)\n\n[1] 40\n\nmax(L2.data$GrammarR)\n\n[1] 80\n\n\n\n\n\n\n\n8.3.2 Interquartile range\nWe saw that the median is a measure of central tendency that represents the middle value. This means that 50% of the data falls below the median and 50% falls above the median. Going back to the test results of our six learners of Breton in Fiji, this means that half of the class scored below 86.5 and the other half above 86.5.\n\nmedian(c(5, 82, 86, 87, 89, 91))\n\n[1] 86.5\n\n\nWe can further subdivide the distribution into chunks of 25% of the data, or quartiles (see Figure¬†8.6).\n\nThe first quartile (Q1) is the value below which 25% of the data falls. In other words, the first quartile corresponds to a value that lies above one-quarter of the values in the data set.\nThe second quartile (Q2) is the median and, as we know, half of the data (25% + 25% = 50%) are below this value, the other half are above.\nThe third quartile (Q3) is the value below which 75% of the data falls. In other words, it is also the value above which the upper 25% of the data are.\nThe interquartile range (IQR) is the range between the second and the third quartile: it therefore covers the middle 50% of the data. This is illustrated below with a growing number of imaginary Breton learners.\n\n\n\n\n\n\n\nFigure¬†8.6: Animation showing the interquartile range of five different sets of values (CC-BY Elen Le Foll)\n\n\n\nThe easiest way to examine a variable‚Äôs IQR in R is to use the handy summary() function which, when applied to a numeric variable, returns a number of useful descriptive statistics including its first and third quartiles.5\n\nsummary(L1.data$GrammarR)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  58.00   71.25   76.00   74.42   79.00   80.00 \n\n\nFrom the output of the summary() function, we can easily calculate the IQR, which we know is equal to the range between the first and the third quantile.\n\n79 - 71.25\n\n[1] 7.75\n\n\nAlternatively, we can compute the IQR directly using the IQR() function.\n\nIQR(L1.data$GrammarR)\n\n[1] 7.75\n\n\nThe reason that the summary() function is probably more useful than IQR() is that, like the full range, the interquantile range is not usually reported as the difference between Q3 and Q1. This is because it is more informative to consider the first quartile (Q1), the median (Q2), and the third quartile (Q3) together to grasp both the central tendency of a set of numbers and the amount of variability there is around this central tendency.\nIn practice, quartiles are rarely reported as numbers. Instead, they are usually visualised as boxplots. Boxplots present a visual summary of a numeric variable‚Äôs central tendency and variability around this central tendency. On a boxplot, the box represents the IQR. Its dividing line is the median. The whiskers and any outlier points represent the rest of the distribution (see Figure¬†8.7). In other words, the lower whisker roughly covers the lower 25% of the data and the upper whisper the top 25% of the data. Boxplots are most often displayed vertically and are used to visually compare the main characteristics of distributions of numeric values across different groups (e.g., grammar comprehension across different language proficiency groups).\n\n\n\n\n\n\nFigure¬†8.7: Animation showing the making of a boxplot (CC-BY Elen Le Foll)\n\n\n\nRemember that, in a perfectly normal distribution, the mean and median are equal. When a variable follows a normal distribution, its box is divided into two equal halves and the whiskers are of equal length (see Figure¬†8.8). This symmetry comes from the fact that the values are equally distributed to the left and right of the median/mean. For the same reason, the bells of the normal distributions in Figure¬†8.5 were all (almost) symmetrical, although they had very different heights and widths.\n\n\n\n\n\n\nQuiz time!\n\n\n\nQ10. Examine the boxplots displayed in Figure¬†8.8.\n\n\n\n\n\n\n\n\nFigure¬†8.8: Three boxplots\n\n\n\n\n\nWhich of the following statements accurately describe the age distributions displayed in Figure¬†8.8?\n\n\n\n\nAges in Group 1 are normally distributed.\n\n\nAges in Group 1 are not normally distributed.\n\n\nAges in Group 2 are normally distributed.\n\n\nAges in Group 2 are not normally distributed.\n\n\nAges in Group 3 are normally distributed.\n\n\nIn Group 3, all participants were born within 12 months of each other.\n\n\nOn average, participants were older in Group 1 and younger in Group 3.\n\n\nIn all three groups, the median age is approximately the same.\n\n\nIn all three groups, the mean age is approximately the same.\n\n\nIn all three groups, the IQR is approximately the same.\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a first hint.\n\n\n\n\nü¶â Hover over the owl for a second hint.\n\n\n\n\n¬†\nQ11. The boxplots in Figure¬†8.8 are based on the same data as the three density plots in Figure¬†8.5. Compare the two figures. Which distribution corresponds to which boxplot?\n\n\n\n\nDistribution C is visualised in boxplot 1.\n\n\nDistribution C is visualised in boxplot 3.\n\n\nDistribution A is visualised in boxplot 3.\n\n\nDistributions A, B and C are visualised in boxplot 2.\n\n\nDistribution B is visualised in boxplot 1.\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\nQ12. Examine the following distribution of scores on the grammatical comprehension test administered as part of DƒÖbrowska (2019).\n\n\n\n\n\n\n\n\nFigure¬†8.9: Density plot of participants‚Äô scores on the English comprehension grammar test\n\n\n\n\n\n¬†\nAre the scores visualised in Figure¬†8.9 normally distributed?\n\n\n\n\nNo, they are far from normally distributed.\n\n\nYes, they are approximately normally distributed, but with a slight positive skew.\n\n\nYes, they are approximately normally distributed.\n\n\nIt's impossible to tell from the plot alone.\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\nQ13. Compare the following outputs of the summary() function.\n\nsummary(L1.data$GrammarR)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  58.00   71.25   76.00   74.42   79.00   80.00 \n\nsummary(L2.data$GrammarR)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  40.00   58.50   75.00   67.76   78.00   80.00 \n\n\nBased on the outputs of the summary() function, what does Figure¬†8.9 display?\n\n\n\n\nThe distribution of GrammarR scores among L1 participants.\n\n\nThe distribution of GrammarR scores among L2 participants.\n\n\nThe distribution of GrammarR scores among both L1 and L2 participants.\n\n\nNone of the above.\n\n\n\n\n\n\n\n¬†\nQ14. Compare the following boxplots which summarise the distribution of scores on the grammatical comprehension test (GrammarR) administered as part of DƒÖbrowska (2019).\n\n\n\n\n\n\n\n\nFigure¬†8.10: Boxplots showing L1 and L2 participants‚Äô English grammar comprehension test scores\n\n\n\n\n\nWhy do the two boxplots look so different?\n\n\n\n\nBecause the IQR of scores was much larger among L2 participants than among L1 participants.\n\n\nBecause the two groups were not of equal size (there were more L1 than L2 participants).\n\n\nBecause more than a quarter of L2 participants scored below 60, whereas only one L1 participant scored below 60.\n\n\nBecause the range of scores was much larger among L2 participants than among L1 participants.\n\n\nBecause the median L2 score is much lower than the median L1 score.\n\n\nBecause proportionally more L2 participants scored below the L2 median score than L1 participants did below the L1 median.\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\nü¶â Hover over the owl for a second hint.\n\n\n\n\n\n\n\n\n8.3.3 Standard deviation\nIn the language sciences and in many other disciplines, standard deviation is the most common reported measure of variability. Whereas the interquartile range (IQR) is a measure of variability around the median, standard deviation (SD) measures variability around the mean. In other words, if you report a mean value as a measure of central tendency, you should report the standard deviation along side it. However, if you report the median, than it makes more sense to report the IQR in the form of a boxplot (see Section 8.3.2).\n\nIn a nutshell, the standard deviation tells us how far away, on average, each data point is from the mean.\n\n¬†Considering the test scores of our five Breton learners, we already know that the standard deviation is likely to be large because the mean (70.6) is quite far away from all five data points.\n\n5, 82, 86, 89, 91\n\nTo calculate how far exactly, we first measure how far each point is from the mean, e.g.¬†for the first data point we calculate 5 - 70.6, for the second 82 - 70.6, etc.\n\nBreton.scores &lt;- c(5, 82, 86, 89, 91)\n\nBreton.scores - mean(Breton.scores)\n\n[1] -65.6  11.4  15.4  18.4  20.4\n\n\nAs you can see, some of the differences between the data points and the mean value are negative, whilst others are positive. For standard deviation, we are not interested in whether data points are above or below the mean, but rather in how far removed they are from the mean. To remove any negative sign, we therefore square all these distances. The squaring operation (^2) also has the effect making large differences even larger.\n\n(Breton.scores - mean(Breton.scores))^2\n\n[1] 4303.36  129.96  237.16  338.56  416.16\n\n\nRemember that standard deviation is a measure of how different, on average, a set of numbers are from one another, with respect to the mean. We have just calculated the sum of the squared differences from the mean and we now need to calculate the average of these squared differences. To calculate the mean squared difference, we sum the differences and divide them by the number of data points.\n\nsum((Breton.scores - mean(Breton.scores))^2) / 5\n\n[1] 1085.04\n\n\nThis is the variance. The problem with the variance is that it is not in the original scale of our variable, but rather in squared units, i.e., here, in squared test scores, which is rather difficult to interpret! This is why we more commonly report the standard deviation, which is the square root of the variance. The square root function in R is sqrt().\n\nsqrt(sum((Breton.scores - mean(Breton.scores))^2) / 5)\n\n[1] 32.93995\n\n\nFrom the above result, we can deduce that, on average, learners‚Äô test scores are 32 points away from the group mean of 70.6 points.\nOf course, there is a base R function to calculate the standard deviation. It is called sd(). However, if we use the sd() function to calculate the standard deviation of our five Breton learners‚Äô test scores, we get a slightly different result.\n\nsd(Breton.scores)\n\n[1] 36.82798\n\n\nThis is because, in practice, we almost always divide the sum of squares not by the total number of data points (N ), but by the total number minus one (N-1). This is the difference between the population standard deviation and the sample standard deviation. The population standard deviation is used when we have access to the entire population (e.g.¬†all L2 English users worldwide!), which is rare in real-world scenarios. In most cases, we work with samples (e.g., as in DƒÖbrowska 2019, a sample of 67 L2 English users). Dividing by N-1 gives us a more accurate estimate of the population‚Äôs standard deviation based on our sample. It helps to reduce the bias in our estimate, making it a more reliable measure of variability around the mean.\nIn R, the sd() function calculates the sample standard deviation.\n\nsqrt(sum((Breton.scores - mean(Breton.scores))^2) / 4)\n\n[1] 36.82798\n\n\nWith a normal distribution, the standard deviation informs us about the width of the bell around the central tendency. In Figure¬†8.5 we saw that three normal distributions, all with a median/mean of 35 could have very different bell shapes. This is because they have very different standard deviations around that central tendency. Let us compare the distribution shapes of these three distributions in detail.\nDistribution A (Figure¬†8.11) is a normal distribution with a mean of 35 years (xÃÖ = 35) and a standard deviation of one year (sd = 1).\n\n\n\n\n\n\n\n\nFigure¬†8.11: Density plot of Distribution A\n\n\n\n\n\nDistribution B (Figure¬†8.12) is a normal distribution with a mean of 35 years (xÃÖ = 35) and a standard deviation of 5 years (sd = 5).\n\n\n\n\n\n\n\n\nFigure¬†8.12: Density plot of Distribution B\n\n\n\n\n\nDistribution C (Figure¬†8.13) is a normal distribution with a mean of 35 years (xÃÖ = 35) and a standard deviation of 10 years (sd = 1).\n\n\n\n\n\n\n\n\nFigure¬†8.13: Density plot of Distribution C\n\n\n\n\n\nThe standard deviation provides a single metric of the variability around the mean. This means that knowing the mean and standard deviation of a numeric variable is not enough to tell whether a distribution is (approximately) normal or skewed. Like the range and the IQR, a large standard deviation value indicates greater variability within a variable, but tells us nothing more. For instance, comparing the following two SDs tells us that there is more variability around the mean in L2 participants‚Äô grammar comprehension test scores than in that of the L1 participants, but nothing more about the distribution of the test scores in either group.\n\nsd(L1.data$GrammarR) |&gt;\n  round(digits = 2)\n\n[1] 5.01\n\nsd(L2.data$GrammarR) |&gt; \n  round(digits = 2)\n\n[1] 13.48\n\n\nIn this respect, boxplots are more informative (compare the above SDs with Figure¬†8.10). To evaluate the full shape of a numeric variable‚Äôs distribution, however, there is no alternative to plotting it as a histogram or density plot.\nIn sum, remember that, when describing variables, it is important to report both an appropriate measure of central tendency and an appropriate measure of variability. In addition, it is good practice to visualise the full distribution of a variable‚Äôs values in the form of a table, histogram, or density plot (see Chapter 11 on data visualisation). This is because any combination of a single measure of central tendency and a single measure of variability can correspond to an array of different distribution shapes.\n\n\n\n\n\n\nQuiz time!\n\n\n\nQ15. What is the standard deviation of L1 participants‚Äô age in DƒÖbrowska (2019)? Calculate the sample standard deviation to two decimal places.\n\n\n\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\nQ16. Compare the standard deviation of the Age variable in the L1 and L2 datasets. What can you conclude on the basis of this comparison?\n\n\n\n\nAge is not normally distributed in both the L1 and the L2 data.\n\n\nThere is greater variability around the mean age in the L1 data than in the L2 data.\n\n\nThere is greater variability around the mean age in the L2 data than in the L1 data.\n\n\nL2 participants are more likely to be older than L1 participants.\n\n\nThere is almost twice as much variability in L2 participants' ages than in L1's.\n\n\n\n\n\n\n\nüê≠ Click on the mouse for a hint.\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\nAs a follow-up, I highly recommend reading this short and highly accessible article by Fahd Alhazmi (2020), who provides a wonderful visual guide to understanding standard deviation: https://towardsdatascience.com/a-visual-interpretation-of-the-standard-deviation-30f4676c291c.\n\n\n\n\nCheck your progress üåü\nYou have successfully completed 0 out of 13 quiz questions in this chapter.\nAre you confident that you can‚Ä¶?\n\nUse and interpret different measures of central tendency (Section 8.1)\nCalculate the mode, mean, median of a numeric variable in R (Section 8.1.1 - Section 8.1.2)\nInterpret histograms and density plots (Section 8.2)\nRecognise the characteristics of a normal distribution (Section 8.2.3)\nInterpret and calculate the interquartile range in R (Section 8.3.2)\nInterpret boxplots (Section 8.3.2)\nInterpret and calculate the standard deviation (Section 8.3.3)\n\nIn Chapter 10, we will cover the basics of data visualisation and learn how to create a range of informative and elegant plots (including histograms and density plots) using the popular R package ggplot2. But, first, we need to learn about data wrangling (Chapter 9) to prepare our data for data visualisation and multivariable analyses. Are you ready? ü§ì\n\n\n\n\nAlhazmi, Fahd. 2020. A visual interpretation of the standard deviation. Medium. https://towardsdatascience.com/a-visual-interpretation-of-the-standard-deviation-30f4676c291c.\n\n\nDƒÖbrowska, Ewa. 2019. Experience, aptitude, and individual differences in linguistic attainment: A comparison of native and nonnative speakers. Language Learning 69(S1). 72‚Äì100. https://doi.org/10.1111/lang.12323.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Desc`R`iptive statistics</span>"
    ]
  },
  {
    "objectID": "8_DescriptiveStats.html#footnotes",
    "href": "8_DescriptiveStats.html#footnotes",
    "title": "8¬† DescRiptive statistics",
    "section": "",
    "text": "Breton is the Celtic language of Brittany (now in North-West France). With around 216,000 active speakers (Wikipedia, 26/08/2024), Breton is classified as ‚Äòseverely endangered‚Äô in the UNESCO‚Äôs Atlas of the World‚Äôs Languages in Danger. It would presumably be quite a feat to put together a class of five Breton learners in Fiji, an island country far removed from Brittany in the South Pacific Ocean with fewer than one million inhabitants (Wikipedia, 26/08/2024)!‚Ü©Ô∏é\nWe also see that this data needs cleaning before we can do any serious data analysis. There are also a few typos (e.g., Unemploed) and synonyms (School Crossing Guard and School Crossing Patrol) that we will need to standardise. This process is part of data wrangling and we will cover how to do this in a reproducible way in R in the following chapter.‚Ü©Ô∏é\nA Likert scale is a type of rating scale used to measure attitudes, opinions, or feelings. It typically consists of a series of statements or questions with a range of possible responses, often on a scale from ‚Äústrongly disagree‚Äù to ‚Äústrongly agree‚Äù. For example, in a study on language attitudes, participants might be asked to rate their agreement with the statement ‚ÄúI think it‚Äôs important to speak standard English in formal situations‚Äù on a scale from ‚Äú1 (strongly disagree)‚Äù to ‚Äú5 (strongly agree)‚Äù. The resulting variable will therefore consist of numbers ranging between 1 and 5. Note also that, strictly speaking, Likert scales are not numeric variables, but rather ordinal variables (see Section 7.2.1). The numbers refer to different categories that describe an order of responses, rather than a quantity.‚Ü©Ô∏é\nOf course, there is an R function to help you do the maths! The edcf() function allows us to calculate the area under the curve between the ages of 42 and 62.\n\necdf(L2.data$Age)(62) - ecdf(L2.data$Age)(42)\n\n[1] 0.119403\n\n\nIn other words, there is a 11.94 % probability of any L2 participant in this study being aged between 42 and 62 (corresponding to the light purple area in plot A). Compare this to the probability of a participant being between 22 and 42 years old.\n\necdf(L2.data$Age)(42) - ecdf(L2.data$Age)(22)\n\n[1] 0.7761194\n\n\nThis is, indeed, a much higher probability (ca. 78 %), as depicted by the much larger area highlighted in plot B.\n\n\n\n\n\n\n\n\n\n‚Ü©Ô∏é\nQuartiles can also be computed using the quantile() function, which takes two arguments: the variable and a value between 0 and 1 corresponding to our quantile of interest. We are interested in the first and third quartiles, therefore in the values below which lie one quarter (0.25) and three-quarters (0.75) of all the data.\nTo compute the first quantile (Q1), we therefore enter:\n\nquantile(L1.data$GrammarR, 0.25)\n\n  25% \n71.25 \n\n\nFor the third quantile (Q3), we need:\n\nquantile(L1.data$GrammarR, 0.75)\n\n75% \n 79 \n\n\n‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Desc`R`iptive statistics</span>"
    ]
  },
  {
    "objectID": "99_references.html",
    "href": "99_references.html",
    "title": "References",
    "section": "",
    "text": "2011. IRIS. https://iris-database.org/.\n\n\nAbeysooriya, Mandhri, Megan Soria, Mary Sravya Kasu & Mark Ziemann.\n2021. Gene name errors: Lessons not learned. PLOS Computational\nBiology. Public 17(7). e1008984. https://doi.org/10.1371/journal.pcbi.1008984.\n\n\nAlhazmi, Fahd. 2020. A visual interpretation of the standard deviation.\nMedium. https://towardsdatascience.com/a-visual-interpretation-of-the-standard-deviation-30f4676c291c.\n\n\nalvinashcraft, alexbuckgit, ArcticLampyrid & bearmannl. 2022.\nMaximum path length limitation. Learn Microsoft. https://learn.microsoft.com/en-us/windows/win32/fileio/maximum-file-path-limitation.\n\n\nBarrett, Malcolm. 2018. Why should i use the here package when i‚Äôm\nalready using projects? - malcolm barrett. https://malco.io/articles/2018-11-05-why-should-i-use-the-here-package-when-i-m-already-using-projects.\n\n\nBerez-Kroeker, Andrea L., Bradley McDonnell, Eve Koller & Lauren B.\nCollister. 2022. The open handbook of linguistic data\nmanagement. MIT Press. https://doi.org/10.7551/mitpress/12200.001.0001.\n\n\nBryan, Jennifer. 2018. Let‚Äôs git started | happy git and GitHub for\nthe useR. Open Education Resource. https://happygitwithr.com/.\n\n\nBryan, Jenny. 2017. Project-oriented workflow. Tidyverse.org.\nhttps://www.tidyverse.org/blog/2017/12/workflow-vs-script/.\n\n\nBusterud, Guro, Anne Dahl, Dave Kush & Kjersti Faldet Listhaug.\n2023. Verb placement in L3 french and L3 german: The role of\nlanguage-internal factors in determining cross-linguistic influence from\nprior languages. Linguistic Approaches to Bilingualism. John\n13(5). 693‚Äì716. https://doi.org/10.1075/lab.22058.bus.\n\n\nDƒÖbrowska, Ewa. 2019. Experience, aptitude, and individual differences\nin linguistic attainment: A comparison of native and nonnative speakers.\nLanguage Learning 69(S1). 72‚Äì100. https://doi.org/10.1111/lang.12323.\n\n\nDauber, Daniel. 2024. R for non-programmers: A guide for social\nscientists. Open Education Resource. https://bookdown.org/daniel_dauber_io/r4np_book/.\n\n\nDouglas, Alex, Deon Roos, Francesca Mancini & David Lusseau. 2024.\nAn introduction to R. https://intro2r.com/.\n\n\nLausberg, Hedda & Han Sloetjes. 2009. Coding gestural behavior with\nthe NEUROGES-ELAN system. Behavior Research Methods 41(3).\n841‚Äì849. https://doi.org/10.3758/BRM.41.3.841.\n\n\nLe Foll, Elen. 2022. Textbook English: A\ncorpus-based analysis of the language of EFL textbooks used in secondary\nschools in France, Germany and\nSpain. Osnabr√ºck University PhD thesis. https://doi.org/10.48693/278.\n\n\nParsons, Sam, Fl√°vio Azevedo, Mahmoud M. Elsherif, Samuel Guay, Owen N.\nShahim, Gisela H. Govaart, Emma Norris, et al. 2022. A community-sourced\nglossary of open scholarship terms. Nature Human\nBehaviour. Nature 6(3). 312‚Äì318. https://doi.org/10.1038/s41562-021-01269-4.\n\n\nPrat, Chantel S., Tara M. Madhyastha, Malayka J. Mottarella &\nChu-Hsuan Kuo. 2020. Relating natural language aptitude to individual\ndifferences in learning programming languages. Scientific\nReports. Nature 10(1). 3817. https://doi.org/10.1038/s41598-020-60661-8.\n\n\nR Core Team. 2024. R: A language and environment for statistical\ncomputing. R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nSchimke, Sarah, Israel de la Fuente, Barbara Hemforth & Saveria\nColonna. 2018. First language influence on second language offline and\nonline ambiguous pronoun resolution. Language Learning 68(3).\n744‚Äì779. https://doi.org/10.1111/lang.12293.\n\n\nSchweinberger, Martin. 2022. Data management, version control, and\nreproducibility. https://ladal.edu.au/repro.html.\n\n\nSilge, Julia. 2022. Janeaustenr: Jane Austen‚Äôs complete\nnovels. https://CRAN.R-project.org/package=janeaustenr.\n\n\nThe Turing Way Community. 2022. The turing way: A handbook for\nreproducible, ethical and collaborative research (1.0.2). Zenodo. https://doi.org/10.5281/zenodo.3233853.\n\n\nWinter, Bodo. 2019. Statistics for linguists: An introduction using\nR. Routledge. https://doi.org/10.4324/9781315165547.\n\n\nZiemann, Mark, Yotam Eren & Assam El-Osta. 2016. Gene name errors\nare widespread in the scientific literature. Genome Biology\n17(1). 177. https://doi.org/10.1186/s13059-016-1044-7.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "A_FurtherResources.html",
    "href": "A_FurtherResources.html",
    "title": "Appendix A ‚Äî Next-step resources",
    "section": "",
    "text": "A.1 Recommended resources specific to the language sciences",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Next-step resources</span>"
    ]
  },
  {
    "objectID": "A_FurtherResources.html#recommended-resources-specific-to-the-language-sciences",
    "href": "A_FurtherResources.html#recommended-resources-specific-to-the-language-sciences",
    "title": "Appendix A ‚Äî Next-step resources",
    "section": "",
    "text": "Brezina, Vaclav. 2018. Statistics in Corpus Linguistics: A Practical Guide. Cambridge: Cambridge University Press. https://doi.org/10.1017/9781316410899.\nDesagulier, Guillaume. 2017. Corpus Linguistics and Statistics with R: Introduction to Quantitative Methods in Linguistics (Quantitative Methods in the Humanities and Social Sciences). Cham: Springer International Publishing.\nGries, Stefan Thomas. 2013. Statistics for linguistics with R: a practical introduction. 2nd revised edition. Berlin: De Gruyter Mouton.\nLADAL contributors. Tutorials of the Language Technology and Data Analysis Laboratory. https://ladal.edu.au/tutorials.html Open Educational Resource.\nLevshina, Natalia. 2015. How to do linguistics with R: Data exploration and statistical analysis. Amsterdam: John Benjamins.\nSchneider, Dr Gerold & Max Lauber. 2020. Statistics for Linguists. https://dlf.uzh.ch/openbooks/statisticsforlinguists/ Open Educational Resource.\nWinter, Bodo. 2019. Statistics for Linguists: An Introduction Using R. New York: Routledge. https://doi.org/10.4324/9781315165547.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Next-step resources</span>"
    ]
  },
  {
    "objectID": "A_FurtherResources.html#further-open-educational-resources-in-no-particular-order",
    "href": "A_FurtherResources.html#further-open-educational-resources-in-no-particular-order",
    "title": "Appendix A ‚Äî Next-step resources",
    "section": "A.2 Further Open Educational Resources (in no particular order)",
    "text": "A.2 Further Open Educational Resources (in no particular order)\n\nDiez, David, Mine Cetinkaya-Rundel, Christopher Barr & OpenIntro. 2015. OpenIntro Statistics. Leanpub. https://leanpub.next/os.\nGuide to Effect Sizes and Confidence Intervals: https://matthewbjane.quarto.pub/guide-to-effect-sizes-and-confidence-intervals/\nHappy Git and GitHub for the useR: https://happygitwithr.com/\nQuarto & reproducibility: https://ucsbcarpentry.github.io/Reproducible-Publications-with-RStudio-Quarto/index.html\nModern Data Visualization with R: https://rkabacoff.github.io/datavis\nBuilding reproducible analytical pipelines with R: https://raps-with-r.dev/\nModern Plain Text Computing: https://mptc.io/content/01-content.html\nhttps://www.data-to-viz.com/\nInterpreting data visualisation: https://pressbooks.library.torontomu.ca/criticaldataliteracy/\nImprove your statistical inferences: https://lakens.github.io/statistical_inferences/\nWhat they forgot to teach you about R: https://rstats.wtf/\nIntroduction to Data Science: https://florian-huber.github.io/data_science_course/book/cover.html\nData Science in Education Using R: https://datascienceineducation.com/\nModels Demystified: A Practical Guide from t-tests to Deep Learning https://m-clark.github.io/book-of-models/\nData Visualization in R https://datavizf23.classes.andrewheiss.com/\nR for Data Science https://r4ds.hadley.nz/intro\nDauber, Daniel. 2024. R for Non-Programmers: A Guide for Social Scientists. https://bookdown.org/daniel_dauber_io/r4np_book/.\nBayes Rules! An Introduction to Applied Bayesian Modeling https://www.bayesrulesbook.com/\nFundamentals of Data Visualization by Claus O. Wilke https://clauswilke.com/dataviz/\nLearning statistics with R https://learningstatisticswithr.com\nQuarto for scientists https://qmd4sci.njtierney.com/\nThe Version Control Book: Track, organize and share your work: An introduction to Git for research https://lennartwittkuhn.com/version-control-book/",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Next-step resources</span>"
    ]
  }
]